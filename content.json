[{"title":"Java：“目标服务器没有返回一个X-Frame-Options头”的解决方案","date":"2018-07-29T03:25:00.000Z","path":"java/java-springmvc-X-Frame-Options.html","text":"Java：“目标服务器没有返回一个X-Frame-Options头”的解决方案。 前言在涉及网站安全时遇到一个问题，“目标服务器没有返回一个X-Frame-Options头”，找了网上的帖子，说的都不是太清楚，所以研究总结一下，方便后人。 正文问题描述以下摘录一下对于安全网站这个问题的描述和建议解决方案： 概要目标服务器没有返回一个X-Frame-Options头。攻击者可以使用一个透明的、不可见的iframe，覆盖在目标网页上，然后诱使用户在该网页上进行操作，此时用户将在不知情的情况下点击透明的iframe页面。通过调整iframe页面的位置，可以诱使用户恰好点击iframe页面的一些功能性按钮上，导致被劫持。解决方案修改web服务器配置，添加X-frame-options响应头。赋值有如下三种：（1）DENY：不能被嵌入到任何iframe或frame中。（2）SAMEORIGIN：页面只能被本站页面嵌入到iframe或者frame中。（3）ALLOW-FROM uri：只能被嵌入到指定域名的框架中。也可在代码中加入，在PHP中加入：header(‘X-Frame-Options: deny’); 具体实例但是我们的环境是Java的Springmvc，这个应该怎么解决呢？其实Spring框架中的security本身有对这个问题的解决方案，但是这是之前的Spring框架中的（SSH那会的），现在用了Springmv了，应该怎么去解决这个问题呢？ 参考这里，这里介绍说配置项目的web.xml文件如下，即可解决问题： 1234567891011121314&lt;filter&gt; &lt;filter-name&gt;httpHeaderSecurity&lt;/filter-name&gt; &lt;filter-class&gt;org.apache.catalina.filters.HttpHeaderSecurityFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;antiClickJackingOption&lt;/param-name&gt; &lt;param-value&gt;SAMEORIGIN&lt;/param-value&gt; &lt;/init-param&gt; &lt;async-supported&gt;true&lt;/async-supported&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;httpHeaderSecurity&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 但是又引出一个新的问题： cvc-complex-type.2.4.a: Invalid content was found starting with element ‘async-supported’. One of ‘{“http://java.sun.com/xml/ns/javaee&quot;:run-as, “http://java.sun.com/xml/ns/javaee&quot;:security-role-ref}&#39; is expected. 继续探索，找到这里说的： xmlns中再加两行：http://www.springmodules.org/schema/cache/springmodules-cache.xsdhttp://www.springmodules.org/schema/cache/springmodules-ehcache.xsd 问题才真正得到了解决，但是原因是什么呢？ 找到Tomcat官网的讲解： org.apache.catalina.filters.HttpHeaderSecurityFilter .//过滤器的类名……antiClickJackingOption //参数配置，可以设置成DENY（拒绝），SAMEORIGIN（同源），ALLOW-FROM（允许从哪里来的）What value should be used for the anticlick-jacking header? Must be one of DENY, SAMEORIGIN, ALLOW-FROM (case-insensitive). If not specified, the default value of DENY will be used. 这样，上面配置这个过滤器就搞明白了，那么后面出现的那个问题又是怎么回事呢？ 这里要研究一下这段语句的意思：1234567&lt;web-app version=&quot;3.0&quot; xmlns=&quot;http://java.sun.com/xml/ns/javaee http://www.springmodules.org/schema/cache/springmodules-cache.xsd http://www.springmodules.org/schema/cache/springmodules-ehcache.xsd&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd&quot;&gt; xmlns：xml的namespace，这个是为了解决多个开发者对于xml的命名会产生冲突的问题。xmlns:xsi：定义了xml的标准前缀。xsi:schemaLocation：xml的schema定义的位置。 简言之，Java对于xml的名值设置了一套定义规则，发布在上面的地方，我们上面使用的这个元素名async-supported ，在之前的web.xml中所定义的位置是没有找到的，所以要改成可以找到这个元素定义的位置。 至此，问题基本搞明白了。 参考https://www.w3schools.com/xml/schema_intro.asp。","tags":[{"name":"Java","slug":"Java","permalink":"https://www.oxysun.cn/tags/Java/"}]},{"title":"Git：git diff发现windows下会出现\"^M\"符号","date":"2018-07-28T13:53:00.000Z","path":"git/git-diff-m-symbol.html","text":"原帖收藏于IT老兵驿站，传递一个IT老兵凋零前的光和氧。 Git：git diff发现windows下会出现”^M”符号。 前言在不同操作系统上编译Git仓库的文件，经常在git diff 时发现很多文件的变化是尾部多了一个^M 的符号。这给工作带来很多困扰，研究一下这个问题。 正题翻到这个帖子： GitHub suggests that you should make sure to only use \\n as a newline character in git-handled repos. There’s an option to auto-convert: 1$ git config --global core.autocrlf true 大体翻译：GitHub建议你应该只用\\n 来做为新行的开始，用上面那样的设置就可以做到自动的转换，这样也就解决了问题，Git不会再报告差异。 那这是为什么呢？ 阅读一下这里所介绍的这个帖子。 If you’re using Git to collaborate with others on GitHub, ensure that Git is properly configured to handle line endings. Every time you press return on your keyboard you’re actually inserting an invisible character called a line ending. Historically, different operating systems have handled line endings differently. When you view changes in a file, Git handles line endings in its own way. Since you’re collaborating on projects with Git and GitHub, Git might produce unexpected results if, for example, you’re working on a Windows machine, and your collaborator has made a change in OS X. 这里大概是说每个操作系统有自己的换行符（就是当你按下”回车”后，系统会自动插入一些不可见的符号来表示一行的结束），Linux和Mac都是使用LF ，Windows 则是CRLF ，这样就造成了差异。 Git会对此进行一些处理，但是做什么处理呢？这里没有说清楚，只是说要用 1git config core.autocrlf 来控制，和上面说的是一样的，但是原理还是没有搞明白。 只好来看官网。 core.autocrlfSetting this variable to “true” is the same as setting the text attribute to “auto” on all files and core.eol to “crlf”. Set to true if you want to have CRLF line endings in your working directory and the repository has LF line endings. This variable can be set to input, in which case no output conversion is performed. 这个变量设置为true 等同于在所有文件上设置text attribute 为auto 并且把core.eol 设置为crlf。设成true ， 如果你的工作空间用的是CRLF 作为行结束符，同时仓库用的是LF 行结束符。这个变量也可以设置成input，这样在输出时就不做转换了。 对上面说的core.eol 又不明白了，继续查看： core.eolSets the line ending type to use in the working directory for files that have the text property set when core.autocrlf is false. Alternatives are lf, crlf and native, which uses the platform’s native line ending. The default value is native. See gitattributes[5] for more information on end-of-line conversion. 这个变量是用来设置行结束符的，在core.autocrlf 是false的时候。可以设置成lf，crlf和native ， native是说使用当前平台自己的行结束符。 到这里，大体就明白了，还留有一个问题，就是attribute的问题，留在下一次来研究。","tags":[{"name":"Git","slug":"Git","permalink":"https://www.oxysun.cn/tags/Git/"}]},{"title":"Linux下shell命令用法及常见用例：which","date":"2018-07-26T15:03:07.000Z","path":"linux/shell-command-which.html","text":"which命令用于查找并显示给定命令的绝对路径，环境变量$PATH中保存了查找命令时需要遍历的目录。which指令会在环境变量$PATH设置的目录里查找符合条件的文件。也就是说，使用which命令，就可以看到某个系统命令是否存在，以及执行的到底是哪一个位置的命令。 备注今天有点累，也已经很晚了，总结一个较为简单的命令吧，20英里法则，每天尽量坚持往前走一点。 命令功能which命令是查找某个命令的完整路径。它是用来在当前登录用户的$PATH环境变量记录的路径中查找可执行文件（即二进制文件）的路径。默认情况下，只返回第一个搜索结果。 1234WHICH(1) General Commands Manual WHICH(1)NAME which - shows the full path of (shell) commands. 命令格式which [选项] 命令 实例实例：查看ls命令的位置 123[root@iZwz90drrwkerfi7bc8mqiZ ~]# which lsalias ls=&apos;ls --color=auto&apos; /usr/bin/ls 第一行输出暂时没有搞明白是哪里来的，第二行就是ls命令的位置了。","tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.oxysun.cn/tags/Linux/"}]},{"title":"Git：修改远程仓库地址","date":"2018-07-25T14:58:00.000Z","path":"git/git-remote-set-url.html","text":"Git：修改远程仓库地址。 前言有的时候，我们会遇到Git远程仓库IP发生改变，这样的改变可能是： 远程服务器挂了：远程服务器上的Git仓库被一个爱折腾的同事给删掉了，这个时候把他骂死也没用了，这要是SVN就没办法了，还好是Git，可以从本机的仓库去恢复这个远程仓库。 远程服务器迁移了，IP变了。这个时候就要用到这个命令了。 命令1git-remote - Manage set of tracked repositories（管理被追踪的仓库集合） 概要123git remote set-url [--push] &lt;name&gt; &lt;newurl&gt; [&lt;oldurl&gt;]git remote set-url --add [--push] &lt;name&gt; &lt;newurl&gt;git remote set-url --delete [--push] &lt;name&gt; &lt;url&gt; 修改远程仓库的url只是这个命令的一个功能。 记得很久以前（刚毕业的时候）从一本书中看到，中括号表示是可选项，尖括号表示为必选项，现在找不到了，上网查了查，可以参考这里。关于这个问题，接触过的很多同事都是糊里糊涂的，我觉得这样总是不好，搞计算机，应该严谨一些，做事情，还是应该寻根究底。 所以，要修改远程仓库，只需要进入代码目录： 12345678git remote -v# 查看当前的远程仓库git remote set-url origin https://where you want to put your repository to.git# 修改为想要设置的远程仓库git remote -v#验证一下 大功告成，亲个嘴（韦小宝语）。 参考https://git-scm.com/docs/git-remote。","tags":[{"name":"Git","slug":"Git","permalink":"https://www.oxysun.cn/tags/Git/"}]},{"title":"Git：revert的使用","date":"2018-07-24T14:10:00.000Z","path":"git/git-revert.html","text":"Git：revert的使用。 介绍1git-revert - Revert some existing commits // 撤销一些已经存在的提交 语法1234git revert [--[no-]edit] [-n] [-m parent-number] [-s] [-S[&lt;keyid&gt;]] &lt;commit&gt;…​git revert --continuegit revert --quitgit revert --abort 理解 Given one or more existing commits, revert the changes that the related patches introduce, and record some new commits that record them. This requires your working tree to be clean (no modifications from the HEAD commit).Note: git revert is used to record some new commits to reverse the effect of some earlier commits (often only a faulty one). If you want to throw away all uncommitted changes in your working directory, you should see git-reset[1], particularly the –hard option. If you want to extract specific files as they were in another commit, you should see git-checkout[1], specifically the git checkout – syntax. Take care with these alternatives as both will discard uncommitted changes in your working directory. 这个工具的使用场景有一点复杂，所以把原本的介绍贴在这里，下面附上翻译：给定一个或多个现有提交，还原由这些提交引入的更改，并用新的提交去记录。 这需要您的工作树是干净的（没有对于HEAD的修改）。注意：git revert用于记录一些新的提交以还原某些早期提交的效果（通常是一个错误的提交）。 如果你想丢弃工作目录中所有未提交的更改，你应该看到git-reset [1]，特别是–hard选项。 如果你想在另一个提交中提取特定文件，你应该看到git-checkout [1]，特别是git checkout &lt;commit&gt; - &lt;filename&gt;语法。 请注意这些替代方案，因为它们都会丢弃工作目录中未提交的更改。 意思是，如果你想撤销之前的一个或几个提交带来的修改，那么使用这个工具；如果想放弃工作目录的修改（并没有提交），那么你应该使用git reset；或者你只是想检出一个文件的某一个版本，那么使用git checkout。 实例摘录了官网的两个例子：实例： 撤销HEAD指针之前的第3个提交，并且生成一个新的提交。 1git revert HEAD~3 Revert the changes specified by the fourth last commit in HEAD and create a new commit with the reverted changes. 实例： 撤销从master之前第5个提交到之前第3个提交的变化（这么看来，前面是开区间，第6个没有被包含；后面是闭区间，包含了第3个）。 1git revert -n master~5..master~2 Revert the changes done by commits from the fifth last commit in master (included) to the third last commit in master (included), but do not create any commit with the reverted changes. The revert only modifies the working tree and the index. 实例： 撤销某个提交带来的修改1git revert &lt;commit&gt;","tags":[{"name":"Git","slug":"Git","permalink":"https://www.oxysun.cn/tags/Git/"}]},{"title":"区块链：教程 | 以太坊智能合约编程之菜鸟教程","date":"2018-07-23T14:37:00.000Z","path":"blockchain/mongodb-collection-aggregation-introduction.html","text":"区块链：教程 | 以太坊智能合约编程之菜鸟教程。 这篇介绍以太坊合约的文章写得很好，在查找了这么多资料，进行对比之后，感觉阅读这一篇就可以大体理解以太坊编程的原理，如果对个别的知识点还有点含糊，可以相应地去查一查，就是以这篇为主干，别的资料为辅。稍微整理了一下格式，以及修改了一些半角符号。 译注：原文首发于ConsenSys开发者博客，原作者为Eva以及ConsenSys的开发团队。如果您想要获取更多及时信息，可以访问ConsenSys首页点击左下角Newsletter订阅邮件。本文的翻译获得了ConsenSys创始人Lubin先生的授权。 有些人说以太坊太难对付，于是我们(译注：指Consensys, 下同)写了这篇文章来帮助大家学习如何利用以太坊编写智能合约和应用。这里所用到的工具，钱包，应用程序以及整个生态系统仍处于开发状态，它们将来会更好用！ 第一部分概述，讨论了关键概念，几大以太坊客户端以及写智能合约用到的编程语言。 第二部分讨论了总体的工作流程，以及目前流行的一些DApp框架和工具。 第三部分主要关于编程，我们将学习如何使用Truffle来为智能合约编写测试和构建DApp。 第一部分 概述如果你对诸如比特币以及其工作原理等密码学货币的概念完全陌生，我们建议你先看看Andreas Antonopoulos所著的Bitcoin Book的头几章，然后读一下以太坊白皮书。(译注：以太坊白皮书中文版请看 http://ethfans.org/posts/ethereum-whitepaper) 如果你觉得白皮书中的章节太晦涩，也可以直接动手来熟悉以太坊。在以太坊上做开发并不要求你理解所有那些“密码经济计算机科学”(crypto economic computer science)，而白皮书的大部分是关于以太坊想对于比特币架构上的改进。 新手教程ethereum.org提供了官方的新手入门教程，以及一个代币合约和众筹合约的教程。合约语言Solidity也有官方文档。学习智能合约的另一份不错的资料（也是我的入门资料）是dappsForBeginners，不过现在可能有些过时了。 这篇文章的目的是成为上述资料的补充，同时介绍一些基本的开发者工具，使入门以太坊，智能合约以及构建DApps(decentralized apps, 分布式应用)更加容易。我会试图按照我自己(依然是新手)的理解来解释工作流程中的每一步是在做什么，我也得到了ConsenSys酷酷的开发者们的许多帮助。 基本概念了解这些名词是一个不错的开始： 公钥加密系统。 Alice有一把公钥和一把私钥。她可以用她的私钥创建数字签名，而Bob可以用她的公钥来验证这个签名确实是用Alice的私钥创建的，也就是说，确实是Alice的签名。当你创建一个以太坊或者比特币钱包的时候，那长长的0xdf...5f地址实质上是个公钥，对应的私钥保存某处。类似于Coinbase的在线钱包可以帮你保管私钥，你也可以自己保管。如果你弄丢了存有资金的钱包的私钥，你就等于永远失去了那笔资金，因此你最好对私钥做好备份。过来人表示：通过踩坑学习到这一点是非常痛苦的… 点对点网络。 就像BitTorrent, 以太坊分布式网络中的所有节点都地位平等，没有中心服务器。(未来会有半中心化的混合型服务出现为用户和开发者提供方便，这我们后面会讲到。) 区块链。 区块链就像是一个全球唯一的帐簿，或者说是数据库，记录了网络中所有交易历史。 以太坊虚拟机(EVM)。 它让你能在以太坊上写出更强大的程序（比特币上也可以写脚本程序）。它有时也用来指以太坊区块链，负责执行智能合约以及一切。 节点。 你可以运行节点，通过它读写以太坊区块链，也即使用以太坊虚拟机。完全节点需要下载整个区块链。轻节点仍在开发中。 矿工。 挖矿，也就是处理区块链上的区块的节点。这个网页可以看到当前活跃的一部分以太坊矿工：stats.ethdev.com。 工作量证明。 矿工们总是在竞争解决一些数学问题。第一个解出答案的(算出下一个区块)将获得以太币作为奖励。然后所有节点都更新自己的区块链。所有想要算出下一个区块的矿工都有与其他节点保持同步，并且维护同一个区块链的动力，因此整个网络总是能达成共识。(注意：以太坊正计划转向没有矿工的权益证明系统(POS)，不过那不在本文讨论范围之内。) 以太币。 缩写ETH。一种你可以购买和使用的真正的数字货币。这里是可以交易以太币的其中一家交易所的走势图。在写这篇文章的时候，1个以太币价值65美分。 Gas。(汽油) 在以太坊上执行程序以及保存数据都要消耗一定量的以太币，Gas是以太币转换而成。这个机制用来保证效率。 DApp。 以太坊社区把基于智能合约的应用称为去中心化的应用程序(Decentralized App)。DApp的目标是(或者应该是)让你的智能合约有一个友好的界面，外加一些额外的东西，例如IPFS（可以存储和读取数据的去中心化网络，不是出自以太坊团队但有类似的精神)。DApp可以跑在一台能与以太坊节点交互的中心化服务器上，也可以跑在任意一个以太坊平等节点上。(花一分钟思考一下：与一般的网站不同，DApp不能跑在普通的服务器上。他们需要提交交易到区块链并且从区块链而不是中心化数据库读取重要数据。相对于典型的用户登录系统，用户有可能被表示成一个钱包地址而其它用户数据保存在本地。许多事情都会与目前的web应用有不同架构。) 如果想看看从另一个新手视角怎么理解这些概念，请读Just Enough Bitcoin for Ethereum。 以太坊客户端，智能合约语言编写和部署智能合约并不要求你运行一个以太坊节点。下面有列出基于浏览器的IDE和API。但如果是为了学习的话，还是应该运行一个以太坊节点，以便理解其中的基本组件，何况运行节点也不难。 运行以太坊节点可用的客户端以太坊有许多不同语言的客户端实现（即多种与以太坊网络交互的方法），包括C++, Go, Python, Java, Haskell等等。为什么需要这么多实现？不同的实现能满足不同的需求（例如Haskell实现的目标是可以被数学验证），能使以太坊更加安全，能丰富整个生态系统。 在写作本文时，我使用的是Go语言实现的客户端geth (go-ethereum)，其他时候还会使用一个叫testrpc的工具, 它使用了Python客户端pyethereum。后面的例子会用到这些工具。 注: 我曾经使用过C++的客户端，现在仍然在用其中的ethminer组件和geth配合挖矿，因此这些不同的组件是可以一起工作的。关于挖矿：挖矿很有趣，有点像精心照料你的室内盆栽，同时又是一种了解整个系统的方法。虽然以太币现在的价格可能连电费都补不齐，但以后谁知道呢。人们正在创造许多酷酷的DApp, 可能会让以太坊越来越流行。 交互式控制台。 客户端运行起来后，你就可以同步区块链，建立钱包，收发以太币了。使用geth的一种方式是通过Javascript控制台（JavaScript console, 类似你在chrome浏览器里面按F12出来的那个，只不过是跑在终端里）。此外还可以使用类似cURL的命令通过JSON RPC来与客户端交互。本文的目标是带大家过一边DApp开发的流程，因此这块就不多说了。但是我们应该记住这些命令行工具是调试，配置节点，以及使用钱包的利器。 在测试网络运行节点。 如果你在正式网络运行geth客户端，下载整个区块链与网络同步会需要相当时间。（你可以通过比较节点日志中打印的最后一个块号和stats.ethdev.com上列出的最新块来确定是否已经同步。) 另一个问题是在正式网络上跑智能合约需要实实在在的以太币。在测试网络上运行节点的话就没有这个问题。此时也不需要同步整个区块链，创建一个自己的私有链就勾了，对于开发来说更省时间。 testrpc。 用geth可以创建一个测试网络，另一种更快的创建测试网络的方法是使用testrpc。Testrpc可以在启动时帮你创建一堆存有资金的测试账户。它的运行速度也更快因此更适合开发和测试。你可以从testrpc起步，然后随着合约慢慢成型，转移到geth创建的测试网络上 - 启动方法很简单，只需要指定一个networkid：geth --networkid &quot;12345&quot;。这里是testrpc的代码仓库，下文我们还会再讲到它。 接下来我们来谈谈可用的编程语言，之后就可以开始真正的编程了。 写智能合约用的编程语言用Solidity就好。 要写智能合约有好几种语言可选：有点类似Javascript的Solidity, 文件扩展名是.sol和Python接近的Serpent, 文件名以.se结尾。还有类似Lisp的LLL。Serpent曾经流行过一段时间，但现在最流行而且最稳定的要算是Solidity了，因此用Solidity就好。听说你喜欢Python? 用Solidity。 solc编译器。 用Solidity写好智能合约之后，需要用solc来编译。它是一个来自C++客户端实现的组件（又一次，不同的实现产生互补），这里是安装方法。如果你不想安装solc也可以直接使用基于浏览器的编译器，例如Solidity real-time compiler或者Cosmo。后文有关编程的部分会假设你安装了solc。 注意：以太坊正处于积极的开发中，有时候新的版本之间会有不同步。确认你使用的是最新的dev版本，或者稳定版本。如果遇到问题可以去以太坊项目对应的Gitter聊天室或者forums.ethereum.org上问问其他人在用什么版本。 web3.js API。 当Solidity合约编译好并且发送到网络上之后，你可以使用以太坊的web3.js JavaScript API来调用它，构建能与之交互的web应用。 以上就是在以太坊上编写智能合约和构建与之交互的DApp所需的基本工具。 第二部分 DApp框架，工具以及工作流程DApp开发框架虽然有上文提到的工具就可以进行开发了，但是使用社区大神们创造的框架会让开发更容易。 Truffle and Embark。 是Truffle把我领进了门。在Truffle出现之前的那个夏天，我目睹了一帮有天分的学生是如何不眠不休的参加一个hackathon（编程马拉松）活动的，虽然结果相当不错，但我还是吓到了。然后Truffle出现了，帮你处理掉大量无关紧要的小事情，让你可以迅速进入写代码-编译-部署-测试-打包DApp这个流程。另外一个相似的DApp构建与测试框架是Embark。我只用过Truffle, 但是两个阵营都拥有不少DApp大神。 Meteor。 许多DApp开发者使用的另一套开发栈由web3.js和Meteor组成，Meteor是一套通用webapp开发框架（ethereum-meteor-wallet项目提供了一个很棒的入门实例，而SilentCiero正在构建大量Meteor与web3.js和DApp集成的模板）。我下载并运行过一些不错的DApp是以这种方式构造的。在11月9日至13日的以太坊开发者大会ÐΞVCON1上将有一些有趣的讨论，是关于使用这些工具构建DApp以及相关最佳实践的（会议将会在YouTube上直播）。 APIs。 BlockApps.net打算提供一套RESTful API给DApp使用以免去开发者运行本地节点的麻烦，这个中心化服务是基于以太坊Haskell实现的。这与DApp的去中心化模型背道而驰，但是在本地无法运行以太坊节点的场合非常有用，比如在你希望只有浏览器或者使用移动设备的用户也能使用你的DApp的时候。BlockApps提供了一个命令行工具bloc，注册一个开发者帐号之后就可以使用。 许多人担心需要运行以太坊节点才能使用DApp的话会把用户吓跑，其实包括BlockApps在内的许多工具都能解决这个问题。Metamask允许你在浏览器里面使用以太坊的功能而无需节点，以太坊官方提供的AlethZero或者AlethOne是正在开发中有易用界面的客户端，ConsenSys正在打造一个轻钱包LightWallet，这些工具都会让DApp的使用变得更容易。轻客户端和水平分片(sharding)也在计划和开发之中。这是一个能进化出混合架构的P2P生态系统。 智能合约集成开发环境 (IDE)IDE。 以太坊官方出品了用来编写智能合约的Mix IDE，我还没用过但会尽快一试。 基于浏览器的IDE。 Solidity real-time compiler和Cosmo都可以让你快速开始在浏览器中编写智能合约。你甚至可以让这些工具使用你的本地节点，只要让本地节点开一个端口（注意安全！这些工具站点必须可信，而且千万不要把你的全部身家放在这样一个本地节点里面！Cosmo UI上有如何使用geth做到这一点的指引）。在你的智能合约调试通过之后，可以用开发框架来给它添加用户界面和打包成DApp，这正是Truffle的工作，后面的编程章节会有详细讲解。 Ether.Camp正在开发另一个强大的企业级浏览器IDE。他们的IDE将支持沙盒测试网络，自动生成用于测试的用户界面（取代后文将展示的手动编写测试），以及一个测试交易浏览器test.ether.camp。当你的合约准备正式上线之前，使用他们的测试网络会是确保你的智能合约在一个接近真实的环境工作正常的好方法。他们也为正式网络提供了一个交易浏览器frontier.ether.camp，上面可以看到每一笔交易的细节。在本文写作时Ether.Camp的IDE还只能通过邀请注册，预计很快会正式发布。 合约和Dapp示例。 在Github上搜索DApp仓库和.sol文件可以看到进行中的有趣东西。这里有一个DApp大列表：dapps.ethercasts.com，不过其中一些项目已经过时。Ether.fund/contracts上有一些Solidity和Serpent写的合约示例，但是不清楚这些例子有没有经过测试或者正确性验证。11月12日的开发者大会ÐΞVCON1将会有一整天的DApp主题演讲。 部署智能合约的流程流程如下： 启动一个以太坊节点 (例如geth或者testrpc)。 使用solc_编译_智能合约。 =&gt; 获得二进制代码。 将编译好的合约部署到网络。（这一步会消耗以太币，还需要使用你的节点的默认地址或者指定地址来给合约签名。） =&gt; 获得合约的区块链地址和ABI（合约接口的JSON表示，包括变量，事件和可以调用的方法）。(译注：作者在这里把ABI与合约接口弄混了。ABI是合约接口的二进制表示。) 用web3.js提供的JavaScript API来调用合约。（根据调用的类型有可能会消耗以太币。） 下图详细描绘了这个流程： 你的DApp可以给用户提供一个界面先部署所需合约再使用之（如图1到4步），也可以假设合约已经部署了（常见方法），直接从使用合约（如图第6步）的界面开始。 第三部分 编程在Truffle中进行测试Truffle用来做智能合约的测试驱动开发(TDD)非常棒，我强烈推荐你在学习中使用它。它也是学习使用JavaScript Promise的一个好途径，例如deferred和异步调用。Promise机制有点像是说“做这件事，如果结果是这样，做甲，如果结果是那样，做乙… 与此同时不要在那儿干等着结果返回，行不？”。Truffle使用了包装web3.js的一个JS Promise框架Pudding（因此它为为你安装web3.js）。(译注：Promise是流行于JavaScript社区中的一种异步调用模式。它很好的封装了异步调用，使其能够灵活组合，而不会陷入callback hell.) Transaction times。 Promise对于DApp非常有用，因为交易写入以太坊区块链需要大约12-15秒的时间。即使在测试网络上看起来没有那么慢，在正式网络上却可能会要更长的时间（例如你的交易可能用光了Gas，或者被写入了一个孤儿块）。 下面让我们给一个简单的智能合约写测试用例吧。 使用Truffle首先确保你 1.安装好了solc以及 2.testrpc。（testrpc需要Python和pip。如果你是Python新手，你可能需要用virtualenv来安装，这可以将Python程序库安装在一个独立的环境中。） 接下来安装 3.Truffle（你可以使用NodeJS’s npm来安装：npm install -g truffle, -g开关可能会需要sudo）。安装好之后，在命令行中输入truffle list来验证安装成功。然后创建一个新的项目目录（我把它命名为’conference’），进入这个目录，运行truffle init。该命令会建立如下的目录结构： 现在让我们在另一个终端里通过执行testrpc来启动一个节点（你也可以用geth）： 回到之前的终端中，输入truffle deploy。这条命令会部署之前truffle init产生的模板合约到网络上。任何你可能遇到的错误信息都会在testrpc的终端或者执行truffle的终端中输出。 在开发过程中你随时可以使用truffle compile命令来确认你的合约可以正常编译（或者使用solc YourContract.sol），truffle deploy来编译和部署合约，最后是truffle test来运行智能合约的测试用例。 第一个合约下面是一个针对会议的智能合约，通过它参会者可以买票，组织者可以设置参会人数上限，以及退款策略。本文涉及的所有代码都可以在这个代码仓库找到。 contract Conference { address public organizer; mapping (address =&gt; uint) public registrantsPaid; uint public numRegistrants; uint public quota; event Deposit(address _from, uint _amount); // so you can log these events event Refund(address _to, uint _amount); function Conference() { // Constructor organizer = msg.sender; quota = 500; numRegistrants = 0; } function buyTicket() public returns (bool success) { if (numRegistrants &gt;= quota) { return false; } registrantsPaid[msg.sender] = msg.value; numRegistrants++; Deposit(msg.sender, msg.value); return true; } function changeQuota(uint newquota) public { if (msg.sender != organizer) { return; } quota = newquota; } function refundTicket(address recipient, uint amount) public { if (msg.sender != organizer) { return; } if (registrantsPaid[recipient] == amount) { address myAddress = this; if (myAddress.balance &gt;= amount) { recipient.send(amount); registrantsPaid[recipient] = 0; numRegistrants--; Refund(recipient, amount); } } } function destroy() { // so funds not locked in contract forever if (msg.sender == organizer) { suicide(organizer); // send funds to organizer } } } 接下来让我们部署这个合约。（注意：本文写作时我使用的是Mac OS X 10.10.5, solc 0.1.3+ (通过brew安装)，Truffle v0.2.3, testrpc v0.1.18 (使用venv)） 部署合约 (译注：图中步骤翻译如下：） 使用truffle部署智能合约的步骤：1. truffle init (在新目录中) =&gt; 创建truffle项目目录结构2. 编写合约代码，保存到contracts/YourContractName.sol文件。3. 把合约名字加到config/app.json的’contracts’部分。4. 启动以太坊节点（例如在另一个终端里面运行testrpc）。5. truffle deploy（在truffle项目目录中) 添加一个智能合约。 在truffle init执行后或是一个现有的项目目录中，复制粘帖上面的会议合约到contracts/Conference.sol文件中。然后打开config/app.json文件，把’Conference’加入’deploy’数组中。 启动testrpc。 在另一个终端中启动testrpc。 编译或部署。 执行truffle compile看一下合约是否能成功编译，或者直接truffle deploy一步完成编译和部署。这条命令会把部署好的合约的地址和ABI（应用接口）加入到配置文件中，这样之后的truffle test和truffle build步骤可以使用这些信息。 出错了？ 编译是否成功了？记住，错误信息即可能出现在testrpc终端也可能出现在truffle终端。 重启节点后记得重新部署！ 如果你停止了testrpc节点，下一次使用任何合约之前切记使用truffle deploy重新部署。testrpc在每一次重启之后都会回到完全空白的状态。 合约代码解读让我们从智能合约头部的变量声明开始： address public organizer; mapping (address =&gt; uint) public registrantsPaid; uint public numRegistrants; uint public quota; address。 地址类型。第一个变量是会议组织者的钱包地址。这个地址会在合约的构造函数function Conference()中被赋值。很多时候也称呼这种地址为’owner’（所有人）。 uint。 无符号整型。区块链上的存储空间很紧张，保持数据尽可能的小。 public。 这个关键字表明变量可以被合约之外的对象使用。private修饰符则表示变量只能被本合约(或者衍生合约)内的对象使用。如果你想要在测试中通过web3.js使用合约中的某个变量，记得把它声明为public。 Mapping或数组。（译注：Mapping类似Hash, Directory等数据类型，不做翻译。）在Solidity加入数组类型之前，大家都使用类似mapping (address =&gt; uint)的Mapping类型。这个声明也可以写作address registrantsPaid[]，不过Mapping的存储占用更小(smaller footprint)。这个Mapping变量会用来保存参加者（用他们的钱包地址表示）的付款数量以便在退款时使用。 关于地址。 你的客户端（比如testrpc或者geth）可以生成一个或多个账户/地址。testrpc启动时会显示10个可用地址： 第一个地址, accounts[0]，是发起调用的默认地址，如果没有特别指定的话。 组织者地址 vs 合约地址。 部署好的合约会在区块链上拥有自己的地址（与组织者拥有的是不同的地址）。在Solidity合约中可以使用this来访问这个合约地址，正如refundTicket函数所展示的：address myAddress = this; Suicide, Solidity的好东西。（译注：suicide意为’自杀’, 为Solidity提供的关键字，不做翻译。）转给合约的资金会保存于合约（地址）中。最终这些资金通过destroy函数被释放给了构造函数中设置的组织者地址。这是通过suicide(orgnizer);这行代码实现的。没有这个，资金可能被永远锁定在合约之中（reddit上有些人就遇到过），因此如果你的合约会接受资金一定要记得在合约中使用这个方法！ 如果想要模拟另一个用户或者对手方（例如你是卖家想要模拟一个买家），你可以使用可用地址数组中另外的地址。假设你要以另一个用户，accounts[1], 的身份来买票，可以通过from参数设置： conference.buyTicket({ from: accounts[1], value: some_ticket_price_integer }); 函数调用可以是交易。 改变合约状态（修改变量值，添加记录，等等）的函数调用本身也是转账交易，隐式的包含了发送人和交易价值。因此web3.js的函数调用可以通过指定{ from: __, value: __ }参数来发送以太币。在Solidity合约中，你可以通过msg.sender和msg.value来获取这些信息： function buyTicket() public { ... registrantsPaid[msg.sender] = msg.value; ... } 事件(Event)。 可选的功能。合约中的Deposit（充值）和Send（发送）事件是会被记录在以太坊虚拟机日志中的数据。它们实际上没有任何作用，但是用事件(Event)把交易记录进日志是好的做法。 好了，现在让我们给这个智能合约写一个测试，来确保它能工作。 写测试把项目目录test/中的example.js文件重命名为conference.js，文件中所有的’Example’替换为’Conference’。 contract(&apos;Conference&apos;, function(accounts) { it(&quot;should assert true&quot;, function(done) { var conference = Conference.at(Conference.deployed_address); assert.isTrue(true); done(); // stops tests at this point }); }); 在项目根目录下运行truffle test，你应该看到测试通过。在上面的测试中truffle通过Conference.deployed_address获得合约部署在区块链上的地址。 让我们写一个测试来初始化一个新的Conference，然后检查变量都正确赋值了。将conference.js中的测试代码替换为： contract(&apos;Conference&apos;, function(accounts) { it(&quot;Initial conference settings should match&quot;, function(done) { var conference = Conference.at(Conference.deployed_address); // same as previous example up to here Conference.new({ from: accounts[0] }) .then(function(conference) { conference.quota.call().then( function(quota) { assert.equal(quota, 500, &quot;Quota doesn&apos;t match!&quot;); }).then( function() { return conference.numRegistrants.call(); }).then( function(num) { assert.equal(num, 0, &quot;Registrants should be zero!&quot;); return conference.organizer.call(); }).then( function(organizer) { assert.equal(organizer, accounts[0], &quot;Owner doesn&apos;t match!&quot;); done(); // to stop these tests earlier, move this up }).catch(done); }).catch(done); }); }); 构造函数。 Conference.new({ from: accounts[0] })通过调用合约构造函数创造了一个新的Conference实例。由于不指定from时会默认使用accounts[0]，它其实可以被省略掉： Conference.new({ from: accounts[0] }); // 和Conference.new()效果相同 Promise。 代码中的那些then和return就是Promise。它们的作用写成一个深深的嵌套调用链的话会是这样： conference.numRegistrants.call().then( function(num) { assert.equal(num, 0, &quot;Registrants should be zero!&quot;); conference.organizer.call().then( function(organizer) { assert.equal(organizer, accounts[0], &quot;Owner doesn&apos;t match!&quot;); }).then( function(...)) }).then( function(...)) // Because this would get hairy... Promise减少嵌套，使代码变得扁平，允许调用异步返回，并且简化了表达“成功时做这个”和“失败时做那个”的语法。Web3.js通过回调函数实现异步调用，因此你不需要等到交易完成就可以继续执行前端代码。Truffle借助了用Promise封装web3.js的一个框架，叫做Pudding，这个框架本身又是基于Bluebird的，它支持Promise的高级特性。 call。 我们使用call来检查变量的值，例如conference.quota.call().then(...，还可以通过传参数，例如call(0), 来获取mapping在index 0处的元素。Solidity的文档说这是一种特殊的“消息调用”因为 1.不会为矿工记录和 2.不需要从钱包账户/地址发起（因此它没有被账户持有者私钥做签名）。另一方面，交易/事务(Transaction)会被矿工记录，必须来自于一个账户（也就是有签名），会被记录到区块链上。对合约中数据做的任何修改都是交易。仅仅是检查一个变量的值则不是。因此在读取变量时不要忘记加上call()！否则会发生奇怪的事情。（此外如果在读取变量是遇到问题别忘记检查它是否是public。）call()也能用于调用不是交易的函数。如果一个函数本来是交易，但你却用call()来调用，则不会在区块链上产生交易。 断言。 标准JS测试中的断言（如果你不小心拼成了复数形式’asserts’，truffle会报错，让你一头雾水），assert.equal是最常用的，其他类型的断言可以在Chai的文档中找到。 再一次运行truffle test确保一切工作正常。 测试合约函数调用现在我们测试一下改变quote变量的函数能工作。在tests/conference.js文件的contract(&#39;Conference&#39;, function(accounts) {...};)的函数体中添加如下测试用例： it(&quot;Should update quota&quot;, function(done) { var c = Conference.at(Conference.deployed_address); Conference.new({from: accounts[0] }).then( function(conference) { conference.quota.call().then( function(quota) { assert.equal(quota, 500, &quot;Quota doesn&apos;t match!&quot;); }).then( function() { return conference.changeQuota(300); }).then( function(result) { // result here is a transaction hash console.log(result); // if you were to print this out it’d be long hex - the transaction hash return conference.quota.call() }).then( function(quota) { assert.equal(quota, 300, &quot;New quota is not correct!&quot;); done(); }).catch(done); }).catch(done); }); 这里的新东西是调用changeQuota函数的那一行。console.log对于调试很有用，用它能在运行truffle的终端中输出信息。在关键点插入console.log可以查看执行到了哪一步。记得把Solidity合约中changeQuota函数被声明为public，否则你不能调用它： function changeQuota(uint newquota) public { } 测试交易现在让我们调用一个需要发起人发送资金的函数。 Wei。 以太币有很多种单位（这里有个很有用的转换器）,在合约中通常用的是Wei，最小的单位。Web3.js提供了在各单位与Wei之间互相转换的便利方法，形如web3.toWei(.05, &#39;ether&#39;)。JavaScript在处理很大的数字时有问题，因此web3.js使用了程序库BigNumber，并建议在代码各处都以Wei做单位，直到要给用户看的时候（文档。 账户余额。 Web3.js提供了许多提供方便的方法，其中另一个会在下面测试用到的是web3.eth.getBalance(some_address)。记住发送给合约的资金会由合约自己持有直到调用suicide。 在contract(Conference, function(accounts) {...};)的函数体中插入下面的测试用例。在高亮显示的方法中，测试用例让另一个用户(accounts[1])以ticketPrice的价格买了一张门票。然后它检查合约的账户余额增加了ticketPrice，以及购票用户被加入了参会者列表。 这个测试中的buyTicket是一个交易函数： it(&quot;Should let you buy a ticket&quot;, function(done) { var c = Conference.at(Conference.deployed_address); Conference.new({ from: accounts[0] }).then( function(conference) { var ticketPrice = web3.toWei(.05, &apos;ether&apos;); var initialBalance = web3.eth.getBalance(conference.address).toNumber(); conference.buyTicket({ from: accounts[1], value: ticketPrice }).then( function() { var newBalance = web3.eth.getBalance(conference.address).toNumber(); var difference = newBalance - initialBalance; assert.equal(difference, ticketPrice, &quot;Difference should be what was sent&quot;); return conference.numRegistrants.call(); }).then(function(num) { assert.equal(num, 1, &quot;there should be 1 registrant&quot;); return conference.registrantsPaid.call(accounts[1]); }).then(function(amount) { assert.equal(amount.toNumber(), ticketPrice, &quot;Sender&apos;s paid but is not listed&quot;); done(); }).catch(done); }).catch(done); }); 交易需要签名。 和之前的函数调用不同，这个调用是一个会发送资金的交易，在这种情况下购票用户(accounts[1])会用他的私钥对buyTicket()调用做签名。（在geth中用户需要在发送资金之前通过输入密码来批准这个交易或是解锁钱包的账户。） toNumber()。 有时我们需要把Solidity返回的十六进制结果转码。如果结果可能是个很大的数字可以用web3.toBigNumber(numberOrHexString)来处理因为JavaScript直接对付大数要糟。 测试包含转账的合约最后，为了完整性，我们确认一下refundTicket方法能正常工作，而且只有会议组织者能调用。下面是测试用例： it(&quot;Should issue a refund by owner only&quot;, function(done) { var c = Conference.at(Conference.deployed_address); Conference.new({ from: accounts[0] }).then( function(conference) { var ticketPrice = web3.toWei(.05, &apos;ether&apos;); var initialBalance = web3.eth.getBalance(conference.address).toNumber(); conference.buyTicket({ from: accounts[1], value: ticketPrice }).then( function() { var newBalance = web3.eth.getBalance(conference.address).toNumber(); var difference = newBalance - initialBalance; assert.equal(difference, ticketPrice, &quot;Difference should be what was sent&quot;); // same as before up to here // Now try to issue refund as second user - should fail return conference.refundTicket(accounts[1], ticketPrice, {from: accounts[1]}); }).then( function() { var balance = web3.eth.getBalance(conference.address).toNumber(); assert.equal(web3.toBigNumber(balance), ticketPrice, &quot;Balance should be unchanged&quot;); // Now try to issue refund as organizer/owner - should work return conference.refundTicket(accounts[1], ticketPrice, {from: accounts[0]}); }).then( function() { var postRefundBalance = web3.eth.getBalance(conference.address).toNumber(); assert.equal(postRefundBalance, initialBalance, &quot;Balance should be initial balance&quot;); done(); }).catch(done); }).catch(done); }); 这个测试用例覆盖的Solidity函数如下： function refundTicket(address recipient, uint amount) public returns (bool success) { if (msg.sender != organizer) { return false; } if (registrantsPaid[recipient] == amount) { address myAddress = this; if (myAddress.balance &gt;= amount) { recipient.send(amount); Refund(recipient, amount); registrantsPaid[recipient] = 0; numRegistrants--; return true; } } return false; } 合约中发送以太币。 address myAddress = this展示了如何获取该会议合约实例的地址，以变接下来检查这个地址的余额（或者直接使用this.balance）。合约通过recipient.send(amount)方法把资金发回了购票人。 交易无法返回结果给web3.js。 注意这一点！refundTicket函数会返回一个布尔值，但是这在测试中无法检查。因为这个方法是一个交易函数（会改变合约内数据或是发送以太币的调用），而web3.js得到的交易运行结果是一个交易哈希（如果打印出来是一个长长的十六进制/怪怪的字符串）。既然如此为什么还要让refundTicket返回一个值？因为在Solidity合约内可以读到这个返回值，例如当另一个合约调用refundTicket()的时候。也就是说Solidity合约可以读取交易运行的返回值，而web3.js不行。另一方面，在web3.js中你可以用事件机制（Event, 下文会解释）来监控交易运行，而合约不行。合约也无法通过call()来检查交易是否修改了合约内变量的值。 关于sendTransaction()。 当你通过web3.js调用类似buyTicket()或者refundTicket()的交易函数时（使用web3.eth.sendTransaction），交易并不会立即执行。事实上交易会被提交到矿工网络中，交易代码直到其中一位矿工产生一个新区块把交易记录进区块链之后才执行。因此你必须等交易进入区块链并且同步回本地节点之后才能验证交易执行的结果。用testrpc的时候可能看上去是实时的，因为测试环境很快，但是正式网络会比较慢。 事件/Event。 在web3.js中你应该监听事件而不是返回值。我们的智能合约示例定义了这些事件： event Deposit(address _from, uint _amount); event Refund(address _to, uint _amount); 它们在buyTicket()和refundTicket()中被触发。触发时你可以在testrpc的输出中看到日志。要监听事件，你可以使用web.js监听器(listener)。在写本文时我还不能在truffle测试中记录事件，但是在应用中没问题： Conference.new({ from: accounts[0] }).then( function(conference) { var event = conference.allEvents().watch({}, &apos;&apos;); // or use conference.Deposit() or .Refund() event.watch(function (error, result) { if (error) { console.log(&quot;Error: &quot; + error); } else { console.log(&quot;Event: &quot; + result.event); } }); // ... 过滤器/Filter。 监听所有事件可能会产生大量的轮询，作为替代可以使用过滤器。它们可以更灵活的开始或是停止对事件的监听。更多过滤器的信息可查看Solidity文档。 总的来说，使用事件和过滤器的组合比检查变量消耗的Gas更少，因而在验证正式网络的交易运行结果时非常有用。 Gas。 （译注：以太坊上的燃料，因为代码的执行必须消耗Gas。直译为汽油比较突兀，故保留原文做专有名词。）直到现在我们都没有涉及Gas的概念，因为在使用testrpc时通常不需要显式的设置。当你转向geth和正式网络时会需要。在交易函数调用中可以在{from: __, value: __, gas: __}对象内设置Gas参数。Web3.js提供了web3.eth.gasPrice调用来获取当前Gas的价格，Solidity编译器也提供了一个参数让你可以从命令行获取合约的Gas开销概要：solc --gas YouContract.sol。下面是Conference.sol的结果： 为合约创建DApp界面下面的段落会假设你没有网页开发经验。 上面编写的测试用例用到的都是在前端界面中也可以用的方法。你可以把前端代码放到app/目录中，运行truffle build之后它们会和合约配置信息一起编译输出到build/目录。在开发时可以使用truffle watch命令在app/有任何变动时自动编译输出到build/目录。然后在浏览器中刷新页面即可看到build/目录中的最新内容。（truffle serve可以启动一个基于build/目录的网页服务器。） app/目录中有一些样板文件帮助你开始： index.html会加载app.js： 因此我们只需要添加代码到app.js就可以了。 默认的app.js会在浏览器的console(控制台)中输出一条”Hello from Truffle!”的日志。在项目根目录中运行truffle watch，然后在浏览器中打开build/index.html文件，再打开浏览器的console就可以看到。（大部分浏览器例如Chrome中，单击右键 -&gt; 选择Inspect Element然后切换到Console即可。） 在app.js中，添加一个在页面加载时会运行的window.onload调用。下面的代码会确认web3.js已经正常载入并显示所有可用的账户。（注意：你的testrpc节点应该保持运行。） window.onload = function() { var accounts = web3.eth.accounts; console.log(accounts); } 看看你的浏览器console中看看是否打印出了一组账户地址。 现在你可以从tests/conference.js中复制一些代码过来（去掉只和测试有关的断言），将调用返回的结果输出到console中以确认代码能工作。下面是个例子： window.onload = function() { var accounts = web3.eth.accounts; var c = Conference.at(Conference.deployed_address); Conference.new({ from: accounts[0] }).then( function(conference) { var ticketPrice = web3.toWei(.05, &apos;ether&apos;); var initialBalance = web3.eth.getBalance(conference.address).toNumber(); console.log(&quot;The conference&apos;s initial balance is: &quot; + initialBalance); conference.buyTicket({ from: accounts[1], value: ticketPrice }).then( function() { var newBalance = web3.eth.getBalance(conference.address).toNumber(); console.log(&quot;After someone bought a ticket it&apos;s: &quot; + newBalance); return conference.refundTicket(accounts[1], ticketPrice, {from: accounts[0]}); }).then( function() { var balance = web3.eth.getBalance(conference.address).toNumber(); console.log(&quot;After a refund it&apos;s: &quot; + balance); }); }); }; 上面的代码应该输出如下： (console输出的warning信息可忽略。) 现在起你就可以使用你喜欢的任何前端工具，jQuery, ReactJS, Meteor, Ember, AngularJS，等等等等，在app/目录中构建可以与以太坊智能合约互动的DApp界面了！接下来我们给出一个极其简单基于jQuery的界面作为示例。 这里是index.html的代码，这里是app.js的代码。 通过界面测试了智能合约之后我意识到最好加入检查以保证相同的用户不能注册两次。另外由于现在是运行在testrpc节点上，速度很快，最好是切换到geth节点并确认交易过程依然能及时响应。否则的话界面上就应该显示提示信息并且在处理交易时禁用相关的按钮。 尝试geth。 如果你使用geth, 可以尝试以下面的命令启动 - 在我这儿(geth v1.2.3)工作的很好： build/bin/geth --rpc --rpcaddr=&quot;0.0.0.0&quot; --rpccorsdomain=&quot;*&quot; --mine --unlock=&apos;0 1&apos; --verbosity=5 --maxpeers=0 --minerthreads=&apos;4&apos; --networkid &apos;12345&apos; --genesis test-genesis.json 这条命令解锁了两个账户, 0和1。1. 在geth控制台启动后你可能需要输入这两个账户的密码。2. 你需要在test-genesis.json文件里面的’alloc’配置中加入你的这两个账户，并且给它们充足的资金。3. 最后，在创建合约实例时加上gas参数： Conference.new({from: accounts[0], gas: 3141592}) 然后把整个truffle deploy, truffle build流程重来一遍。 教程中的代码。 在这篇基础教程中用到的所有代码都可以在这个代码仓库中找到。 自动为合约生成界面。 SilentCicero制作了一个叫做DApp Builder的工具，可以用Solidity合约自动生成HTML, jQuery和web.js的代码。这种模式也正在被越来越多的正在开发中的开发者工具采用。 教程到此结束！ 最后一章我们仅仅学习了一套工具集，主要是Truffle和testrpc. 要知道即使在ConsenSys内部，不同的开发者使用的工具和框架也不尽相同。你可能会发现更适合你的工具，这里所说的工具可能很快也会有改进。但是本文介绍的工作流程帮助我走上了DApp开发之路。 (⊙ω⊙) wonk wonk 感谢Joseph Chow的校阅和建议，Christian Lundkvist, Daniel Novy, Jim Berry, Peter Borah和Tim Coulter帮我修改文字和debug，以及Tim Coulter, Nchinda Nchinda和Mike Goldin对DApp前端步骤图提供的帮助。","tags":[{"name":"Blockchain","slug":"Blockchain","permalink":"https://www.oxysun.cn/tags/Blockchain/"}]},{"title":"MongoDB的基本操作：删除记录（删）","date":"2018-07-23T13:29:48.000Z","path":"mongodb/mongodb-collection-delete.html","text":"MongoDB的基本操作：删除记录（删）。 方法删除记录有两个方法： 123.2版本之前db.collection.remove() // 1233.2版本之后 - db.collection.deleteMany() //删除匹配条件的多条记录 - db.collection.deleteOne() //删除匹配条件的单条记录 括号里面的参数是查询过滤器。 查询过滤器：查询过滤器用来设定查询条件。 格式&lt;field&gt;:&lt;value&gt;。 12345&#123; &lt;field1&gt;: &lt;value1&gt;, &lt;field2&gt;: &#123; &lt;operator&gt;: &lt;value&gt; &#125;, ...&#125; 实例实例：删除前文test数据库中所有记录。 1db.test.deleteMany(&#123;&#125;); {}表示没有约束条件。 实例：删除前文test数据库中_id为5abb3b5bce69c048be080199的记录。 1db.test.deleteMany(&#123;_id: ObjectId(&quot;5abb3b5bce69c048be080199&quot;)&#125;); 笔记整理到这里，发现之前的记录有点问题，因为对MongoDB的官网的结构没有完全搞清楚，所以，之前的基本操作更多偏向于参考手册的层面，可能还需要修改和调整一下。 参考：https://docs.mongodb.com/manual/tutorial/remove-documents/。","tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"https://www.oxysun.cn/tags/MongoDB/"}]},{"title":"JS：逻辑操作符“||”、“&&”和“!”","date":"2018-07-19T15:00:00.000Z","path":"js/js-logical-operator.html","text":"JS：逻辑操作符“||”、“&amp;&amp;”和“!”。 Operator Usage Description Logical AND (&amp;&amp;) expr1 &amp;&amp; expr2 Returns expr1 if it can be converted to false; otherwise, returns expr2. Thus, when used with Boolean values, &amp;&amp; returns true if both operands are true; otherwise, returns false. Logical OR (&#124;&#124;) expr1 &#124;&#124; expr2 Returns expr1 if it can be converted to true; otherwise, returns expr2. Thus, when used with Boolean values, &#124;&#124; returns true if either operand is true. Logical NOT (!) !expr Returns false if its single operand can be converted to true; otherwise, returns true. 翻译一下： 操作符 用法 描述 逻辑和 (&amp;&amp;) expr1 &amp;&amp; expr2 如果expr1可以被转换为false，那么返回expr1，否则，返回expr2。 如果使用的是布尔值，那么仅当两个操作数都为真时，返回true；否则，返回false 逻辑或 (&#124;&#124;) expr1 &#124;&#124; expr2 如果expr1可以被转换为true，返回expr1；否则，返回expr2。如果是布尔值，则两个操作数中有一个位true就返回true。 逻辑非 (!) !expr 如果这个操作数可以转换为true，返回false，否则，返回true 以下这些表达式都可以转换为false： null; NaN; 0; empty string (“” or ‘’); undefined. 这样就比较清楚了。 需要注意的是：操作符有一个优先级的规定，可以参考：https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Operator_Precedence。 参考：https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Logical_Operators。","tags":[{"name":"JS,逻辑操作符","slug":"JS-逻辑操作符","permalink":"https://www.oxysun.cn/tags/JS-逻辑操作符/"}]},{"title":"程序员晋升之路：生存意识、服务意识--IT老兵的心得","date":"2018-07-18T15:15:33.000Z","path":"thinking in programmer life/full-stack-programmer.html","text":"前言 这篇文章原载于新浪博客，写于2017-06-0623:15:33，现在因为建立了自己的博客，所以迁过来，也转载在CSDN上，同时又加上“时过境迁”，又会有一些新的思考，所以修改一下，修改的地方以备注的形式展示出来，可以看出一些心态的不同来。 有一个程序员，学过前端、学过iOS，或者这么说，他喜欢研究技术，而且能把所研究的技术都搞得明明白白，但是他做项目，从来不排期，不汇报，也从来不怎么理会产品设计，结果他什么好的产品都做不出来。 这些是在厦门遇到了一个程序员所发出的感想，到了今时今日，据我了解，他还是什么都没有做出来 做不出好的产品来，是一个好的程序员吗？ 技术都会过时的，最新的技术也不见得是最好的技术，那么技术人员的使命是什么呢？ 掌握了那么复杂的C++就算是好的程序员了吗？ 实际上，很多年了，C++程序员都缺乏用武之地了—-直到今天的区块链的火热，才又唤起市场对C++程序员的需求。 或者说，现在所鼓吹的全栈，你成为全栈了，就是好的程序员了吗？ 我觉得都不是。 你用你的能力，掌握了技术，能够很好服务于你的公司，服务于社会，这才是好的程序员。 技术是为人类服务的，脱离了服务，再尖端的技术又有什么用呢？脱离了服务，掌握了再尖端的技术的程序员，又有什么用呢？ 要使用你的技术，去提供服务，换取你的合理报酬，这就是生存意识。 掌握社会服务所需要的，或者是将要需要的技术，去提供服务，换取更好的报酬，这就是生存意识。 固守于一门很复杂的语言，为自己掌握了它而别人没有掌握而沾沾自喜，却不思考这门语言对于提供服务的价值和意义，这就已经完全走偏了，惑于技巧的层面，而忽略了根本的初衷，我们不是为了学技术而学技术的，技术也从来不是为了让你学而产生的。如果一门技术，已经不能很好地服务于社会，那怕它再难，学习起来再有挑战性，对你来说只能是满足征服的快乐，而不是满足你谋生、立业的人生目标。 放下心中自己围起来的那道技术的篱笆，不拘一格地去掌握那些需要你掌握的技术，做出好的产品来提供你的服务。 不要太在意这个技术是你新学的，也许掌握的还没有那么扎实，也许写出来的代码还没有那么漂亮，这些都会慢慢变好的，因为你写的代码，做出的产品有人在使用，这就要比那些写的很漂亮，但是没人用，只能束之高阁的代码要强太多了。代码不被使用，再漂亮，也缺乏生命力。 代码也是有生命的，这是我的感觉，所以，我们需要好好去维护她，不断去调整她。","tags":[]},{"title":"Git：checkout的用法（1）","date":"2018-07-17T15:00:00.000Z","path":"git/git-checkout-1.html","text":"Git的checkout的用法。 初衷checkout是Git最常用的命令之一，但又是有些复杂的命令，总会感觉有些用不明白，用不明白的原因应该是没有深度地、全面地理解一下，所以要对它好好整理一下。 介绍checkout在CVS和SVN中都是检出的意思，从版本库检出一个版本，在Git中就不是这么简单了。手册上是这样介绍的： 1git-checkout - Switch branches or restore working tree files 在Git里面，checkout用于切换分支或者恢复工作树的文件。 实例问题：线上分支出现了一个问题，急需要修复（可以参看Git Flow一章）。步骤： 需要创建一个hotfix分支，参考语法：1git checkout -b|-B &lt;new_branch&gt; [&lt;start point&gt;] 实际语句：1git checkout -b hotfix-1.2.1 master 这个时候分支是本地分支，并没有提交到服务器上去，如果这个分支已经被创建，这个命令会失败，这个时候，如果想要重置这个分支，需要使用-B参数。 查看分支：git branch -av 进行修改工作 …… 问题：本地发生了一些修改，但是想放弃这些修改，回退到获取这个版本初始时的状态。参考语法：1git checkout [&lt;tree-ish&gt;] [--] &lt;pathspec&gt;…​ 实际语句：123git checkout 26a2e80 # 26a2e80 是一个commit号，这个命令会把index区域和工作区域的内容都更新git checkout -- README # README是想恢复的文件名，恢复成index区域里面的内容，为什么要加“--”呢，这个是为了告诉Git，这是一个文件而不是一个分支Git checkout . # 从index区域恢复所有文件 这个命令很灵活，既可以带一个commit号，又可以带着一个路径，tree-ish 可以理解成一个commit号，就是恢复到某一个commit号，index就是暂存区，这里要理解Git的三个区域，如果这个还不明白，那需要单开一篇文章去讲了。 以上是checkout比较常用的两个用法，逐步整理其他的用法。 参考：https://git-scm.com/docs/git-checkout。https://stackoverflow.com/questions/14460595/git-checkout-with-dot。","tags":[{"name":"Git","slug":"Git","permalink":"https://www.oxysun.cn/tags/Git/"}]},{"title":"Linux下shell命令用法及常见用例：top","date":"2018-07-13T14:20:23.000Z","path":"linux/shell-command-top.html","text":"top命令可以实时动态地查看系统的整体运行情况，是一个综合了多方信息监测系统性能和运行信息的使用工具。top命令提供了互动式的界面，用热键管理。这个命令是一个非常重要和常用的命令，但是同时也有点复杂，参数较多，怎么能够掌握好呢？用了这么多年，也都一直没有用好。老老实实读一遍手册，总体了解一下都有什么才好去做整理，有的时候可能连它都有什么功能都不知道。 命令格式top [选项] 命令功能top命令用来显示Linux的处理器活动和内核实时管理的任务。它会显示正在使用的处理器和内存以及运行进程等其他信息。 命令选项 -b：以批处理模式操作。 -c：显示完整的命令。 -d：屏幕刷新间隔时间。 -I：忽略失效过程。 -s：保密模式。 -S：累积模式。 -i&lt;时间&gt;：设置间隔时间。 -u&lt;用户名&gt;：指定用户名。 -p&lt;进程号&gt;：指定进程。 -n&lt;次数&gt;：循环显示的次数。 top交互命令在top命令执行过程中可以使用的一些交互命令。这些命令都是单字母的，如果在命令行中使用了-s选项， 其中一些命令可能会被屏蔽。 h：显示帮助画面，给出一些简短的命令总结说明。 k：终止一个进程。 i：忽略闲置和僵死进程，这是一个开关式命令。 q：退出程序。 r：重新安排一个进程的优先级别。 S：切换到累计模式。 s：改变两次刷新之间的延迟时间（单位为s），如果有小数，就换算成ms。输入0值则系统将不断刷新，默认值是5s。 f或者F：从当前显示中添加或者删除项目。 o或者O：改变显示项目的顺序。 l：切换显示平均负载和启动时间信息。 m：切换显示内存信息。 t：切换显示进程和CPU状态信息。 c：显示进程启动时的完整路径和程序名。 M：根据驻留内存大小进行排序。 P：根据CPU使用百分比大小进行排序。 T：根据时间/累计时间进行排序。 w：将当前设置写入~/.toprc文件中。 界面解释12345top - 21:52:52 up 247 days, 6:23, 2 users, load average: 0.09, 0.12, 0.13Tasks: 126 total, 1 running, 125 sleeping, 0 stopped, 0 zombie%Cpu(s): 4.0 us, 2.3 sy, 0.0 ni, 93.7 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 3881808 total, 153396 free, 3577588 used, 150824 buff/cacheKiB Swap: 4063228 total, 1206484 free, 2856744 used. 86344 avail Mem 统计信息区前五行是系统整体的统计信息。系统运行时间和平均负载第一行是任务队列信息，同uptime命令的执行结果，可以使用l命令切换uptime的显示。其内容如下： 21:52:52：当前时间。 up 247 days, 6:23：系统运行时间。 2 users：当前登录用户数。 load average: 0.09, 0.12, 0.13：系统负载，即任务队列平均长度。分别为1、5、15min前到现在平均值。 进程第二行为进程信息。内容如下： 126 total：进程总数[键入H可查看线程数]。 1 running：正在运行的进程。 125 sleeping：睡眠进程。 0 stopped：停止的进程。 0 zombie：僵尸进程数。 CPU状态第三行为CPU状态信息，当有多个CPU时，这些内容可能会超过两行。内容如下： us, user：运行(未调整优先级的) 用户进程的CPU百分比。 sy，system：运行内核进程的CPU百分比。 ni，niced：运行已调整优先级的用户进程的CPU百分比。 wa，IO wait：用于等待IO完成的CPU百分比。 hi：处理硬件中断的CPU百分比。 si：处理软件中断的CPU百分比。 st：这个虚拟机被hypervisor偷去的CPU百分比。（译注：如果当前处于一个hypervisor下的vm，实际上hypervisor也是要消耗一部分CPU处理时间的）。 内存使用倒数第2、3行为内存相关信息，内存显示可以用m命令切换： KiB Mem: 3881808 total, 153396 free：分别是物理内存总量、空闲内存总量。 3577588 used, 150824 buff/cache：使用物理内存总量、用作内核缓存内存量。 KiB Swap: 4063228 total, 1206484 free：分别是交换分区总量、使用交换分区剩余量。 2856744 used. 86344 avail Mem：可用来启动应用的内存（有些复杂，以后解释，恶意参考这里）。 字段/列最后一行则是进程相关的资源占用信息： PID：进程的ID，进程的唯一标识符。 USER：进程所有者的实际用户名。 PR：进程的优先级别，范围0-39，越小越优先被执行。 NI：nice值。范围-20-19，负值表示高优先级，正值表示低优先级。在top里，PR-NI=20，默认启动一个进程，nice是0。 VIRT：进程占用的虚拟内存。 RES：进程占用的物理内存。 SHR：进程使用的共享内存。 S：进程的状态。 D：表示不可终端的睡眠状态。 R：表示正在运行。 S：表示休眠。 T：表示作业控制信号下已停止。 t：表示在调试状态的停止。 Z：表示僵死状态。 %CPU：自从上一次更新到现在任务所使用的CPU使用率。 %MEM：进程使用的物理内存和总内存的百分比。 TIME+：该进程启动后占用的总的CPU时间，即占用CPU使用时间的累加值，精确到百分之一秒。 COMMAND：进程启动命令名称。 交互命令实例实例：h：帮助描述：在top状态下，按h键或者?键显示交互命令的帮助菜单。输出： 123456789101112131415161718192021222324Help for Interactive Commands - procps-ng version 3.3.10Window 1:Def: Cumulative mode Off. System: Delay 3.0 secs; Secure mode Off. Z,B,E,e Global: &apos;Z&apos; colors; &apos;B&apos; bold; &apos;E&apos;/&apos;e&apos; summary/task memory scale l,t,m Toggle Summary: &apos;l&apos; load avg; &apos;t&apos; task/cpu stats; &apos;m&apos; memory info 0,1,2,3,I Toggle: &apos;0&apos; zeros; &apos;1/2/3&apos; cpus or numa node views; &apos;I&apos; Irix mode f,F,X Fields: &apos;f&apos;/&apos;F&apos; add/remove/order/sort; &apos;X&apos; increase fixed-width L,&amp;,&lt;,&gt; . Locate: &apos;L&apos;/&apos;&amp;&apos; find/again; Move sort column: &apos;&lt;&apos;/&apos;&gt;&apos; left/right R,H,V,J . Toggle: &apos;R&apos; Sort; &apos;H&apos; Threads; &apos;V&apos; Forest view; &apos;J&apos; Num justify c,i,S,j . Toggle: &apos;c&apos; Cmd name/line; &apos;i&apos; Idle; &apos;S&apos; Time; &apos;j&apos; Str justify x,y . Toggle highlights: &apos;x&apos; sort field; &apos;y&apos; running tasks z,b . Toggle: &apos;z&apos; color/mono; &apos;b&apos; bold/reverse (only if &apos;x&apos; or &apos;y&apos;) u,U,o,O . Filter by: &apos;u&apos;/&apos;U&apos; effective/any user; &apos;o&apos;/&apos;O&apos; other criteria n,#,^O . Set: &apos;n&apos;/&apos;#&apos; max tasks displayed; Show: Ctrl+&apos;O&apos; other filter(s) C,... . Toggle scroll coordinates msg for: up,down,left,right,home,end k,r Manipulate tasks: &apos;k&apos; kill; &apos;r&apos; renice d or s Set update interval W,Y Write configuration file &apos;W&apos;; Inspect other output &apos;Y&apos; q Quit ( commands shown with &apos;.&apos; require a visible task display window ) Press &apos;h&apos; or &apos;?&apos; for help with Windows,Type &apos;q&apos; or &lt;Esc&gt; to continue 实例：显示各个CPU负载描述：在top状态下，按下“1”，可以显示每个CPU的负载情况。 12345678top - 22:30:09 up 247 days, 7:00, 2 users, load average: 0.16, 0.14, 0.14Tasks: 126 total, 1 running, 125 sleeping, 0 stopped, 0 zombie%Cpu0 : 0.3 us, 0.3 sy, 0.0 ni, 99.3 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu1 : 0.3 us, 0.0 sy, 0.0 ni, 99.7 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu2 : 0.3 us, 0.0 sy, 0.0 ni, 99.7 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu3 : 0.3 us, 0.3 sy, 0.0 ni, 99.3 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 3881808 total, 141164 free, 3578540 used, 162104 buff/cacheKiB Swap: 4063228 total, 1206756 free, 2856472 used. 79768 avail Mem 实例：手动刷新描述：在top状态下，按空格或者回车进行手动刷新。top命令默认在一个特定间隔（3秒）后刷新显示。 实例：A：切换交替显示模式 描述：在top状态下，按A键，可以在全屏和交替模式间切换。在交替模式下会显示4个窗口。 Def（默认字段组） Job（任务字段组） Mem（内存字段组） Usr（用户字段组） 这四组字段共有一个独立的可配置的概括区域和它自己的可配置任务区域。4个窗口中只有一个窗口是当前窗口。当前窗口的名称显示在左上方。只有当前窗口才会接受你键盘交互命令。可以用a和w在4个窗口间切换，a移到后一个窗口，w移到前一个窗口。用g命令可以输入一个数字来选择当前窗口。 实例：B：粗体显示描述：在top状态下，按B键，会将一些重要信息会以加粗字体显示。输出： 实例：d或s：设置显示的刷新间隔描述：在top状态下，按d键或者s键，设置显示的刷新间隔为1秒。输出： 实例：f：字段管理描述：在top状态下，按f键进入字段管理界面。d键选择要显示的字段，用*标记的是已选择的。上下光标键在字段内导航，左光标键可以选择字段，右光标键进入排序状态，此时按上下光标键可以进行上下移动，回车确认。s键设置当前排序的字段，q或Esc键退出。输出： 实例：R：反向排序描述：在top状态下，按R键切换反向/常规排序。 实例：c：切换显示命令名称和完整命令行描述：在top状态下，按c键，切换是否显示进程启动时的完整路径和程序名。也可以使用如下命令行。命令：top -c输出： 实例：i：空闲任务描述：在top状态下，按i键，切换显示空闲任务。输出：不显示空闲任务： 实例：V：树视图描述：在top状态下，按V键，切换树视图。输出： 实例：z：切换彩色显示描述：在top状态下，按z键，切换彩色，即打开或关闭彩色显示。输出： 实例：Z：改变配色描述：在top状态下，按Z键，显示一个改变top命令的输出颜色的屏幕。可以为8个任务区域选择8种颜色。输出：设置修改：显示效果： 实例：按照内存使用大小排序描述：在top状态下，按shift+m，可以按照内存使用大小排序进程。输出： 实例：x、y：切换高亮信息描述：在top状态下，按x键将排序字段高亮显示（纵列）；按y键将运行进程高亮显示（横行）。输出： 实例：u：特定用户的进程描述：在top状态下，按u键将会提示输入用户名，输入首显示特定用户的进程。空白将会显示全部用户。输出： 实例：n或#：任务的数量描述：在top状态下，按n键或者#键可以设置最大显示的任务数量。输出： 实例：k：结束任务描述：在top状态下，按k键输入PID后，发送信号给任务（通常是结束任务）。输出： 实例：r：重新设置优先级描述：在top状态下，按r键输入-20~19范围中的数字后，重新设置一个任务的调度优先级（nice值）。输出： 命令行实例实例：-p：监控特定的PID描述：-p选项监控指定的PID。PID的值为0将被作为top命令自身的PID。命令：top -p 0 实例：-u或-U: 用户名或者UID描述：可以用这些选项浏览特定用户的进程。用户名或者UID可以在选项中指定。-p、-u和-U选项是互斥的，同时只可以使用这其中一个选项。试图组合使用这些选项时，会得到一个错误:命令：top -p 1248 -u root输出： 实例：-b：批处理模式描述：-b选项以批处理模式启动top命令，在文件中保存输出时是很有用的。 实例：-c：命令/程序名 触发:描述：显示进程启动时的完整路径和程序名。 实例：-d：设置延迟间隔描述：设置top的显示间隔(以秒计)。命令：top -d 1 实例：-i：切换显示空闲进程命令：top -i 实例：-n：特定重复次数后退出描述：top输出保持刷新，直到按q键或者到达指定次数。下面的命令将在10次重复之后自动退出。命令：top -n 10","tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.oxysun.cn/tags/Linux/"}]},{"title":"Git：Git merge的--ff和--no-ff","date":"2018-07-12T14:07:00.000Z","path":"git/git-git-merge-ff-no-ff.html","text":"Git：Git merge的–ff和–no-ff。 前言Git merge最容易糊涂的地方就是这个--ff参数和--no-ff 参数，通过本文，把这个整理清楚。 其实官网讲的非常清楚，不过可能因为是英文的，所以大家阅读起来会有一些障碍。（PS：其实还是应该逐步逐步提高自己阅读英文文档的能力，想达到一个更高的高度，是需要客服自己本身很多的弱点的） 实例假设合并前的分支是这样，这个一个非常常见的场景，如果不明白，可以参考另外一篇文章Git Flow工作流：这是一个很常见的用例，功能开发分支是iss53，在开发新功能，master分支是线上分支，出现了问题，开辟了hotfix分支进行修复，修复完成，进行合并，需要把hotfix合并回master。 123456$ git checkout master$ git merge hotfixUpdating f42c576..3a0874cFast-forward index.html | 2 ++ 1 file changed, 2 insertions(+) 步骤如下： 切换回master分支。 将hotfix分支合并会master分支。然后看到了Fast-forward 的字样，这个词组的意思就是快进，播放电影的时候，可以注意一下，快进按钮上面就是这个词组。那么实际变成了什么样呢？仅仅是master指针指向了这个提交C4。这样是一种比较快的合并方式，轻量级，简单。这个时候，我们往往会删掉hotfix分支，因为它的历史作用已经结束，这个时候，我们的iss53这个功能又向前开发，进行了一次提交，到了C5，那么变成了这样：然后，我们要把iss53 这个分支合并回master，就变成了这样：这个时候生成了一个新的commit号，这种提交就不是fast-forward（这个时候也无法生成fast-forward提交，因为要将两个版本的内容进行合并，只有在没有需要合并内容的时候，会有这个fast-forward 方式的提交）。如果我们对第一次合并，使用了--no-ff参数，那么也会产生这样的结果，生成一个新的提交，实际上等于是对C4 进行一次复制，创建一个新的commit，这就是--no-ff的作用。 参考：https://git-scm.com/book/en/v2/Git-Branching-Basic-Branching-and-Merging，这里讲了原理。参考：https://git-scm.com/docs/git-merge，这里是参考。","tags":[{"name":"Git","slug":"Git","permalink":"https://www.oxysun.cn/tags/Git/"}]},{"title":"Ubuntu：新增和删除用户","date":"2018-07-12T03:15:00.000Z","path":"linux/ubuntu-user-add-delete.html","text":"Ubuntu：新增和删除用户，修改用户组信息。参考：https://www.digitalocean.com/community/tutorials/how-to-add-and-delete-users-on-ubuntu-16-04#how-to-delete-a-user。 Linux上root用户是权力最大的用户，但是也非常危险，处于安全考虑，增加个人用户是必要的方法，下文讲了讲在Ubuntu上如何新增和删除用户。 创建用户实例： root用户新增用户chenming1234567891011121314151617root@iZhp3fz3iqsadyes2s8ay8Z:~# adduser chenmingAdding user `chenming&apos; ...Adding new group `chenming&apos; (1000) ...Adding new user `chenming&apos; (1000) with group `chenming&apos; ...Creating home directory `/home/chenming&apos; ...Copying files from `/etc/skel&apos; ...Enter new UNIX password: Retype new UNIX password: passwd: password updated successfullyChanging the user information for chenmingEnter the new value, or press ENTER for the default Full Name []: Room Number []: Work Phone []: Home Phone []: Other []: Is the information correct? [Y/n] y 首先创建了一个新的用户组chenming。在这个组内新建了用户chenming。要求你输入密码。要求输入一些其他信息，可以按回车略过。最后按下y对以上信息进行确认。 实例：非root用户新增用户 1$sudo adduser chenming 给用户授权实例：把chenming加到sudo组里面 12root@iZhp3fz3iqsadyes2s8ay8Z:~# groups chenmingchenming : chenming 可以看到，chenming只在chenming的组里面（前面是用户名，冒号后面是组名）。在这个组里面，可能很多命令你都不能执行。 1root@iZhp3fz3iqsadyes2s8ay8Z:~# usermod -aG sudo chenming 再来看一下： 12root@iZhp3fz3iqsadyes2s8ay8Z:~# groups chenmingchenming : chenming sudo look，进入了sudo组了，这下你可以臭屁了。 还有一种方法可以加入sodu组。如果是root用户。1root@iZhp3fz3iqsadyes2s8ay8Z:~# visudo 这个时候会打开一个文本编辑器，去编辑/etc/sudoer这个文件，可能是vim，也可能是nano。找到： 12# User privilege specificationroot ALL=(ALL:ALL) ALL 在下面加入： 1chenming ALL=(ALL:ALL) ALL 保存（vim下是:x，nano下是ctrl+x），退出，这样chenming这个用户就加入了sudo组。 删除用户仅仅删除用户：1234root@iZhp3fz3iqsadyes2s8ay8Z:~# deluser chenmingRemoving user `chenming&apos; ...Warning: group `chenming&apos; has no more members.Done. 将用户的目录也删除：1root@iZhp3fz3iqsadyes2s8ay8Z:~# deluser --remove-home chenming 但这个时候，这个已经被删除的用户还是在sudo组里面。参照上面的过程，使用visudo命令，删掉增加的那一行即可。","tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.oxysun.cn/tags/Linux/"}]},{"title":"JS：NPM依赖包版本号脱字符\"^\"","date":"2018-07-11T15:07:00.000Z","path":"js/js-npm-symbol-caret.html","text":"JS：NPM依赖包版本号脱字符”^”。 参考官网：https://github.com/npm/node-semver#functions。 Caret Ranges ^1.2.3 ^0.2.5 ^0.0.4Allows changes that do not modify the left-most non-zero digit in the [major, minor, patch] tuple. In other words, this allows patch and minor updates for versions 1.0.0 and above, patch updates for versions 0.X &gt;=0.1.0, and no updates for versions 0.0.X.Many authors treat a 0.x version as if the x were the major “breaking-change” indicator. 大概意思是：允许的改变不能发生在最左侧非零的数字上，NPM采用的是3元组的版本控制，[major，minor，patch]。换句话说，对于版本1.0.0，允许变更的是minor和patch，对于0.X的，patch可以变更，而对于0.0.X，啥都不能变了。这里说的改变是说，npm在自动安装时去获取的这个包的版本，如果使用了脱字符或者波浪线等符号，它可以去获取的版本就是在一个范围之内，而不是固定的，这两个符号就是去约束这个范围的。这里还涉及一个版本锁定的概念，涉及yarn的一些理念，回头再讨论。 Caret ranges are ideal when an author may make breaking changes between 0.2.4 and 0.3.0 releases, which is a common practice. However, it presumes that there will not be breaking changes between 0.2.4 and 0.2.5. It allows for changes that are presumed to be additive (but non-breaking), according to commonly observed practices. “^”这个符号叫做脱字符（caret），这好像是原来打字机的一个功能，现在叫这个名字感觉是有些陌生的。以下是一些例子，感觉也没有太多可讲的。 ^1.2.3 := &gt;=1.2.3 &lt;2.0.0（解释：如果是^1.2.3，那么获取包的范围就是版本&gt;=1.2.3，并且&lt;2.0.0。） ^0.2.3 := &gt;=0.2.3 &lt;0.3.0 ^0.0.3 := &gt;=0.0.3 &lt;0.0.4 ^1.2.3-beta.2 := &gt;=1.2.3-beta.2 &lt;2.0.0 Note that prereleases in the 1.2.3 version will be allowed, if they are greater than or equal to beta.2. So, 1.2.3-beta.4 would be allowed, but 1.2.4-beta.2 would not, because it is a prerelease of a different [major, minor, patch] tuple. ^0.0.3-beta := &gt;=0.0.3-beta &lt;0.0.4 Note that prereleases in the 0.0.3 version only will be allowed, if they are greater than or equal to beta. So, 0.0.3-pr.2 would be allowed. When parsing caret ranges, a missing patch value desugars to the number 0, but will allow flexibility within that value, even if the major and minor versions are both 0. ^1.2.x := &gt;=1.2.0 &lt;2.0.0 ^0.0.x := &gt;=0.0.0 &lt;0.1.0 ^0.0 := &gt;=0.0.0 &lt;0.1.0 A missing minor and patch values will desugar to zero, but also allow flexibility within those values, even if the major version is zero. ^1.x := &gt;=1.0.0 &lt;2.0.0 ^0.x := &gt;=0.0.0 &lt;1.0.0","tags":[]},{"title":"JS：NPM依赖包版本号波浪字符\"~\"","date":"2018-07-11T15:07:00.000Z","path":"js/js-npm-symbol-tilde.html","text":"JS：NPM依赖包版本号波浪字符”~”。 参考官网：https://github.com/npm/node-semver#functions。 Tilde Ranges ~1.2.3 ~1.2 ~1Allows patch-level changes if a minor version is specified on the comparator. Allows minor-level changes if not. 如果minor被指定，则允许patch被改变；如果没有，允许minor被改变。（个别知识需要参考前面的帖子） ~1.2.3 := &gt;=1.2.3 &lt;1.(2+1).0 := &gt;=1.2.3 &lt;1.3.0~1.2 := &gt;=1.2.0 &lt;1.(2+1).0 := &gt;=1.2.0 &lt;1.3.0 (Same as 1.2.x)~1 := &gt;=1.0.0 &lt;(1+1).0.0 := &gt;=1.0.0 &lt;2.0.0 (Same as 1.x)~0.2.3 := &gt;=0.2.3 &lt;0.(2+1).0 := &gt;=0.2.3 &lt;0.3.0~0.2 := &gt;=0.2.0 &lt;0.(2+1).0 := &gt;=0.2.0 &lt;0.3.0 (Same as 0.2.x)~0 := &gt;=0.0.0 &lt;(0+1).0.0 := &gt;=0.0.0 &lt;1.0.0 (Same as 0.x)~1.2.3-beta.2 := &gt;=1.2.3-beta.2 &lt;1.3.0 Note that prereleases in the 1.2.3 version will be allowed, if they are greater than or equal to beta.2. So, 1.2.3-beta.4 would be allowed, but 1.2.4-beta.2 would not, because it is a prerelease of a different [major, minor, patch] tuple.","tags":[]},{"title":"Linux下shell命令用法及常见用例：tar","date":"2018-07-10T15:06:00.000Z","path":"linux/shell-command-tar.html","text":"tar命令用来归档多个文件或目录到单个归档文件中，并且归档文件可以进一步使用gzip或者bzip2等技术进行压缩。 命令格式tar [OPTION...] [FILE]... 命令功能Tar（Tape ARchive，磁带归档的缩写，最初设计用于将文件打包到磁带上，现在大都使用它来实现备份某个分区或者某些重要的目录）是类Unix系统中使用最广泛的命令，用于归档多个文件或目录到单个归档文件中，并且归档文件可以进一步使用gzip或者bzip2等技术进行压缩，还能保留其文件权限。换言之，tar命令也可以用于备份：先是归档多个文件和目录到一个单独的tar文件或归档文件，然后在需要之时将tar文件中的文件和目录释放出来。 命令选项 选项 含义 -A或–catenate 新增文件到以存在的备份文件 -B 设置区块大小 -c或–create 建立新的备份文件 -C&lt;目录&gt; 这个选项用在解压缩，若要在特定目录解压缩，可以使用这个选项 -d 记录文件的差别 -x或–extract或–get 从备份文件中还原文件 -t或–list 列出备份文件的内容 -z或–gzip或–ungzip 通过gzip指令处理备份文件 -Z或–compress或–uncompress 通过compress指令处理备份文件 -f&lt;备份文件&gt;或–file=&lt;备份文件&gt; 指定备份文件 -v或–verbose 显示指令执行过程 -r 添加文件到已经压缩的文件 -u 添加改变了和现有的文件到已经存在的压缩文件 -j 支持bzip2解压文件 -v 显示操作过程 -l 文件系统边界设置 -k 保留原有文件不覆盖 -m 保留文件不被覆盖 -w 确认压缩文件的正确性 -p或–same-permissions 用原来的文件权限还原文件 -P或–absolute-names 文件名使用绝对名称，不移除文件名称前的“/”号 -N &lt;日期格式&gt;或–newer=&lt;日期时间&gt;只将较指定日期更新的文件保存到备份文件里 –exclude=&lt;范本样式&gt; 排除符合范本样式的文件 什么是“文件压缩”？我们知道，在计算机系统中文件的内容是信息，信息实际上就是一个由值0和值1组成的位（又称为比特）序列，8个位被组织成一组，称为字节。一般来说，一个字节的8位是没有被全部利用起来的，这些没有被利用的位占据了一个文件的大部分空间，而“文件压缩”就是利用复杂的计算方式，将这些没有利用的空间腾出来，以让文件占用的空间变小。 简单来说，「压缩」就是把文件中没有完全填满的空间填满。压缩过的文件不能直接被操作系统所使用，因此，「解压缩」就是指把文件「还原」为未压缩之前的模样。压缩前与压缩后的文件所占用的磁盘空间大小之比就是「压缩比」。 常见的压缩格式Linux 中常见的压缩格式有： 123456*.Z：compress 程序压缩的文件。*.gz：gzip 程序压缩的文件。*.bz2：bzip2 程序压缩的文件。*.tar：tar 程序打包的数据，没有被压缩过。*.tar.gz（简写为 .tgz）：tar 程序打包的数据，经过 gzip 的压缩。*.tar.bz2（简写为 .tbz2）：tar 程序打包的数据，经过 bzip2 的压缩。 上面的压缩格式中，主要是gzip和bzip2两个压缩命令，它们是GNU计划的中的一部分，在此之前是compress命令，但它已经不再流行了。bzip2比gzip的压缩比很好，不过bzip2通常只能针对一个文件来压缩和解压缩。如果是这样的话，压缩整个开发环境目录就太繁琐了。 因此tar命令就出现了，tar不是一个 “压缩命令”，而是一个“打包命令”。也就是说，tar可以把很多文件「打包」成一个文件，甚至连目录也可以进行打包。一开始tar命令的确是不支持压缩的功能，后来GNU计划为了提供给使用者更方便并且更加强大的压缩与打包功能，就把整个tar与压缩的功能结合在一起了。 仅仅打包起来的tar文件俗称tarfile文件，经过压缩的tar文件叫做tarball文件。 全能的 tar 命令概要tar可以将多个目录或文件打成一个大文件，同时支持gzip/bzip2 归档：tar {-c} [option…] -f destination source追加归档：tar {-r | -u} -f source [option…] destination解压：tar {-t | -x} -f source [option…] -C destination 最简单的使用 tar 只要记住下面的方式： 压缩：tar -jcv -f filename.tar.bz2 被压缩的文件或目录名称 查看文件：tar -jtv -f filename.tar.bz2 解压缩：tar -jxv -f filename.tar.gz -C 解压到哪里 filename.tar.bz2 既然tar不是一个压缩命令，是个打包命令，那么是如何做到打包并压缩的呢？我们先来看一下tar命令的常用参数： 模式参数 -c（–create）：创建新的归档文件。 -r（–append）：与-c一样创建新的归档文件，但这是以追加的模式，只能往未压缩过的归档文件中追加，要求指定-f参数。 -t：查看归档文件的内容含有哪些文件，可以看到包括文件名在内的详细信息。 -u：与-r一样，但是只往归档文件添加更新的文件。 -x：解压缩归档文件。如果一个归档文件里有相同文件名的多个文件，那么会先将每个文件解压，最新的文件将覆盖旧的文件。 tar分为三种模式，-c，-r，-u三个一类，为归档/压缩模式，在该模式下，tar会递归遍历指定目录下的所有目录和文件，并创建归档文件。-x表示为去归档/解压模式，-t表示为打印列表模式。 通用参数 -j：使用bzip2的支持进行压缩和解压缩，文件名最好为*.tar.bz2。 -z：使用gzip的支持进行压缩和解压缩，文件名最好为*.tar.gz。 -v：在压缩/解压缩的过程中，将正在处理的文件名显示出来。 -f：后面接被处理的文件名，最好把-f单独出来写一个参数。 -C：指定解压的目录。 -p：保留文件的原始信息，权限等等 -P：解压时保留绝对路径。 –exclude=FILE：在打包压缩的时候，不要将FILE打包。 打包并创建归档文件示例：打包一个目录。描述：将/home/test这个目录打包，生成文件名为command-18-06-02.tar的归档文件，保存在当前目录下。123456# tar -cv -f command-18-06-02.tar /home/test/home/test/.bash_logout/home/test/.bashrc/home/test/apache-tomcat-9.0.7.tar.gz/home/test/.bash_profile/home/test/nginx-1.10.1.tar.gz -c（–create的简写）参数，这表示为指定的文件或者目录创建新的归档文件。使用-f指定读取或者写入的归档文件，可以用-表示标准输入或者标准输出，-f可以与其他参数连起来写，必须保证f参数后面跟的是文件名。但不推荐这样写，因为参数调换顺序是允许的，如果写成-cfv就会导致压缩后的文件名变成了v。 使用-v表示生成详细的输出，在压缩或者解压的模式中，会列出正在向归档文件读或者写的文件名字。 创建tar.gz归档文件示例：打包并且使用gzip压缩。描述：将/home/test/images目录下的所有文件以及目录中的文件打包，并用gzip进行压缩，生成名为MyImages-18-06-02.tar.gz的归档文件，放在当前目录下。 12345678# tar -zcv -f MyImages-18-06-02.tar.gz /home/test/imagesOR# tar -zcv -f MyImages-18-06-02.tar.tgz /home/test/images/home/test/images/alejandro-gonzalez-17189.jpg/home/test/images/brooke-lark-275181.jpg/home/test/images/brenda-godinez-228181.jpg/home/test/images/artur-rutkowski-97622.jpg/home/test/images/ben-white-138743.jpg -z表示要使用gzip支持来压缩或者解压文件，注意gzip的压缩的文件格式最好写成tar.gz。（注：tar.gz 和 tgz 是同一个意思） 打包压缩排除某些文件示例：打包压缩并排除某些文件。描述：将/home/test/images目录下，排除brooke-lark-275181.jpg和ben-white-138743.jpg之外的所有文件打包，并用gzip进行压缩，生成名为MyImages-18-06-02.tar.gz的归档文件，放在当前目录下。 1234# tar -czv -f MyImages-18-06-02.tar.gz --exclude=./brooke-lark-275181.jpg --exclude=./ben-white-138743.jpg /home/test/images/home/test/images/alejandro-gonzalez-17189.jpg/home/test/images/brenda-godinez-228181.jpg/home/test/images/artur-rutkowski-97622.jpg 解压归档文件（默认）示例：解压，默认解压。描述：将名为MyImages-18-06-02.tar的归档文件解压至当前目录下。 1234# tar -xvf MyImages-18-06-02.tarhome/test/images/alejandro-gonzalez-17189.jpghome/test/images/brenda-godinez-228181.jpghome/test/images/artur-rutkowski-97622.jpg 其中，-x参数表示去解压一个归档文件，如果归档文件中有两个相同名字的文件，那么每一个文件都会被解压出来，然后最新的会覆盖旧的文件。注意这里没有指定-j参数，因为tar看到指定了-x参数，就知道这是解压操作，会自动判断该解压包的压缩类型。 解压归档文件并指定目录示例：解压到一个指定目录。描述：将名为MyImages-18-06-02.tar.gz的归档文件解压至一个指定的目录。 1234# tar -xv -f MyImages-18-06-02.tar -C /home/test/public_imageshome/test/public_images/alejandro-gonzalez-17189.jpghome/test/public_images/brenda-godinez-228181.jpghome/test/public_images/artur-rutkowski-97622.jpg 查看压缩包文件信息示例：查看压缩包文件信息。描述：列出MyImages-18-06-02.tar.bz2中的文件信息，-v参数，会生成与ls(1)命令相近的输出。 123456# tar -tv -f MyImages-18-06-02.tar.gzOR# tar -tv -f MyImages-18-06-02.tar.bz2-rw-r--r-- root/root 2176861 2018-06-02 21:26 home/test/images/alejandro-gonzalez-17189.jpg-rw-r--r-- root/root 8452524 2018-06-02 21:26 home/test/images/brenda-godinez-228181.jpg-rw-r--r-- root/root 1131986 2018-06-02 21:26 home/test/images/artur-rutkowski-97622.jpg 解压单个文件示例：解压单个文件。描述：将home/test/.bashrc这一个文件从归档文件中提取出来。 12# tar -xv -f command-18-06-02.tar home/test/.bashrchome/test/.bashrc 解压多个指定的文件示例：解压多个指定的文件。描述：将file1、file2等多个文件从归档文件中提取出来，可以用空格隔开多个文件，也可以用通配符的形式。 1234567# tar -zxv -f MyImages-18-06-02.tar.gz \"file 1\" \"file 2\"OR# tar -zxv -f MyImages-18-06-02.tar.gz --wildcards '*b*.jpg'home/test/images/brooke-lark-275181.jpghome/test/images/brenda-godinez-228181.jpghome/test/images/ben-white-138743.jpghome/test/images/aleks-dahlberg-274646.jpg","tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.oxysun.cn/tags/Linux/"}]},{"title":"CSS：文档流","date":"2018-07-09T15:24:00.000Z","path":"css/css-normal-flow.html","text":"CSS的文档流介绍。 官网：https://www.w3.org/TR/2016/WD-CSS22-20160412/visuren.html#normal-flow。 文档流文档流其实应该叫正常流，英文是Normal flow，我的理解呢，就是接收到的文档的内容，因为这些内容一直从服务端传输过来，边传输边需要处理，就像水流一样，所以称为流。 在文档流中的盒子是需要归属于一个上下文的，块级盒子参与到块格式化上下文中，内联级盒子参与到内联格式化上下文中，还有表格格式化上下文。 块格式化上下文（Block formatting contexts）块格式化上下文，简称BFC，是按照从上到下，一个一个垂直排列的，块之间的间距是靠margin来控制的。 In a block formatting context, boxes are laid out one after the other, vertically, beginning at the top of a containing block. The vertical distance between two sibling boxes is determined by the ‘margin’ properties. Vertical margins between adjacent block-level boxes in a block formatting context collapse. 翻译：在块格式化上下文中，框从一个包含块的顶部开始一个接一个地垂直排列。 两个兄弟盒子之间的垂直距离由“margin”属性决定。 块格式化上下文中相邻块级盒子之间的垂直margin会折叠。 ##内联格式化上下文（Inline formatting contexts）内联格式化上下文，简称IFC，主要是水平排列的，水平对齐是由一些参数来控制的。 An inline formatting context is established by a block container box that contains no block-level boxes. In an inline formatting context, boxes are laid out horizontally, one after the other, beginning at the top of a containing block. Horizontal margins, borders, and padding are respected between these boxes. The boxes may be aligned vertically in different ways: their bottoms or tops may be aligned, or the baselines of text within them may be aligned. The rectangular area that contains the boxes that form a line is called a line box. 翻译：内联格式化上下文由不包含块级框的块容器盒子建立。 在内联格式化上下文中，盒子从一个接一个地开始，从一个包含块的顶部开始。 这些框之间会考虑水平边距，边框和填充。 盒子可以以不同的方式垂直对齐：它们的底部或顶部可以对齐，或者它们内的文本的基线可以对齐。 包含形成一条线的框的矩形区域称为线盒子line box。 这里面有一些父容器和子布局的一些关系，需要梳理。 相对定位相对定位是根据这个盒子原本在文档流中的位置或者floated进行一些偏移。 未完，待续……","tags":[]},{"title":"Java：Tomcat的部署实例之资源目录","date":"2018-07-07T11:55:00.000Z","path":"java/java-deploy-resource-folder.html","text":"Tomcat上部署应用后，原本目录是否会被移除。 实例：一个项目的资源放在了WebContent下面，这样每次打包，都会将这些文件打包进去，这样在打包时，导致打出来的war包有好几百兆，这样上传Git也非常不方便。 方案1：分析：如果删除掉本地WebContent下的资源文件，再部署到服务器上，war包其实是一个压缩包，加压后覆盖原本目录下的相同内容，因为新上传的war包没有相同的资源文件，这样就不会覆盖原本的资源文件。结果：加压后的项目目录也不存在资源文件了，看来这个部署过程，是会删掉原本的项目目录的。 方案2：分析：因为webapps是web服务根目录，那么把资源文件从项目目录移到webapps下面，这样应该也可以被访问到。结果：成功，可以被访问到。 为了验证这个，上网查了很多帖子，众说纷纭，最后还是在官网找到这么一段话： The following deployment sequence will occur on Tomcat startup in that case: Any Context Descriptors will be deployed first. Exploded web applications not referenced by any Context Descriptor will then be deployed. If they have an associated .WAR file in the appBase and it is newer than the exploded web application, the exploded directory will be removed and the webapp will be redeployed from the .WAR .WAR files will be deployed 注意这里the exploded directory will be removed and the webapp will be redeployed from the .WAR，原本的解压目录会被移除，应用会被重新从war文件中部署。 寻根究底，而不人云亦云，这样才是端正的学习的态度。","tags":[{"name":"Java","slug":"Java","permalink":"https://www.oxysun.cn/tags/Java/"}]},{"title":"Git：工作流程Git Flow","date":"2018-07-06T13:22:00.000Z","path":"git/git-git-flow.html","text":"Git的工作流程Git Flow介绍。 前言参考：https://nvie.com/posts/a-successful-git-branching-model/， 这篇帖子是10年发表的，而我大概是08、09年接触的Git，当时因为刚刚花了好大气力研究明白SVN的流程，所以对Git很排斥，这也是我工作中一直以来的一个问题，因为在一项老技术上花了太多气力，而导致对新技术的出现本能地产生很大的排斥。如果当时仔细去研究一下Git，应该会发现Git不是来革我们这些SVN拥趸的命，而是提供完善和丰富了SVN的功能。 概述从CVS到SVN，再从SVN到Git。从中心化到去中心化的中心化（Decentralized but centralized），这句话挺有挺有深意。 分支长期分支项目存在两个长期分支： 主分支master。 开发分支develop或者dev。 We consider origin/master to be the main branch where the source code of HEAD always reflects a production-ready state.We consider origin/develop to be the main branch where the source code of HEAD always reflects a state with the latest delivered development changes for the next release. Some would call this the “integration branch”. This is where any automatic nightly builds are built from. 这里的HEAD是Git的一个指针，指向当前的分支上。上面的话的意思大概是master分支总是指向“等待上生产”状态的代码。develop分支往往是最近交付的开发修改。这个过程是和原本的SVN工作流是很接近的，一个开发分支，一个线上分支。开发完，测试后，发布到线上。SVN流程推荐在测试时分叉一个branch出来进行测试，这个时候不影响trunk上业务的继续开发，这个工作流没有这么明说，但是因为Git的灵活性，建立一个临时的测试分支也是没有问题的。Git好就好在非常灵活，不过也正是因为如此，导致了一些问题，之前有一个小朋友，把所有的功能分支都保存了下来，还说这样会更加方便，我很难理解，这样怎么会方便呢？每个人分支都需要不断同步。灵活也应该是相对的，在一个相对固定的流程下，适当的灵活，是可以提高效率的。 支持分支原文叫做supporting branches。这里面的每一个分支都有指定的目的和约束的规则，如何产生和如何合并。 Feature branches Release branches Hotfix branches 功能分支可以产生于:develop必须合并到:develop分支命名约定:除了master, develop, release-, or hotfix- 都可以，前面几个作为保留。 功能分支用于开发未来的一项功能，目标的发布此时可能还不确定。这个分支最终会被合并回develop（采用了）或者被抛弃掉（不采用）。功能分支更多存在于用户仓库，而不是origin仓库。 创建：12$ git checkout -b myfeature developSwitched to a new branch &quot;myfeature&quot; 合并回develop： 12345678$ git checkout developSwitched to branch &apos;develop&apos;$ git merge --no-ff myfeatureUpdating ea1b82a..05e9557(Summary of changes)$ git branch -d myfeatureDeleted branch myfeature (was 05e9557).$ git push origin develop 对于–no-ff，参考：https://git-scm.com/docs/git-merge，有待更进一步的解释。 发布分支可以产生于:develop必须合并到:develop和master分支分支命名约定:release-* 我理解的，这里主要用于准备一个发布版的功能已经开发完成，等待一些信息最后的确认，为了不影响下一个开发版的正常进行，打出一个发布分支。 创建一个发布分支1234567$ git checkout -b release-1.2 developSwitched to a new branch &quot;release-1.2&quot;$ ./bump-version.sh 1.2Files modified successfully, version bumped to 1.2.$ git commit -a -m &quot;Bumped version number to 1.2&quot;[release-1.2 74d9424] Bumped version number to 1.21 files changed, 1 insertions(+), 1 deletions(-) 结束一个发布分支合并回master分支123456$ git checkout masterSwitched to branch &apos;master&apos;$ git merge --no-ff release-1.2Merge made by recursive.(Summary of changes)$ git tag -a 1.2 合并回develop分支12345$ git checkout developSwitched to branch &apos;develop&apos;$ git merge --no-ff release-1.2Merge made by recursive.(Summary of changes) 删除原分支12$ git branch -d release-1.2Deleted branch release-1.2 (was ff452fe). 热修复分支可以产生于:master必须合并到:develop和master分支分支命名约定:hotfix-* 主要用于对线上代码进行热修复用，线上代码出现了问题，开出一个分支进行修复，等修复完成，合并回master和develop分支。 创建 1234567$ git checkout -b hotfix-1.2.1 masterSwitched to a new branch &quot;hotfix-1.2.1&quot;$ ./bump-version.sh 1.2.1Files modified successfully, version bumped to 1.2.1.$ git commit -a -m &quot;Bumped version number to 1.2.1&quot;[hotfix-1.2.1 41e61bb] Bumped version number to 1.2.11 files changed, 1 insertions(+), 1 deletions(-) 提交 123$ git commit -m &quot;Fixed severe production problem&quot;[hotfix-1.2.1 abbe5d6] Fixed severe production problem5 files changed, 32 insertions(+), 17 deletions(-) 结束合并回master123456$ git checkout masterSwitched to branch &apos;master&apos;$ git merge --no-ff hotfix-1.2.1Merge made by recursive.(Summary of changes)$ git tag -a 1.2.1 合并回develop12345$ git checkout developSwitched to branch &apos;develop&apos;$ git merge --no-ff hotfix-1.2.1Merge made by recursive.(Summary of changes) 删除 12$ git branch -d hotfix-1.2.1Deleted branch hotfix-1.2.1 (was abbe5d6).","tags":[{"name":"Git","slug":"Git","permalink":"https://www.oxysun.cn/tags/Git/"}]},{"title":"Linux下shell命令用法及常见用例：netstat","date":"2018-07-05T07:14:47.000Z","path":"linux/shell-command-netstat.html","text":"netstat命令用来查看系统中所有的网络套接字连接情况。 命令格式netstat [选项] 参考：https://linux.die.net/man/8/netstat。 netstat命令用来查看系统中所有的网络套接字连接情况。 命令格式netstat [选项] 参考：https://linux.die.net/man/8/netstat。 netstat命令用来查看系统中所有的网络套接字连接情况。 命令格式netstat [选项] 命令功能netstat命令用来查看系统中所有的网络套接字连接情况，包括TCP、UDP和Unix套接字。也可以显示路由表，接口状态，masquerade 连接，多播成员（Multicast Memberships）等等。另外，它还可以列出处于监听状态（等待接入请求）的套接字，比如想确认系统中的web服务是否起来，就可以查看80端口有没有打开。 命令参数 -a或–all：显示所有选项，默认不显示LISTEN相关。 -t或–tcp：(TCP)仅显示TCP相关选项。 -u或–udp：(UDP)仅显示UDP相关选项。 -x或–unix：此参数的效果和指定”-A unix”参数相同。 -n或–numeric：拒绝显示别名，能显示数字的全部转化成数字。 -l或–listening：仅列出有在Listen(监听)的服务状态。 -g或–groups：显示多重广播功能群组组员名单。 -p或–programs：显示建立相关链接的程序名和PID。 -r或–route：显示路由信息，路由表。 -e或–extend：显示扩展信息，例如UID等。 -s或–statistics：按各个协议进行统计。 -c或–continuous：每隔一个固定时间，执行该netstat命令。 -g或–groups：显示多重广播功能群组组员名单。 提示：LISTEN和LISTENING的状态只有用-a或者-l才能看到。 输出信息含义netstat的输出结构可以分为两个部分：一个是Active Internet connections，称为有源TCP连接。其中”Recv-Q”和”Send-Q”指的是接收队列和发送队列。123456Active Internet connections (w/o servers)Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 VM01.root:ssh 61.149.11.230:21859 ESTABLISHEDtcp 0 0 localhost:51476 localhost:27017 ESTABLISHEDtcp 0 0 VM01.root:ssh 61.149.11.230:50883 ESTABLISHEDtcp 0 0 VM01.root:58300 47.89.193.173:3666 ESTABLISHED 另一个是Active UNIX domain sockets，称为有源Unix域套接口(和网络套接字一样，但是只能用于本机通信，性能可以提高一倍)。Proto显示连接使用的协议，RefCnt表示连接到本套接口上的进程号，Types显示套接口的类型，State显示套接口当前的状态，Path表示连接到套接口的其它进程使用的路径名。 1234567Active UNIX domain sockets (w/o servers)Proto RefCnt Flags Type State I-Node Pathunix 2 [ ] DGRAM 15049 /run/user/0/systemd/notifyunix 3 [ ] DGRAM 13640 /run/systemd/notifyunix 2 [ ] DGRAM 13645 /run/systemd/journal/syslogunix 8 [ ] DGRAM 13660 /run/systemd/journal/socketunix 25 [ ] DGRAM 10467 /run/systemd/journal/dev-log 实例实例：列出当前所有的连接（-a）命令：netstat -a输出： 12345678root@iZhp3fz3iqsadyes2s8ayeZ:~# netstat -aActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 *:8838 *:* LISTEN tcp 0 0 localhost:27017 *:* LISTEN tcp 0 0 *:8330 *:* LISTEN tcp 0 0 localhost:submission *:* LISTEN ...... 实例：列出所有TCP端口（-t）命令：netstat -at输出： 1234567root@iZhp3fz3iqsadyes2s8ayeZ:~# netstat -atActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 *:8838 *:* LISTEN tcp 0 0 localhost:27017 *:* LISTEN tcp 0 0 *:8330 *:* LISTEN tcp 0 0 localhost:submission *:* LISTEN 示例：列出所有监听TCP的端口，数字显示描述：查看本机监听的（-l）TCP连接（-t）的IP地址的数字显示（-n）。不适用-n的话，就会用端口的约定名称来显示，例如80端口，会显示成http。命令：netstat -tnl输出： 123456root@iZhp3fz3iqsadyes2s8ayeZ:~# netstat -tnlActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 0.0.0.0:8838 0.0.0.0:* LISTEN tcp 0 0 127.0.0.1:27017 0.0.0.0:* LISTEN tcp 0 0 0.0.0.0:8330 0.0.0.0:* LISTEN 示例：获取本机的所有的TCP连接的进程名、进程号以及用户ID描述：使用-p选项查看进程信息，-ep选项可以同时查看进程名和用户名。另外，-n和-e选项一起使用，User列的属性就是用户ID，而不是用户名。查看本机所有的（al）TCP连接的（t）进程名（p）和用户名ID（ne）。命令：netstat -altpen 1234567root@iZhp3fz3iqsadyes2s8ayeZ:~# netstat -altpenActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address Foreign Address State User Inode PID/Program nametcp 0 0 0.0.0.0:8838 0.0.0.0:* LISTEN 0 11863750 31212/bnewd tcp 0 0 127.0.0.1:27017 0.0.0.0:* LISTEN 110 2945745 18546/mongod tcp 0 0 0.0.0.0:8330 0.0.0.0:* LISTEN 0 22250263 13550/btnd tcp 0 0 127.0.0.1:587 0.0.0.0:* LISTEN 0 12285119 11792/sendmail: MTA 这个可能是最屌的命令了，也可能是最常用的命令了。 还有一些实例，暂时不常用，有待完善。","tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.oxysun.cn/tags/Linux/"}]},{"title":"MongoDB：聚合之累加操作符","date":"2018-07-04T15:29:00.000Z","path":"mongodb/mongodb-collection-aggregator-accumulate-operator.html","text":"MongoDB的聚合之累加操作符。 官网：https://docs.mongodb.com/manual/reference/operator/aggregation/group/#considerations。 累加操作符感觉这个没有太多可说的，简单翻译一下。 名字 描述 $avg Returns an average of numerical values. Ignores non-numeric values.（返回平均值） $first Returns a value from the first document for each group. Order is only defined if the documents are in a defined order.（返回第一个） $last Returns a value from the last document for each group. Order is only defined if the documents are in a defined order.（返回最后一个） $max Returns the highest expression value for each group.（返回最大值） $min Returns the lowest expression value for each group.（返回最小值） $push Returns an array of expression values for each group. $addToSet Returns an array of unique expression values for each group. Order of the array elements is undefined.（） $stdDevPop Returns the population standard deviation of the input values. $stdDevSamp Returns the sample standard deviation of the input values. $sum Returns a sum of numerical values. Ignores non-numeric values.（返回总和）","tags":[]},{"title":"MongoDB：聚合之介绍","date":"2018-07-04T15:24:00.000Z","path":"mongodb/mongodb-collection-aggregation-introduction.html","text":"MongoDB的聚合功能介绍。 官网：https://docs.mongodb.com/manual/aggregation/#single-purpose-agg-operations。 初衷：MongoDB的使用还是有一定难度的，官网讲解的一环牵扯一环，不容易一下子把握住重点，也不利于快速查询操作，所以整理一下。 聚合函数是对记录集（data records）进行操作，是把多条记录集合（group）在一起，进行处理，与此相对应的是sql的group by等操作，这是数据处理的一个方面。 MongoDB提供三种聚合方法： 聚合管道。 map-reduce函数。 单一功能的聚合方法。 聚合管道接触过linux shell的人应该对管道不会陌生，管道就是对输入的数据进行一系列的处理、转换，变成新的数据。 这里的聚合管道是对记录集进行多阶段的转换，产出新聚合结果，例如： 解释一下： 数据集合：orders，共有4条记录，这里省略了_id 这个域。 需求：查找所有status=&quot;A&quot; 的记录，根据cust_id进行分组，计算每个组的amount的和。 分析：{$match: {status: &quot;A&quot;}}，第一个阶段，匹配阶段，查找所有status=&quot;A&quot; 的记录。{$group: {_id: &quot;$cust_id&quot;, total: {$sum: &quot;$amount&quot;}}}，第二个阶段，分组计算，根据cust_id进行分组，对每个组的amount进行求和。这里涉及$group 的语法，如下： 1&#123; $group: &#123; _id: &lt;expression&gt;, &lt;field1&gt;: &#123; &lt;accumulator1&gt; : &lt;expression1&gt; &#125;, ... &#125; &#125; 其中，_id是强制的，后面是可选的。&lt;accumulator1&gt;是累加操作符，参考这里，例如这里的$sum，注意，这里必须要加$。&lt;expression1&gt;是表达式，有待补充， &quot;$amount&quot; , 表示是去取上一个结果中的amount 这个域，对其进行累加，并把结果存入新的域total中。 这个例子看明白了，聚合就基本明白了。 Map-Reducemap-reduce操作分为两个阶段：map阶段，处理每一条记录，产出一个或多个对象；reduce阶段，合并map阶段的输出。作为可选，map-reduce可以有一个最终阶段来对结果进行最终的操作。map-reduce也可以进行查询、排序和限制输出结果。 单一功能的聚合方法MongoDB也提供db.collection.count()（求和）和db.collection.distinct()（去重）函数。","tags":[]},{"title":"MongoDB：查询和投影操作符","date":"2018-07-02T13:03:00.000Z","path":"mongodb/mongodb-collection-find-projection-operator.html","text":"MongoDB查询和投影操作符。 官网：https://docs.mongodb.com/manual/reference/operator/query/。 这一章节都是很简单的英语，就做一个很简单的备注，如果连这个英语都看不懂，那就需要提高了，程序员看不懂基本的英语是很难提高的。这一章节还需要完善一些样例，这个有待补充。 查询选择器比较 名字 描述 $eq Matches values that are equal to a specified value.（判断相等） $gt Matches values that are greater than a specified value.（判断大于） $gte Matches values that are greater than or equal to a specified value.（判断大于等于） $in Matches any of the values specified in an array.（判断在其中） $lt Matches values that are less than a specified value.（判断小于） $lte Matches values that are less than or equal to a specified value.（判断小于等于） $ne Matches all values that are not equal to a specified value.（判断所有值都不等于指定值） $nin Matches none of the values specified in an array.（判断不在其中） 逻辑 名字 描述 $and Joins query clauses with a logical AND returns all documents that match the conditions of both clauses.（与） $not Inverts the effect of a query expression and returns documents that do not match the query expression.（非） $nor Joins query clauses with a logical NOR returns all documents that fail to match both clauses.（异或） $or Joins query clauses with a logical OR returns all documents that match the conditions of either clause.（或） 元素 名字 描述 $exists Matches documents that have the specified field. $type Selects documents if a field is of the specified type. 评估 名字 描述 $expr Allows use of aggregation expressions within the query language. $jsonSchema Validate documents against the given JSON Schema. $mod Performs a modulo operation on the value of a field and selects documents with a specified result. $regex Selects documents where values match a specified regular expression. $text Performs text search. $where Matches documents that satisfy a JavaScript expression. 地理空间 名字 描述 $geoIntersects Selects geometries that intersect with a GeoJSON geometry. The 2dsphere index supports $geoIntersects. $geoWithin Selects geometries within a bounding GeoJSON geometry. The 2dsphere and 2d indexes support $geoWithin. $near Returns geospatial objects in proximity to a point. Requires a geospatial index. The 2dsphere and 2d indexes support $near. $nearSphere Returns geospatial objects in proximity to a point on a sphere. Requires a geospatial index. The 2dsphere and 2d indexes support $nearSphere. 数组 名字 描述 $all Matches arrays that contain all elements specified in the query. $elemMatch Selects documents if element in the array field matches all the specified $elemMatch conditions. $size Selects documents if the array field is a specified size. 位操作 名字 描述 $bitsAllClear Matches numeric or binary values in which a set of bit positions all have a value of 0. $bitsAllSet Matches numeric or binary values in which a set of bit positions all have a value of 1. $bitsAnyClear Matches numeric or binary values in which any bit from a set of bit positions has a value of 0. $bitsAnySet Matches numeric or binary values in which any bit from a set of bit positions has a value of 1. 注释 名字 描述 $comment Adds a comment to a query predicate. 投影操作 名字 描述 $ Projects the first element in an array that matches the query condition. $elemMatch Projects the first element in an array that matches the specified $elemMatch condition. $meta Projects the document’s score assigned during $text operation. $slice Limits the number of elements projected from an array. Supports skip and limit slices.","tags":[]},{"title":"MongoDB集合的基本操作：查找记录（查）","date":"2018-07-02T13:03:00.000Z","path":"mongodb/mongodb-collection-find-1.html","text":"MongoDB集合的基本操作：查找记录（查）。 语法1db.collection.find(query, projection) 在集合或者视图的文档中进行选择，并且返回一个指向被选中的文档的游标。（原文是：Selects documents in a collection or view and returns a cursor to the selected documents.）参数|类型|描述-|-|-query|文档型|可选。使用查询操作符(参考这里)，指定了查询过滤器。 想要返回集合中所有的文档，忽略这个参数，或者传一个空的文档({})。projection|文档型|可选。制定了匹配查询过滤器，要返回的文档的域。想要返回匹配的文档中的所有域，忽略这个参数。 projection参数决定了哪些域需要被返回。 1&#123; field1: &lt;value&gt;, field2: &lt;value&gt; ... &#125; &lt;value&gt;可以是: 1 或 true 表示要在返回文档中包含这个域。 0 或 false 表示不包含这个域。 表达式使用了投影操作符（有待解释）。 分析基本的查找参考上面的语法即可，下面也有实例，其实较为难以掌握的是组合查找，例如逻辑关系是AND的，或者是OR的，还有IN的，这几个需要梳理一下。 实例实例 查找上文test集合中的所有文档。12345678910111213141516171819&gt; db.test.find().pretty()&#123; &quot;_id&quot; : ObjectId(&quot;5abb3b5bce69c048be080199&quot;), &quot;meta&quot; : &#123; &quot;createAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;), &quot;updateAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;) &#125;, &quot;a&quot; : &quot;1&quot;, &quot;b&quot; : &quot;1&quot;&#125;&#123; &quot;_id&quot; : ObjectId(&quot;5abb3b5bce69c048be080120&quot;), &quot;meta&quot; : &#123; &quot;createAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;), &quot;updateAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;) &#125;, &quot;a&quot; : &quot;1&quot;, &quot;b&quot; : &quot;3&quot;&#125; pretty()是用来让展示更加舒适。 实例 查找test集合中的b=&quot;3&quot;的记录，这里要注意“3”和3是不一样的，这里是要符合js的语法，字符串和数字表示方式是不同的。做一个好的程序员，一定要严谨，而做到了严谨，可以帮你更快地提高，更快地产出，更好地规避错误，其实加快了你的职场发展节奏。12345678910&gt; db.test.find(&#123;b: &quot;3&quot;&#125;).pretty()&#123; &quot;_id&quot; : ObjectId(&quot;5abb3b5bce69c048be080120&quot;), &quot;meta&quot; : &#123; &quot;createAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;), &quot;updateAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;) &#125;, &quot;a&quot; : &quot;1&quot;, &quot;b&quot; : &quot;3&quot;&#125; 可以看到，这次只查出了一条符合条件的记录。 实例 查找test集合中的b=&quot;3&quot;的记录a和b两个域，不要其它域。 12&gt; db.test.find(&#123;b: &quot;3&quot;&#125;, &#123;a: 1, b: 1&#125;).pretty()&#123; &quot;_id&quot; : ObjectId(&quot;5abb3b5bce69c048be080120&quot;), &quot;a&quot; : &quot;1&quot;, &quot;b&quot; : &quot;3&quot; &#125; 可以看到，没有涉及的域就没有再获取出来，这样在一些情况下是可以节省网络开销和分析成本的，在《高性能MySQL》也是讲过类似的原理，不要大而全地去把所有内容获取回来，对于资源的使用，应该是有规划的、经济地去使用。 实例 查找test集合中的b=&quot;3&quot; 并且a=&quot;4&quot;的记录。1&gt; db.test.find(&#123;b: &quot;3&quot;, a: &quot;4&quot;&#125;&#125;).pretty() 可以看到，在第一个{} 中逗号分隔开的是AND的查询关系。 实例 查找test集合中的b=&quot;3&quot; 或者b=&quot;4&quot;的记录。1&gt; db.test.find(&#123;b: &#123;$in: [&quot;3&quot;, &quot;4&quot;]&#125;&#125;).pretty() 这个语法的原则是操作符$in在前，作为JSON名值对的名，[&quot;3&quot;, &quot;4&quot;]是它的值，然后整个{$in: [&quot;3&quot;, &quot;4&quot;]}作为b的值，从JSON语法的角度去思考和记忆这个语法，就容易一些了。 实例 修改一下上面的例子，查找test集合中的b=&quot;3&quot; 或者a=&quot;4&quot;的记录。1&gt; db.test.find(&#123;$or: [&#123;b: &quot;3&quot;&#125;, &#123;a: &quot;4&quot;&#125;]&#125;).pretty() 这个语法和IN 的道理是一样的，其实AND也可以这么用，上面那种是隐式的用法，显式的用法是这样：1&gt; db.test.find(&#123;$and: [&#123;b: &quot;3&quot;&#125;, &#123;a: &quot;4&quot;&#125;]&#125;).pretty() 查询操作符还有一些大于、小于等操作，具体参考查询操作符一节。 参考https://docs.mongodb.com/manual/reference/method/db.collection.find/。","tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"https://www.oxysun.cn/tags/MongoDB/"}]},{"title":"MongoDB集合的基本操作：插入记录（增）","date":"2018-07-02T07:46:48.000Z","path":"mongodb/mongodb-collection-insert-1.html","text":"MongoDB集合的基本操作：插入记录（增）。 初衷MongoDB的使用还是有一定难度的，官网讲解的一环牵扯一环，不容易一下子把握住重点，也不利于快速查询操作，所以整理一下，便于快速查找。另外，做一做笔记，对于记忆和理解也是有好处的，同时可以方便一些英语暂时不好的同学用来参考。 语法1233.2版本之后db.collection.insertOne()db.collection.insertMany() 123.2版本之前db.collection.insert() 12345678910111213141516171819202122db.collection.insert( &lt;document or array of documents&gt;, &#123; writeConcern: &lt;document&gt;, ordered: &lt;boolean&gt; &#125;)db.collection.insertOne( &lt;document&gt;, &#123; writeConcern: &lt;document&gt; &#125;)db.collection.insertMany( [ &lt;document 1&gt; , &lt;document 2&gt;, ... ], &#123; writeConcern: &lt;document&gt;, ordered: &lt;boolean&gt; &#125;) 参数 类型 描述 document 文档或者数组 将要插入集合的文档或者文档数组。 writeConcern 文档 可选。待解释和细化。 ordered 布尔型 可选。插入数组时是否要按照顺序，默认为true。 实例：数据库：my_test，之前文章创建的数据库，创建数据库，参看这里。集合：test。插入记录如下： 123456789&#123; &quot;_id&quot; : ObjectId(&quot;5abb3b5bce69c048be080199&quot;), &quot;meta&quot; : &#123; &quot;createAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;), &quot;updateAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;) &#125;, &quot;a&quot; : &quot;1&quot;, &quot;b&quot; : &quot;1&quot;,&#125; 语句： 123456789db.test.insert(&#123; &quot;meta&quot; : &#123; &quot;createAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;), &quot;updateAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;) &#125;, &quot;a&quot; : &quot;1&quot;, &quot;b&quot; : &quot;1&quot;,&#125;)WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;) 看到最后这句，表示插入一条记录成功。馈赠一条，为之后的例子做一个铺垫：123456789db.test.insert(&#123; &quot;meta&quot; : &#123; &quot;createAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;), &quot;updateAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;) &#125;, &quot;a&quot; : &quot;1&quot;, &quot;b&quot; : &quot;3&quot;,&#125;)WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;) 查看一下： 12345678910111213141516171819&gt; db.test.find().pretty()&#123; &quot;_id&quot; : ObjectId(&quot;5abb3b5bce69c048be080199&quot;), &quot;meta&quot; : &#123; &quot;createAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;), &quot;updateAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;) &#125;, &quot;a&quot; : &quot;1&quot;, &quot;b&quot; : &quot;1&quot;&#125;&#123; &quot;_id&quot; : ObjectId(&quot;5abb3b5bce69c048be080120&quot;), &quot;meta&quot; : &#123; &quot;createAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;), &quot;updateAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;) &#125;, &quot;a&quot; : &quot;1&quot;, &quot;b&quot; : &quot;3&quot;&#125; 我们看到了两条记录，查询的语法请参考关于查询的文档。 参考https://docs.mongodb.com/manual/tutorial/insert-documents/。https://docs.mongodb.com/manual/reference/method/db.collection.insert/#db.collection.insert。","tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"https://www.oxysun.cn/tags/MongoDB/"}]},{"title":"Linux下shell命令用法及常见用例：touch","date":"2018-07-01T06:28:00.000Z","path":"linux/shell-command-touch.html","text":"touch命令用来创建文件，也可以更改和修改一个文件的时间戳。 概要touch [选项]... 文件... 描述touch命令用来创建文件，也可以更改和修改一个文件的时间戳。Linux中的每个文件都与时间戳相关联，而且每个文件都存储上次访问时间，上次修改时间，上次更改时间的信息。因为，无论何时创建一个新文件，访问或者修改现有文件，时间戳都会被自动更新。 命令选项Linux中的文件有三个时间： access time（atime）：访问时间，对一次文件的内容就会更新。例如cat，vi/vim，cp，touch命令。 modification time（mtime）：修改时间，对文件内容修改一次就会更新。例如touch，vi/vim命令。 status time（ctime）：状态改动时间。通过chmod/chown/chgrp等命令更改一次文件属性，通过touch准确地修改时间等，这个时间就会更新。例如mv，touch，chmod/chown/chgrp，vi/vim等命令。 touch命令选项： -a，只改变访问时间。 -c，如果文件不存在，那就不创建。 -d，更新访问时间和修改时间。 -m，只改变修改时间。 -r，将参照文件ref_file相应的时间戳作为指定文件file时间戳的新值。 -t，用指定的时间创建文件，格式是[[CC]YY]MMDDhhmm[.SS]。CCYY的范围在1969~2068之内。SS为秒数，范围在0~61之间，这样可以处理闰秒。由于系统的限制，早于1970年1月1日的时间是错误的。 示例：1. 创建空文件描述：若文件不存在，使用touch命令可以轻松地创建一个空文件，或是创建多个。如果文件已存在，那么文件的3个时间：修改时间（mtime）、状态改动时间（ctime）和访问时间（atime）都会被更新为当前时间。stat命令可以查看文件时间。命令：touch my_onestat my_onetouch my_one my_two my_three输出： 示例：2. 只改变文件的修改时间（mtime）和状态改动时间（ctime）描述：只改变my_three文件的修改时间为当前时间，同时状态改动时间会在命令执行后更新为当前时间。这个操作并不需要修改文件内容。-m选项只更改文件的修改时间。命令：touch -m my_three输出： 示例：3. 只改变文件访问时间（atime）和状态改动时间（ctime）描述：只改变my_three文件的访问时间为当前时间，同时状态改动时间会在命令执行后更新为当前时间。如果文件不存在，会创建新的空文件。-a选项只更改文件的访问时间。命令：touch -a my_three输出： 示例：4. 指定文件的访问时间和修改时间描述：同时设置文件的访问时间和修改时间为指定时间，同时会更新状态改变时间为当前命令执行后的时间。如果文件不存在，会创建新的空文件。-d选项同时改变文件的访问时间和修改时间。命令：touch -d &quot;2018-06-14 14:00:00&quot; my_three输出： 描述：将my_three文件的访问时间和修改时间修改成两天前。touch还支持像date命令那样修改文件的时间。命令：touch -d &quot;2 days ago&quot; my_three输出： 示例：5. 避免创建新文件描述：更新atime、ctime、mtime，如果文件不存在，-c选项不会创建新的文件。命令：touch -c leena输出： 示例：6. 使用另一个文件的时间戳描述：-r选项将my_three的时间戳作为my_two文件的时间戳的新值，这两个文件有相同的时间戳。命令：touch -r my_three my_two输出： 示例：7. 使用指定的时间戳创建一个文件描述：将my_four文件的时间戳指定为1997年6月14日17点00分55秒。时间格式是[[CC]YY]MMDDhhmm[.SS]。命令：touch -t 199706141700.55 my_four输出：","tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.oxysun.cn/tags/Linux/"}]},{"title":"Linux下shell命令用法及常见用例：awk","date":"2018-07-01T02:00:00.000Z","path":"linux/shell-command-awk.html","text":"awk命令在文件或字符串中基于指定规则浏览和抽取信息。 命令功能awk是一种小巧的编程语言及命令行工具。（其名称得自于它的创始人Alfred Aho、Peter Weinberger 和 Brian Kernighan姓氏的首个字母）。它非常适合服务器上的日志处理，主要是因为awk可以对文件进行操作，通常以可读文本构建行。awk命令在文件或字符串中基于指定规则浏览和抽取信息。awk抽取信息后，才能进行其他文本操作，awk脚本通常用来格式化文本文件中的信息。 命令格式有三种方式调用awk，第一种是命令行方式，例如：awk [-F field-separator] &#39;commands&#39; input-file(s)awk默认使用空格作为缺省的域分隔符。如果要浏览诸如passwd文件，此文件是以冒号作为分隔符，则必须指明-F选项。例如：awk -F : &#39;commands&#39; input-file第二种方式是将所有awk命令插入一个文件，并使awk程序可执行，然后用awk命令解释器作为脚本的首行，以便通过键入脚本名称来调用它。第三种方式是将所有的awk命令插入一个单独文件，然后调用：awl -f awk-script-file input-file(s)-f选项指明在文件awk-script-file中的awk脚本，input_file(s)是使用awk进行浏览的文件名。 awk脚本代码结构awk脚本的代码结构很简单，就是一系列的模式（pattern）和动作（action）。 12345678# commentPattern1 &#123; ACTIONS; &#125;# commentPattern2 &#123; ACTIONS; &#125;# commentPattern3 &#123; ACTIONS; &#125;# commentPattern4 &#123; ACTIONS; &#125; 扫描文档的每一行时都必须与每一个模式进行匹配比较，一次只匹配一个模式。 12this is line 1this is line 2 this is line 1这行会先Pattern1进行匹配，如果匹配成功，就会执行ACTIONS。然后this is line 1会和Pattern2进行匹配，如果匹配失败，就调到Pattern3进行匹配，以此类推。一旦所有的模式都匹配过了，this is line 2就会以同样的步骤进行匹配。其他的行也一样，直到读取完整个文件。这就是awk的运行模式。 数据类型awk仅有两个主要的数据类型：字符串和数字，它们可以相互转换。在ACTIONS部分使用=操作符给变量赋值，可以在任意时刻、任意地方声明和使用变量，也可以使用未初始化的变量，默认是空字符串。awk有数组类型，并且它们是动态的一维关联数组。 模式模式分为三大类：正则表达式、布尔表达式和特殊模式。 所有模式都是可选的，下面的脚本形式会对输入的每一行都会简单地执行ACRIONS。{ ACTIONS } 特殊的模式模式包括两个特殊字段：BEGIN和END。BEGIN在所有输入未被处理之前，即文本浏览动作之前进行匹配。可以初始化脚本变量和所有种类的状态的主要地方。END会在所有的输入都被处理完后，即完成文本浏览动作后进行匹配。可以在退出前进行清除工作和一些最后的输出。最后一类模式，要把它进行归类有点困难。它处于变量和特殊值之间，我们通常称它们为域（Field）。而且名副其实。 域1234567891011# According to the following line## $1 $2 $3# 00:34:23 GET /foo/bar.html# _____________ _____________/# $0 # Hack attempt?/admin.html$/ &amp;&amp; $2 == &quot;DELETE&quot; &#123;print &quot;Hacker Alert!&quot;;&#125; 域（默认地）由空格分隔。$0域代表了一整行的字符串。$1 域是第一块字符串（在任何空格之前），$2\\$域是后一块，以此类推。awk执行时，其浏览域标记为$1, $2, $3…$n。这种方式称为域标识。使用$1, $3标识表示第1和第3域。使用$0$标识表示所有域。awk浏览到一新行时，即到达域的记录末尾，执行新记录下一行的读动作，重新设置域分隔。 动作最常用和最有用的行为： 123456789101112&#123; print $0; &#125; # prints $0. In this case, equivalent to &apos;print&apos; alone&#123; exit; &#125; # ends the program&#123; next; &#125; # skips to the next line of input&#123; a=$1; b=$0 &#125; # variable assignment&#123; c[$1] = $2 &#125; # variable assignment (array) &#123; if (BOOLEAN) &#123; ACTION &#125;else if (BOOLEAN) &#123; ACTION &#125;else &#123; ACTION &#125;&#125;&#123; for (i=1; i&lt;x; i++) &#123; ACTION &#125; &#125;&#123; for (item in c) &#123; ACTION &#125; &#125; awk里的变量都是全局变量。 函数函数的通用文档(regular documentation) 1&#123; somecall($2) &#125; 用户定义的函数： 123456789# function arguments are call-by-valuefunction name (parameter-list) &#123; ACTIONS; #same actions as usual&#125;# return is valid keywordfunction add (val) &#123;return val+1;&#125; 实用命令实例：0. 新建测试文件描述：新建一个device文件，其中(1)为序号，(2)为Android版本，(3)为访问时间，(4)为IP，(5)为访问次数。本文大部分实例根据这一文件进行说明。输出： 实例：1. 抽取域描述：打印第1个（序号）域和第2个（Android版本）域的内容。print用来输出其后跟着的内容，用大括号把print语句括起来，表示一个打印动作。输出： 实例：2. 打印所有记录描述：打印所有记录。$0代表所有域。命令：awk &#39;{print $0}&#39; device输出： 实例：3. 打印报告头描述：在序号和IP地址之间用一些空格使之更容易划分，也可以在域间使用tab键加以划分。本例中加入NO和IP两个信息头以及中划线，\\n启动新行，并在\\n下一行启动打印文本操作。打印信息头放置在BEGIN模式部分，因为打印信息头被界定为一个动作，必须用大括号括起来。在awk查看第一条记录前，信息头被打印。命令：awk &#39;BEGIN {print &quot;NO IP\\n------------------------&quot;} {print $1&quot;\\t&quot;$4}&#39; device输出： 实例：4. 打印信息尾描述：在末行加入end of report信息。END语句在所有文本处理动作执行完之后才被执行，在脚本中的位置是在主要动作之后。命令：awk &#39;BEGIN {print &quot;Version\\n-------&quot;} {print $2} END {print &quot;end-of-report&quot;}&#39; device输出： 实例：5. 错误信息提示描述：如果将在awk命令中缺少一个双引号，awk将返回错误提示信息。命令：awk &#39;BEGIN {print &quot;Version\\n-------&quot;} {print $2} END {print &quot;end-of-report}&#39; device输出： 注意：在碰到awk错误时，应从以下几点进行排查： 确保整个awk命令引用单引号括起来。 确保命令内所有引号成对出现。 确保用花括号括起动作语句，用圆括号括起条件语句。 可能忘记使用花括号。 描述：如果查询的文件不存在，将得到以下错误信息：命令：awk &#39;END {print NR}&#39; device.txt输出： 条件操作符实例：1. 匹配描述：如果field-4以数字4开头，打印它。如果条件满足，则打印匹配的记录行。符号~后紧跟正则表达式，使一域号匹配正则表达式，也可以使用if语句。awk的if后面的条件用()括起来。^尖角符号表示行首。命令：awk &#39;{ if ($4 ~ /^4/) print $0}&#39; device输出： 等同于： 实例：2. 精确匹配描述：精确匹配访问次数为1次的记录，确保不匹配访问次数为15次的记录。使用等号==，并用单引号括起条件，也可以使用if语句。命令：awk &#39;$5==&quot;1&quot; {print $0}&#39; device或者：awk &#39;{if($5==/1/) print $0}&#39; device输出： 实例：3. 不匹配描述：不匹配IP地址以4开头的记录。使用!~表示不匹配。命令：awk &#39;$4 !~ /^4/&#39; device或者：awk &#39;{ if ($4 !~ /^4/) print $0}&#39; device输出： 注意这里不能用!=，因为用引号或者/括起了^4，将只匹配4而不匹配49.65.119.165等。如果查询非49.65.119.165的记录，可做如下操作：awk &#39;$4 != &quot;49.65.119.165&quot;&#39; device 实例：4. 小于，小于等于，大于，大于等于描述：匹配访问次数小于序号的记录。同样的有小于等于（&lt;=），大于（&gt;），大于等于（&gt;=）。命令：awk &#39;$4 !~ /^4/&#39; device或者：awk &#39;{ if ($4 !~ /^4/) print $0}&#39; device输出： 实例：5. 设置大小写描述：匹配含有前面是i或I，后面是OS的记录。[]符号可匹配[]内任意字符或单词。命令：awk &#39;/[iI]OS/&#39; device输出： 实例：6. 任意字符描述：匹配Android版本，第八个字符是7，打印它。表达式/^…….7/表示行首前7个字符任务，第八个是7。命令：awk &#39;$2 ~ /^.......7/&#39; device输出： 实例：7. 或关系匹配描述：匹配IP地址以4或者3开头的记录。竖线符|意为两边模式之一。可以得到与[]表达式相同的结果。命令：awk &#39;$4 ~ /^(4|3)/&#39; device输出： 注意，在使用竖线符时，语句必须用圆括号括起来。另外，除了字符重复出现外，其他的正则表达式在awk中都是合法的。 实例：8. AND 描述：匹配Android版本在7.0以上，并且IP地址以4开头的记录。OR，非与之类似。命令：awk &#39;$2 ~ /^.......7/ &amp;&amp; $4 ~ /^4/&#39; device等同于：awk &#39;{ if ($2 ~ /^.......7/ &amp;&amp; $4 ~ /^4/) print $0} &#39; device输出： awk内置变量awk内置变量如下： 1234567891011BEGIN &#123; # Can be modified by the userFS = &quot;,&quot;; # Field SeparatorRS = &quot;n&quot;; # Record Separator (lines)OFS = &quot; &quot;; # Output Filed SeparatorORS = &quot;n&quot;; # Output Record Separator (lines)&#125;&#123; # Can&apos;t be modified by the userNF # Number of Fileds in the current Record (lines)NR # Number of Records seen so farARGV / ARGC # Script Arguments&#125; NF：支持记录域个数，在记录被读之后再设置。NR：已读的记录数。FILENAME：告知系统目前正在浏览的实际文件，因为awk可以同时处理许多文件。 实例：1. NF、NR、FILENAME 描述：所有记录被打印，并带有记录号（第二和第三列），并在最后输出文件名。使用NF变量显示每一条读记录中有多少个域（5个），使用NR显示已读的记录数，使用FILENAME显示正在处理的文件名。命令：awk &#39;{print NF,NR,$0} END {print FILENAME}&#39; device输出： 实例：2. 判断文件至少有一个记录 描述：先检查文件中至少有一个记录时才查询IP地址。命令：awk &#39;NR &gt; 0 &amp;&amp; $4 ~ /^4/&#39; device输出： 实例：3. 与echo结合使用 描述：将变量$PWD的返回值传入awk并显示其目录。需要指定域分隔符/。命令：echo $PWD | awk -F / &#39;{print $NF}&#39;输出： 描述：显示文件名。命令：echo &quot;/etc/vimrc&quot; | awk -F / &#39;{print $NF}&#39;输出： awk操作符 实例：1. 设置输入域到域变量名描述：赋值IP地址域为ip，版本域为version，查询版本大于7的记录，并打印IP地址和版本信息。命令：awk &#39;{ip=$4;version=$2; if (version ~ /*7*/) print ip&quot;&quot;version}&#39; device输出： 实例：2. 域值比较操作有两种方式测试数值域是否小于另一数值域。 在BEGIN中给变量名赋值。 在关系操作中使用实际数值。 描述：找出访问次数大于10次的所有记录。命令：awk &#39;{if ($5 &gt; 10) print $0}&#39; device输出： 实例：3. 修改数值域的值 当在awk中修改任何域时，实际输入文件是不可修改的，修改的只是保存在缓存里的awk副本，awk会在变量NR或NF变量中反映出修改痕迹。 描述：修改序号为6的记录，将其访问次数减一。命令：awk &#39;{if ($1==6) $5=$5-1; print $1, $2, $5 }&#39; device输出： 实例：4. 修改文本域 描述：修改序号为6的记录，将其版本修改为iOS11.2.3。修改文本域就是对其重新赋值。命令：awk &#39;{if ($1==6) ($2=&quot;iOS11.2.3&quot;); print $1, $2, $5 }&#39; device输出： 实例：5. 只显示修改记录 描述：只显示修改后序号为6的记录。命令：awk &#39;{if ($1==6) {$2=&quot;iOS11.2.3&quot;; print $2}; }&#39; device输出： 实例：6. 创建新的输出域 描述：创建新域6保存目前访问次数大于序号的减法值，表达式为’{$6=$5-$1}’，只打印其值大于零的序号和其新域值。在BEGIN部分加入tab键以对齐报告头。也可以赋给新域更有意义的变量名。命令：awk &#39;BEGIN {print &quot;IP\\t Difference&quot;} {if ($5 &gt; $1) {$6=$5-$1; print $1 &quot;\\t&quot; $6}}&#39; device输出： 实例：7. 增加列值 描述：使用+=累加访问次数的值。awk的每一个操作匹配时，如果没有说明打印记录，那默认会打印所有记录。命令：awk &#39;(total+=$5); END {print &quot;total visits : &quot; total}&#39; device输出： 实例：8. 文件长度相加 描述：查看当前目录中所有文件的长度及其综合，但要排除子目录，使用ls -l命令，然后管道输出到awk，awk首先剔除首字符d（/^[^d]/）的记录，然后将文件长度相加，并输出每一文件长度及在END部分输出所有文件的长度。命令：ls -l | awk &#39;/^[^d]/ {print $9&quot;\\t&quot;$5} {total+=$5} END {print &quot;total KB: &quot; total}&#39;输出： 内置字符串函数 gsub类似于sed查找和替换。它允许替换一个字符串或字符为另一个字符串或字符，并以正则表达式的形式执行，第一个函数作用于记录$0，第二个gsub函数允许指定目标，如果未指定，默认是$0。index(s, t)函数返回目标字符串s中查询字符串t的首位置。length函数返回字符串s字符长度。match函数测试字符串s是否包含一个正则表达式r定义的匹配。split函数使用域分隔符fs，将字符串s划分为指定序列a。sprint函数类似于printf函数，返回基本输出格式fmt的结果字符串exp。sub(r, s)函数将用s代替$0中最左边最长的子串，该子串被（r）匹配。sub(s, p)返回字符串s在位置p后的后缀部分。substr(s, p, n)函数返回字符串s在位置p后长度为n的后缀部分。 实例：1. gsub 描述：匹配记录中访问时间为11:35的记录，修改为11:40。注意要用双引号括起来。命令：awk &#39;gsub(/11:35/, &quot;11:40&quot;) {print $0}&#39; device输出： 实例：2. index描述：匹配字符串Honey中，ney子串第一次出现的位置，即字符个数。命令：awk &#39;BEGIN {print index(&quot;Honey&quot;, &quot;ney&quot;)}&#39;输出： 实例：3. length 描述：匹配序号为6，第二个域的字符长度。也可以直接使用字符串。命令：awk &#39;$1==6 {print length($2) &quot;---&quot; $2}&#39; device输出： 实例：4. match 描述：match测试目标字符串是否包含查找字符的一部分，可以使用正则表达式。命令：在AWK中查找d，因其不存在，所以返回0。awk &#39;BEGIN {print match(&quot;AWK&quot;, /d/)}&#39;在AWK中查找K，因其存在，所有返回AWK中K出现的首位置字符数。awk &#39;BEGIN {print match(&quot;AWK&quot;, /K/)}&#39;在序号为6的记录中，查找Android的大版本号。awk &#39;$1==6 {print match($2, &quot;7&quot;)}&#39; device输出： 实例：5. split 描述：如果域中具有分隔符形式的字符串，使用split函数将其分隔，并保存到一个数组中，最后将数组的第一个元素打印出来。命令：awk &#39;BEGIN {print split(&quot;123#456#789&quot;, myarray, &quot;#&quot;)}&#39;输出： 实例：6. sub 描述：匹配所有Android，替换为android。注意只在模式第一次出现时进行替换操作。命令：awk &#39;sub(/Android/, &quot;android&quot;)&#39; device输出： 实例：7. substr 描述：匹配第二个域版本信息中，打印从第一个字符开始到第七个字符。如果给定的长度值远大于字符串长度，awk将从起始位置返回所有字符。另一种形式是返回字符串后缀或指定位置后面的字符。命令：awk &#39;$1==5 {print substr($2,1,7)}&#39; device输出： 实例：8. 从shell向awk传入字符串命令：使用管道将字符串powerful传入awk，返回其长度。echo &quot;powerful&quot; | awk &#39;{print length($0)}&#39;设置文件名为一变量，管道输出到awk，但会不带扩展名的文件名。STR=&quot;myawk.txt&quot; | echo $STR | awk &#39;{print substr($STR,1,5)}&#39;设置文件名为一变量，管道输出到awk，只返回其扩展名。TR=&quot;myawk.txt&quot; | echo $STR | awk &#39;{print substr($STR,7)}&#39; 输出： 字符转义 printf修饰符基本语法：printf([格式控制符], 参数)格式控制符通常在引号里。 awkprintf修饰符： awk printf格式： 实例：1. 字符转换描述：通过管道输出65到awk中，printf进行ASCII码字符转换。命令：echo &quot;65&quot; | awk &#39;{printf (&quot;%c\\n&quot;, $0)}&#39;或者awk &#39;BEGIN {printf &quot;%c\\n&quot;, 65}&#39;输出： 描述：数字1024转换为浮点数之后，被加入了六个小数点。命令：awk &#39;BEGIN {printf &quot;%f\\n&quot;, 1024}&#39; 输出： 实例：2. 格式化输出 描述：BEGIN后的第一个花括号嵌入头信息，第二个花括号打印所有用户的IP地址和访问时间，要求IP地址左对齐，23个字符长度，后跟访问时间。命令：awk &#39;BEGIN {print &quot;IP\\t\\t\\tTime&quot;} {printf &quot;%-23s %s\\n&quot;, $4, $3}&#39; device 输出： 实例：3. 向一行awk命令传值 描述：在命令行中设置VISITS等于10，然后传入awk中，查询访问次数大于10的所有记录。命令：awk &#39;{if($5 &gt; VISITS) print $0} &#39; VISITS=10 device输出： 描述：用管道将df -k传入awk，然后抽出第四列，即剩余可利用空间容量。使用$4 ~ /^[0-9]/取得容量数值，最后对命令行if($4 &lt; TRIGGER)上变量TRIGGER的值进行查询。查看文件系统空间容量，观察其是否达到一定水平。因为要监视的已使用空间容量不断在变化，所以需要再命令行指定一个触发值。命令：df -k | awk &#39;($4 ~ /^[0-9]/) {if ($4 &lt; TRIGGER) printf &quot;%-15s %s\\n&quot;,$6,$4}&#39; TRIGGER=930000输出： 描述：打印当前注册用户，并加入一定信息。命令：who | awk &#39;{print $1 &quot; is logged on&quot;}&#39;输出： 描述：传入环境变量LOGNAME，显示当前用户名。命令：who | awk &#39;{if ($1 == user) print $1&quot; you are connected to &quot; $2}&#39; user=$LOGNAME&quot;}&#39;输出： 实例：4. awk脚本文件 描述：第一行#! /usr/bin/awk -f告知脚本系统awk命令的位置。在脚本文件后键入文件名之前，需要先对脚本文件加入可执行权限。命令：chmod u+x user_tot.awkuser_tot.awk脚本文件： 描述：执行user_tot.awk脚本文件。命令：./user_tot.awk device输出： 实例：5. 在awk中使用FS变量 描述：从/etc/passwd文件中抽取第1和第5域，通过FS变量，指定冒号:分隔passwd文件域。第1域时账号名，第5域是账号所有者。命令：chmod u+x passwd.awk | ./passwd.awk /etc/passwd输出： 实例：6. 向awk脚本传值 向awk脚本传值与向awk一行命令传值的方式大体相同，格式为：awk script_file var=value input_file 描述：对比检查文件中域号和指定数字。注意不要忘了增加脚本的可执行权限。命令：chmod u+x fieldcheck.awk | ./fieldcheck.awk MAX=7 FS=&quot;:&quot; /etc/passwd输出： 描述：从du命令获得输入，并输出块和字节数。命令：chmod u+x duawk.awk | du /root | ./duawk.awk输出： 实例：9. awk数组 描述：用split将123#456#789划分开，并存入myarray数组，再使用循环打印各数组元素。命令：chmod u+x duawk.awk | du /root | ./duawk.awk输出： 实例：10. 处理由通配符指定的多个文件名 描述：打印当前目录中以.txt结尾的文件。nextfile告诉awk停止处理当前的输入文件。下一个输入记录读取来自下一个输入文件。命令：awk &#39;{ print FILENAME; nextfile } &#39; *.txtawk &#39;BEGIN{ print &quot;Starting...&quot;} { print FILENAME; nextfile }END{ print &quot;....DONE&quot;} &#39; *.txt输出：","tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.oxysun.cn/tags/Linux/"}]},{"title":"Linux下shell命令用法及常见用例：sed","date":"2018-07-01T02:00:00.000Z","path":"linux/shell-command-sed.html","text":"sed是stream editor（流式编辑器）的缩写，是一个非交互式的流编辑器，用于过滤或者转换文本。未完待续… 概要sed 选项… [脚本] [输入文件…] 描述sed编辑器被称作流编辑器(stream editor)，和普通的交互式文本编辑器恰好相反。在交互式文本编辑器中(比如vim)，你可以用键盘命令来交互式地插入、删除或替换数据中的文本。流编辑器则会在编辑器处理数据之前基于预先提供的一组规则来编辑数据流。sed编辑器可以根据命令来处理数据流中的数据，这些命令要么从命令行中输入，要么存储在一个命令文本文件中。sed编辑器会执行下列操作。(1) 一次从输入中读取一行数据。(2) 根据所提供的编辑器命令匹配数据。(3) 按照命令修改流中的数据。(4) 将新的数据输出到STDOUT。 在流编辑器将所有命令与一行数据匹配完毕后，它会读取下一行数据并重复这个过程。在流编辑器处理完流中的所有数据行后，它就会终止。 由于命令是按顺序逐行给出的，sed编辑器只需对数据流进行一遍处理就可以完成编辑操作。这使得sed编辑器要比交互式编辑器快得多，你可以快速完成对数据的自动修改。 理解这个命令使用起来有些复杂，复杂在于功能强大，需要逐步消化。 常见用例实例 替换input.txt文件中所有的“hello”为“world”，并且输出到output.txt中。 1sed &apos;s/hello/world/&apos; input.txt &gt; output.txt 这可能是最常用的例子了（至少在我工作这么多年的经验中），这里使用了sed的命令s。如果想输出到原文件的话，使用-i参数。 1sed -i &apos;s/hello/world/&apos; input.txt 这个在mac下表现会不一样，参考：https://blog.csdn.net/cuiaamay/article/details/49495885。 参考：https://www.gnu.org/software/sed/manual/sed.html。","tags":[{"name":"Linux","slug":"Linux","permalink":"https://www.oxysun.cn/tags/Linux/"}]},{"title":"MongoDB：创建数据库","date":"2018-06-30T07:53:48.000Z","path":"mongodb/mongodb-dababase-create.html","text":"MongoDB如何创建数据库。 官网位置：https://docs.mongodb.com/manual/mongo/。 初衷：MongoDB的使用还是有一定难度的，官网讲解的一环牵扯一环，不容易一下子把握住重点，也不利于快速查询操作，所以整理一下。 进入mongo： 1234root@iZhp3fz3iqsadyes2s8ayeZ:~# mongoMongoDB shell version: 2.6.10connecting to: test...... 如果没有mongo这个命令，表示路径没有配置好。 1use &lt;database&gt; 尖括号表示需要你替换的变量，别完全照搬，当年我是犯过这种很猪头的错误的，你不要证明你也猪头了。 如果数据库存在，这条命令会切换到该数据库，如果不存在，则创建并切换到该数据库。 实例：创建一个数据库，名字为my_test。 12use my_testswitched to db my_test 好，创建成功。","tags":[]},{"title":"MongoDB集合的基本操作：新增简单记录","date":"2018-06-30T07:53:48.000Z","path":"mongodb/mongodb-collection-create.html","text":"MongoDB如何创建数据集合（collection）。 官网地址：https://docs.mongodb.com/manual/reference/method/db.createCollection/#db.createCollection。 这节有点混乱，也有点尴尬，因为原本MongoDB就有些“没有规矩”。 快速创建一个集合，参考插入这一节。 集合不存在的情况下，插入一条记录就会创建集合。 稍微啰嗦一点，如下： 12345678910db.test.insert(&#123; &quot;_id&quot; : ObjectId(&quot;5abb3b5bce69c048be080199&quot;), &quot;meta&quot; : &#123; &quot;createAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;), &quot;updateAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;) &#125;, &quot;a&quot; : &quot;1&quot;, &quot;b&quot; : &quot;1&quot;,&#125;)WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;) 这样即会创建集合test，又会给这个集合插入一条记录。 非要规矩地创建（其实是可以设置一些选项），那么： 12345678910111213db.createCollection(&lt;name&gt;, &#123; capped: &lt;boolean&gt;, autoIndexId: &lt;boolean&gt;, size: &lt;number&gt;, max: &lt;number&gt;, storageEngine: &lt;document&gt;, validator: &lt;document&gt;, validationLevel: &lt;string&gt;, validationAction: &lt;string&gt;, indexOptionDefaults: &lt;document&gt;, viewOn: &lt;string&gt;, pipeline: &lt;pipeline&gt;, collation: &lt;document&gt;, writeConcern: &lt;document&gt;&#125; ) 参数 类型 描述 name 字符串 要创建的集合的名称。 options 文档 可选。一大堆选项，暂时没用到，将来再补充了。","tags":[{"name":"MongoDB","slug":"MongoDB","permalink":"https://www.oxysun.cn/tags/MongoDB/"}]}]