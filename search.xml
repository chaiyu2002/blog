<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Git：真实merge]]></title>
    <url>%2Fgit%2Fgit-git-merge-true-merge.html</url>
    <content type="text"><![CDATA[原帖收藏于IT老兵驿站。Git：真实merge。 前言这里准备碎片化地去解读和理解Git的一些功能。关于git-merge的总结一直没有做，但是几乎每天都会遇到git-merge，而且会遇到很多随着merge而产生的问题，所以只好碎片化地去做一做整理。 正文git-merge有两种merge方式，ff方式和true merge方式，关于ff的方式，另外一篇文章有讲过，这里不再赘述，这里整理一下true merge，真实merge。 介绍先摘录一段： TRUE MERGEExcept in a fast-forward merge (see above), the branches to be merged must be tied together by a merge commit that has both of them as its parents.A merged version reconciling the changes from all branches to be merged is committed, and your HEAD, index, and working tree are updated to it. It is possible to have modifications in the working tree as long as they do not overlap; the update will preserve them.When it is not obvious how to reconcile the changes, the following happens:The HEAD pointer stays the same.The MERGE_HEAD ref is set to point to the other branch head.Paths that merged cleanly are updated both in the index file and in your working tree.For conflicting paths, the index file records up to three versions: stage 1 stores the version from the common ancestor, stage 2 from HEAD, and stage 3 from MERGE_HEAD (you can inspect the stages with git ls-files -u). The working tree files contain the result of the “merge” program; i.e. 3-way merge results with familiar conflict markers &lt;&lt;&lt; === &gt;&gt;&gt;.No other changes are made. In particular, the local modifications you had before you started merge will stay the same and the index entries for them stay as they were, i.e. matching HEAD.If you tried a merge which resulted in complex conflicts and want to start over, you can recover with git merge –abort. 这里是三个版本的关系，公共祖先的版本、HEAD（本地仓库的版本）、MERGE_HEAD（另外一个分支想要merge过来的版本），所以叫3-way merge，三路合并。 关于HEAD、index、worktree、local repository、remote repository的关系，请参考这里，这个挺重要，随后要整理一下。 合并策略： MERGE STRATEGIESThe merge mechanism (git merge and git pull commands) allows the backend merge strategies to be chosen with -s option. Some strategies can also take their own options, which can be passed by giving -X arguments to git merge and/or git pull.resolveThis can only resolve two heads (i.e. the current branch and another branch you pulled from) using a 3-way merge algorithm. It tries to carefully detect criss-cross merge ambiguities and is considered generally safe and fast.recursiveThis can only resolve two heads using a 3-way merge algorithm. When there is more than one common ancestor that can be used for 3-way merge, it creates a merged tree of the common ancestors and uses that as the reference tree for the 3-way merge. This has been reported to result in fewer merge conflicts without causing mismerges by tests done on actual merge commits taken from Linux 2.6 kernel development history. Additionally this can detect and handle merges involving renames, but currently cannot make use of detected copies. This is the default merge strategy when pulling or merging one branch.The recursive strategy can take the following options:oursThis option forces conflicting hunks to be auto-resolved cleanly by favoring our version. Changes from the other tree that do not conflict with our side are reflected to the merge result. For a binary file, the entire contents are taken from our side.This should not be confused with the ours merge strategy, which does not even look at what the other tree contains at all. It discards everything the other tree did, declaring our history contains all that happened in it.theirsThis is the opposite of ours; note that, unlike ours, there is no theirs merge strategy to confuse this merge option with.…… 使用-X&lt;option&gt;参数，可以指定合并策略，上面摘录了两种，一种是resolve，一种是recursive，第一种策略看上去似乎是可以自动解决冲突，第二种是Git默认的merge策略，会产生一些少量的冲突，而不会进行错误的合并，它还有几个选项，就是合并时，只选择本地的（ours），或者只选择别人的（theirs）。 参考https://git-scm.com/docs/git-mergehttps://stackoverflow.com/questions/3689838/whats-the-difference-between-head-working-tree-and-index-in-git]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>git merge</tag>
        <tag>true merge</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git：merge的时候全部采用某一个端的文件]]></title>
    <url>%2Fgit%2Fgit-merge-choose-one-side-code.html</url>
    <content type="text"><![CDATA[原帖收藏于IT老兵驿站，传递一个IT老兵在凋零前的光和氧。Git：merge的时候全部采用某一个端的文件。 正文在Git使用过程中，有的时候进行merge，可能需要会全部采用某一端的文件，换句话说，就是完全采用本地的，或者完全采用远程的，怎么实现这个功能呢？ 使用merge命令：1234# keep remote filesgit merge --strategy-option theirs# keep local filesgit merge --strategy-option ours 官网是这样写的 --strategy-option=&lt;option&gt;Pass merge strategy specific option through to the merge strategy. 这里的策略选项可以参考另外一篇文章《Git：真实merge》。 git-pull也有同样的功能：1git pull -X theirs 原理是一样的。 参考https://stackoverflow.com/questions/6650215/how-to-keep-the-local-file-or-the-remote-file-during-merge-using-git-and-the-comhttps://stackoverflow.com/questions/10697463/resolve-git-merge-conflicts-in-favor-of-their-changes-during-a-pull]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>git merge</tag>
        <tag>冲突</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git：merge后如何检查是否还存在冲突没有处理]]></title>
    <url>%2Fgit%2Fgit-merge-exist-conflict.html</url>
    <content type="text"><![CDATA[原帖收藏于IT老兵驿站，传递一个IT老兵在凋零前的光和氧。Git：merge后如何检查是否还存在冲突没有处理。 正文在工作中，遇到一个问题，在git merge后，发生冲突，而当冲突较多的时候，逐个检查冲突，有的时候会遗漏一些文件，导致带有冲突标记的文件上传到了Git服务器上。 使用以下命令可以快速检查是否还存在有带有冲突标记的文件。git diff --check 说明： –checkWarn if changes introduce conflict markers or whitespace errors. What are considered whitespace errors is controlled by core.whitespace configuration. By default, trailing whitespaces (including lines that consist solely of whitespaces) and a space character that is immediately followed by a tab character inside the initial indent of the line are considered whitespace errors. Exits with non-zero status if problems are found. Not compatible with –exit-code. 上文摘录自手册官网，这个命令会检查conflict markers（冲突标记）和whitespace errors（空格错误）。 总结Git是一个相对比较复杂的工具，我发现，复杂往往源自于过于灵活，它的功能非常强大，掌握好了，就可以事半功倍，但是，把它掌握好，是需要花费一些时间成本的。感觉学习Git，可能需要既需要正面地一篇篇去阅读手册，也需要这样涓涓细流地不断总结各种场景下的用法，也许，这本身就是学习的一种方法。 参考https://git-scm.com/docs/git-diffhttps://ardalis.com/detect-git-conflict-markers]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>git merge</tag>
        <tag>冲突</tag>
        <tag>存在</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vue：学习笔记（六）-组件基础]]></title>
    <url>%2Fjs%2Fjs-vue-note-components.html</url>
    <content type="text"><![CDATA[Vue：学习笔记（六）-组件基础。 提醒原帖完整收藏于IT老兵驿站，并会不断更新。 前言最近在工作中频繁遇到组件，所以就没按照顺序，先总结组件这一章节的内容了，将来再做调整和修改。 （2018-10-24注：这一章粗读了两遍，感觉下面有好些内容都没有理解，有一些难度，看不明白就先修改一会儿，先干点别的。） 正文基本示例这是一个例子：123456789// 定义一个名为 button-counter 的新组件Vue.component(&apos;button-counter&apos;, &#123; data: function () &#123; return &#123; count: 0 &#125; &#125;, template: &apos;&lt;button v-on:click=&quot;count++&quot;&gt;You clicked me &#123;&#123; count &#125;&#125; times.&lt;/button&gt;&apos;&#125;) 在我看来，组件就是模板、数据，加上对于数据处理的逻辑，这些显示和逻辑，基本是固定的，所以以组件的形式固化出来。（感觉，这话一说出来，立刻就清楚了） 123&lt;div id=&quot;components-demo&quot;&gt; &lt;button-counter&gt;&lt;/button-counter&gt;&lt;/div&gt; 1new Vue(&#123; el: &apos;#components-demo&apos; &#125;) id等于“components-demo”是Vue对象的根元素，在它下面创建组件。 组件的复用这里是将把组件应该理解成类，每一个实例是对象，对象之间是没有关系的。 data 必须是一个函数只有将data实现为一个函数，才能实现上面的对象之间没有关系的复用。 组件的组织 这里有两种组件的注册类型：全局注册和局部注册。至此，我们的组件都只是通过 Vue.component 全局注册的：123Vue.component(&apos;my-component-name&apos;, &#123; // ... options ...&#125;) 通过 Prop 向子组件传递数据 Prop 是你可以在组件上注册的一些自定义特性。当一个值传递给一个 prop 特性的时候，它就变成了那个组件实例的一个属性。为了给博文组件传递一个标题，我们可以用一个 props 选项将其包含在该组件可接受的 prop 列表中： 1234Vue.component(&apos;blog-post&apos;, &#123; props: [&apos;title&apos;], template: &apos;&lt;h3&gt;&#123;&#123; title &#125;&#125;&lt;/h3&gt;&apos;&#125;) 感觉这个props仅仅是用来约束，如果没有这个约束，所有在组件的属性中送过来的属性都会被接受。 单个根元素这一章节讲了涉及多个元素的组件是如何组织的。例如：12&lt;h3&gt;&#123;&#123; title &#125;&#125;&lt;/h3&gt;&lt;div v-html=&quot;content&quot;&gt;&lt;/div&gt; 如果模板涉及了多个元素，那么需要将这些元素放在一个根元素内，上面这个模板就涉及到两个元素，这个时候需要在外面再包裹一个元素：1234&lt;div class=&quot;blog-post&quot;&gt; &lt;h3&gt;&#123;&#123; title &#125;&#125;&lt;/h3&gt; &lt;div v-html=&quot;content&quot;&gt;&lt;/div&gt;&lt;/div&gt; 下面的例子涉及到如何设计传递的参数。12345678&lt;blog-post v-for=&quot;post in posts&quot; v-bind:key=&quot;post.id&quot; v-bind:title=&quot;post.title&quot; v-bind:content=&quot;post.content&quot; v-bind:publishedAt=&quot;post.publishedAt&quot; v-bind:comments=&quot;post.comments&quot;&lt;/blog-post&gt; 合理的设计应该是：12345&lt;blog-post v-for=&quot;post in posts&quot; v-bind:key=&quot;post.id&quot; v-bind:post=&quot;post&quot;&gt;&lt;/blog-post&gt; 123456789Vue.component(&apos;blog-post&apos;, &#123; props: [&apos;post&apos;], template: ` &lt;div class=&quot;blog-post&quot;&gt; &lt;h3&gt;&#123;&#123; post.title &#125;&#125;&lt;/h3&gt; &lt;div v-html=&quot;post.content&quot;&gt;&lt;/div&gt; &lt;/div&gt; `&#125;) 通过事件向父级组件发送消息这段没想明白应该怎么去总结，完全照搬过来没有什么意义。 123&lt;button v-on:click=&quot;$emit(&apos;enlarge-text&apos;)&quot;&gt; Enlarge text&lt;/button&gt; 这个是孩子组件（位于父组件之内），可以使用$emit向父组件发送一个自定义的消息。 1234&lt;blog-post ... v-on:enlarge-text=&quot;postFontSize += 0.1&quot;&gt;&lt;/blog-post&gt; 父组件使用v-on去监听这个事件。 使用事件抛出一个值接着上面的例子，如果想给父组件发送消息的同时，传递参数，需要这样：孩子组件：123&lt;button v-on:click=&quot;$emit(&apos;enlarge-text&apos;, 0.1)&quot;&gt; Enlarge text&lt;/button&gt; 父组件：1234&lt;blog-post ... v-on:enlarge-text=&quot;postFontSize += $event&quot;&gt;&lt;/blog-post&gt; 这里第二个参数，可以是一个值，或者是一个方法12345methods: &#123; onEnlargeText: function (enlargeAmount) &#123; this.postFontSize += enlargeAmount &#125;&#125; 好像不能是对象，这个还要确认一下。 在组件上使用 v-model有一点含糊了，prop和v-model在这里有什么区别呢？这个部分讲的感觉又有点不清楚。1&lt;input v-model=&quot;searchText&quot;&gt; 等价于1234&lt;input v-bind:value=&quot;searchText&quot; v-on:input=&quot;searchText = $event.target.value&quot;&gt; 用在自定义的组件上（上面是标准的HTML元素），则是1234&lt;custom-input v-bind:value=&quot;searchText&quot; v-on:input=&quot;searchText = $event&quot;&gt;&lt;/custom-input&gt; 和上面大体接近，只是最后的$event有区别。 为了让它正常工作，这个组件内的 &lt;input&gt; 必须：将其 value 特性绑定到一个名叫 value 的 prop 上在其 input 事件被触发时，将新的值通过自定义的 input 事件抛出写成代码之后是这样的：123456789Vue.component(&apos;custom-input&apos;, &#123; props: [&apos;value&apos;], template: ` &lt;input v-bind:value=&quot;value&quot; v-on:input=&quot;$emit(&apos;input&apos;, $event.target.value)&quot; &gt; `&#125;) 现在 v-model 就应该可以在这个组件上完美地工作起来了：&lt;custom-input v-model=&quot;searchText&quot;&gt;&lt;/custom-input&gt; 意思是：1234&lt;custom-input v-bind:value=&quot;searchText&quot; v-on:input=&quot;searchText = $event&quot;&gt;&lt;/custom-input&gt; 这么写和1&lt;custom-input v-model=&quot;searchText&quot;&gt;&lt;/custom-input&gt; 这么写是一个意思，组件里面都要这么写：123456789Vue.component(&apos;custom-input&apos;, &#123; props: [&apos;value&apos;], template: ` &lt;input v-bind:value=&quot;value&quot; v-on:input=&quot;$emit(&apos;input&apos;, $event.target.value)&quot; &gt; `&#125;) 对event进行了一次转发。 通过插槽分发内容这里讲的是如何把元素的内容传递给组件，叫做分发内容，使用&lt;slot&gt;这样的关键字来接收。123&lt;alert-box&gt; Something bad happened.&lt;/alert-box&gt; 上面是一个自定义组件，给这个组件直接传递内容，会得到不正确的结果，需要有能接收这个内容的东西，这个就叫插槽。这个地方感觉讲的不清楚，自己尝试了一下。如上图，这里并没有显示出内容来，没有用于接收的东西。 改为：12345678Vue.component(&apos;alert-box&apos;, &#123; template: ` &lt;div class=&quot;demo-alert-box&quot;&gt; &lt;strong&gt;Error!&lt;/strong&gt; &lt;slot&gt;&lt;/slot&gt; &lt;/div&gt; `&#125;) 则：这样才显示出来。 动态组件这段又没看懂。 解析 DOM 模板时的注意事项这段和上面那段有关联，但是好像也是没写清楚，继续等待深度理解。 总结断断续续，花了三天，终于大体看明白了（花了很多时间看这个slot，也把后面的关于slot的看了一遍，基本梳理清楚），感觉这一章节是Vue的核心内容，还需要不断完善这篇笔记。 参考https://cn.vuejs.org/v2/guide/components.html]]></content>
      <categories>
        <category>JavaScript</category>
        <category>Vue</category>
      </categories>
      <tags>
        <tag>JS</tag>
        <tag>Vue</tag>
        <tag>组件基础</tag>
        <tag>component</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vue：学习笔记（五）-Class 与 Style 绑定]]></title>
    <url>%2Fjs%2Fjs-vue-note-css-style-binding.html</url>
    <content type="text"><![CDATA[Vue：学习笔记（五）-Class 与 Style 绑定。 提醒原帖完整收藏于IT老兵驿站，并会不断更新。 前言本篇继续对Vue的【Class 与 Style 绑定】篇进行总结学习。 正文 操作元素的 class 列表和内联样式是数据绑定的一个常见需求。因为它们都是属性，所以我们可以用 v-bind 处理它们：只需要通过表达式计算出字符串结果即可。不过，字符串拼接麻烦且易错。因此，在将 v-bind 用于 class 和 style 时，Vue.js 做了专门的增强。表达式结果的类型除了字符串之外，还可以是对象或数组。 绑定 HTML Class对象语法 我们可以传给 v-bind:class 一个对象，以动态地切换 class：&lt;div v-bind:class=&quot;{ active: isActive }&quot;&gt;&lt;/div&gt; 所谓对象语法，就是样式这里使用一个对象（大括号括起来的是对象，JavaScript的对象写法，这里是一个匿名对象），前缀是class，这个对象的域是在data对象中。1234data: &#123; isActive: true, hasError: false&#125; 还可以这么写：&lt;div v-bind:class=&quot;classObject&quot;&gt;&lt;/div&gt; 123456data: &#123; classObject: &#123; active: true, &apos;text-danger&apos;: false &#125;&#125; 这里是一个具名对象。 这个对象也可以是一个计算属性。 数组语法数组的原理是一样的，语法类似下面：&lt;div v-bind:class=&quot;[activeClass, errorClass]&quot;&gt;&lt;/div&gt; 以数组的形式嵌入，定义在：1234data: &#123; activeClass: &apos;active&apos;, errorClass: &apos;text-danger&apos;&#125; data对象的两个域。 用在组件上还没有看到组件一节，先略过。 绑定内联样式对象语法 v-bind:style 的对象语法十分直观——看着非常像 CSS，但其实是一个 JavaScript 对象。CSS 属性名可以用驼峰式 (camelCase) 或短横线分隔 (kebab-case，记得用单引号括起来) 来命名： 这里使用的还是对象，不过前缀变成了style。 12345&lt;div v-bind:style=&quot;&#123; color: activeColor, fontSize: fontSize + &apos;px&apos; &#125;&quot;&gt;&lt;/div&gt;data: &#123; activeColor: &apos;red&apos;, fontSize: 30&#125; 这个是匿名对象的例子，感觉语法和class一样，可能只是优先级不一样。 具名对象：1234567&lt;div v-bind:style=&quot;styleObject&quot;&gt;&lt;/div&gt;data: &#123; styleObject: &#123; color: &apos;red&apos;, fontSize: &apos;13px&apos; &#125;&#125; 数组语法类似上面。 自动添加前缀这里涉及浏览器前缀的一些知识，参考这里。 摘抄一段： 浏览器厂商们有时会给一些在试验阶段和非标准阶段的css属性或JavaScript API添加前缀, 这样开发者就可以在使用这些试验阶段的代码时能够确保不会被其他标准代码所依赖而导致破坏标准WEB代码的问题。开发人员应该等到浏览器行为被标准化之后再取消前缀。 例如经常看到的： -webkit- (谷歌, Safari, 新版Opera浏览器等)-moz- (火狐浏览器)-o- (旧版Opera浏览器等)-ms- (IE浏览器 和 Edge浏览器) 多重值摘抄记录： 从 2.3.0 起你可以为 style 绑定中的属性提供一个包含多个值的数组，常用于提供多个带前缀的值，例如：&lt;div :style=&quot;{ display: [&#39;-webkit-box&#39;, &#39;-ms-flexbox&#39;, &#39;flex&#39;] }&quot;&gt;&lt;/div&gt;这样写只会渲染数组中最后一个被浏览器支持的值。在本例中，如果浏览器支持不带浏览器前缀的 flexbox，那么就只会渲染 display: flex。 总结这篇内容主要涉及了在Vue中怎么设置CSS，这里涉及了CSS的class和style，这里需要总结一下。 设置CSS一共有三种方式： 内联 - 使用HTML元素的style属性，例如： &lt;h1 style=&quot;color:blue;&quot;&gt;This is a Blue Heading&lt;/h1&gt; 内部 - 使用&lt;head&gt;区域的&lt;style&gt;元素，例如： 123456789&lt;html&gt;&lt;head&gt;&lt;style&gt;body &#123;background-color: powderblue;&#125;h1 &#123;color: blue;&#125;p &#123;color: red;&#125;&lt;/style&gt;&lt;/head&gt;&lt;body&gt; 外部 - 使用外部的CSS文件 123456789101112&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;link rel=&quot;stylesheet&quot; href=&quot;styles.css&quot;&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;This is a heading&lt;/h1&gt;&lt;p&gt;This is a paragraph.&lt;/p&gt;&lt;/body&gt;&lt;/html&gt; 还有一个优先级的关系，可以参考这里。 参考https://cn.vuejs.org/v2/guide/class-and-style.htmlhttps://developer.mozilla.org/zh-CN/docs/Glossary/Vendor_Prefixhttps://www.w3schools.com/html/html_css.asp]]></content>
      <categories>
        <category>JavaScript</category>
        <category>Vue</category>
      </categories>
      <tags>
        <tag>JS</tag>
        <tag>Vue</tag>
        <tag>CSS</tag>
        <tag>Style</tag>
        <tag>绑定</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[十月份计划]]></title>
    <url>%2Fscheme%2F2018-10.html</url>
    <content type="text"><![CDATA[十月份计划。 前言写博客，缺乏了一些计划，感觉有些零零散散，应该梳理一下计划。每次有文章的更新，就在当月计划的这篇文章里面记录一下，这样可以记录下自己的足迹。 正文十月份还剩十天，因为最近的工作要用到Vue，所以计划本月整理Vue的笔记，对照官网，再完成几篇对Vue的学习。以现在的进度，可能两三天才能整理一篇，尽管如此，不想光追求速度，还是需要保证质量，“君子勿速成”，速生的东西往往速死，着急赶出来的东西，往往缺乏价值，饭一口一口吃，事情一件一件办。 今年还剩两个多月，计划把MongoDB的笔记再丰富一些，把基本的使用都总结清楚，整理成一个系列；其余的，现在也说不定，就边走边看吧。]]></content>
      <categories>
        <category>计划</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Vue：学习笔记（四）-计算属性和侦听器]]></title>
    <url>%2Fjs%2Fjs-vue-note-computed.html</url>
    <content type="text"><![CDATA[Vue：学习笔记（四）-计算属性和侦听器。 提醒原帖完整收藏于IT老兵驿站，并会不断更新。 前言参考官网的这里和中文版，总体学习一下计算属性，感觉这一章节总体是比较简单的，做一下笔记来进行总结。思路是，原文写的很清楚的，只做简单的概括；对原文存在疑问的地方，摘抄原文，列举问题，总结概括。 正文计算属性摘录原则： 所以，对于任何复杂逻辑，你都应当使用计算属性。 基础例子1234&lt;div id=&quot;example&quot;&gt; &lt;p&gt;Original message: &quot;&#123;&#123; message &#125;&#125;&quot;&lt;/p&gt; &lt;p&gt;Computed reversed message: &quot;&#123;&#123; reversedMessage &#125;&#125;&quot;&lt;/p&gt;&lt;/div&gt; 12345678910111213var vm = new Vue(&#123; el: &apos;#example&apos;, data: &#123; message: &apos;Hello&apos; &#125;, computed: &#123; // 计算属性的 getter reversedMessage: function () &#123; // `this` 指向 vm 实例 return this.message.split(&apos;&apos;).reverse().join(&apos;&apos;) &#125; &#125;&#125;) 这里的reversedMessage实际上是和message绑定在一起了，message发生变化，则reversedMessage也发生变化。 那这里，存在一个疑问了，计算属性是不是也可以不和基本属性（例如message）发生绑定关系呢？ 计算属性缓存 vs 方法这一段刚好解决了上面提出的这个问题，看来不断地提一提问题，对于理解是很有帮助的，“学而不思则罔”。 我们可以将同一函数定义为一个方法而不是一个计算属性。两种方式的最终结果确实是完全相同的。然而，不同的是计算属性是基于它们的依赖进行缓存的。只在相关依赖发生改变时它们才会重新求值。这就意味着只要 message 还没有发生改变，多次访问 reversedMessage 计算属性会立即返回之前的计算结果，而不必再次执行函数。 这段话很好地解释了什么时候要使用计算属性，为了提高效率，很合理地去利用架构提供的缓存的功能。 计算属性 vs 侦听属性 当你有一些数据需要随着其它数据变动而变动时，你很容易滥用 watch——特别是如果你之前使用过 AngularJS。然而，通常更好的做法是使用计算属性而不是命令式的 watch 回调。 去年学习AngularJS，使用watch函数进行监控，后来在网站上看到很多对于这个watch方式的诟病，说这样会发生抖动，会导致DOM树不断被渲染，这个还需要再深度研究一下。 计算属性的 setter12345678910111213141516// ...computed: &#123; fullName: &#123; // getter get: function () &#123; return this.firstName + &apos; &apos; + this.lastName &#125;, // setter set: function (newValue) &#123; var names = newValue.split(&apos; &apos;) this.firstName = names[0] this.lastName = names[names.length - 1] &#125; &#125;&#125;// ... 侦听器1234567&lt;div id=&quot;watch-example&quot;&gt; &lt;p&gt; Ask a yes/no question: &lt;input v-model=&quot;question&quot;&gt; &lt;/p&gt; &lt;p&gt;&#123;&#123; answer &#125;&#125;&lt;/p&gt;&lt;/div&gt; 123456789101112131415161718192021222324252627282930313233343536373839404142434445&lt;!-- 因为 AJAX 库和通用工具的生态已经相当丰富，Vue 核心代码没有重复 --&gt;&lt;!-- 提供这些功能以保持精简。这也可以让你自由选择自己更熟悉的工具。 --&gt;&lt;script src=&quot;https://cdn.jsdelivr.net/npm/axios@0.12.0/dist/axios.min.js&quot;&gt;&lt;/script&gt;&lt;script src=&quot;https://cdn.jsdelivr.net/npm/lodash@4.13.1/lodash.min.js&quot;&gt;&lt;/script&gt;&lt;script&gt;var watchExampleVM = new Vue(&#123; el: &apos;#watch-example&apos;, data: &#123; question: &apos;&apos;, answer: &apos;I cannot give you an answer until you ask a question!&apos; &#125;, watch: &#123; // 如果 `question` 发生改变，这个函数就会运行 question: function (newQuestion, oldQuestion) &#123; this.answer = &apos;Waiting for you to stop typing...&apos; this.debouncedGetAnswer() &#125; &#125;, created: function () &#123; // `_.debounce` 是一个通过 Lodash 限制操作频率的函数。 // 在这个例子中，我们希望限制访问 yesno.wtf/api 的频率 // AJAX 请求直到用户输入完毕才会发出。想要了解更多关于 // `_.debounce` 函数 (及其近亲 `_.throttle`) 的知识， // 请参考：https://lodash.com/docs#debounce this.debouncedGetAnswer = _.debounce(this.getAnswer, 500) &#125;, methods: &#123; getAnswer: function () &#123; if (this.question.indexOf(&apos;?&apos;) === -1) &#123; this.answer = &apos;Questions usually contain a question mark. ;-)&apos; return &#125; this.answer = &apos;Thinking...&apos; var vm = this axios.get(&apos;https://yesno.wtf/api&apos;) .then(function (response) &#123; vm.answer = _.capitalize(response.data.answer) &#125;) .catch(function (error) &#123; vm.answer = &apos;Error! Could not reach the API. &apos; + error &#125;) &#125; &#125;&#125;)&lt;/script&gt; 对于这个例子，我是这么理解的，要监控中间的变化（例如一段文字输入的中间过程），这个时候使用侦听器就是合理的。 这里还涉及了一个知识点 _.debounce(func, [wait=0], [options={}])Creates a debounced function that delays invoking func until after wait milliseconds have elapsed since the last time the debounced function was invoked. 这个方法是对函数进行延时调用，避免函数被调用过于频繁，在上面的例子中，就是避免因为用户输入很快，而反复被调用，所以中间等待500毫秒。 总结阅读了两遍，总结了一遍，大体把这个章节搞明白了，大概耗时三个小时。 参考https://cn.vuejs.org/v2/guide/computed.html]]></content>
      <categories>
        <category>JavaScript</category>
        <category>Vue</category>
      </categories>
      <tags>
        <tag>JS</tag>
        <tag>Vue</tag>
        <tag>计算属性</tag>
        <tag>computed</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vue：学习笔记（三）-模板语法]]></title>
    <url>%2Fjs%2Fjs-vue-note-syntax.html</url>
    <content type="text"><![CDATA[Vue：学习笔记（三）-模板语法。 提醒原帖完整收藏于IT老兵驿站，并会不断更新。 前言忙了三周，又度过一个丰富的十一，现在腾出手来，继续我的学习和总结。最近找到了Vue的中文网站，但是我不想放弃对英文网站的学习，那样可以更准确地理解原意，可以提高自己的英文水平，所以基于英文网站，对照着中文，这样来学习—-人还是应该有些追求。我发现一个问题，有的章节内容多，有的章节内容少，内容多的，可能一天总结不完，那就可能需要拆成几篇连续的笔记来记录了。 正文模板语法 Vue.js uses an HTML-based template syntax that allows you to declaratively bind the rendered DOM to the underlying Vue instance’s data. All Vue.js templates are valid HTML that can be parsed by spec-compliant browsers and HTML parsers.Under the hood, Vue compiles the templates into Virtual DOM render functions. Combined with the reactivity system, Vue is able to intelligently figure out the minimal number of components to re-render and apply the minimal amount of DOM manipulations when the app state changes.If you are familiar with Virtual DOM concepts and prefer the raw power of JavaScript, you can also directly write render functions instead of templates, with optional JSX support. 我对这里的理解是，模板是一种工具，它不需要你去查找元素，进行赋值等处理（传统的方式），而是进行了单向或者双向的绑定，这样你直接操作这个变量，就是在操作DOM中的那个元素（虚拟DOM树的概念），另外，模板会在合适的时候，进行渲染，这样减少因为频繁的渲染页面的抖动。 插值（Interpolations）最早接触这个概念是在对AngularJS的学习中，应该是AngularJS最早引入了这个概念。 文本1&lt;span&gt;Message: &#123;&#123; msg &#125;&#125;&lt;/span&gt; 双大括号的语法，里面是插值的变量名，变量发生改变，这里也会同时发生改变。 &lt;span v-once&gt;这个将不会改变: &lt;/span&gt;使用 v-once 指令，执行一次性地插值。 原始HTML12&lt;p&gt;Using mustaches: &#123;&#123; rawHtml &#125;&#125;&lt;/p&gt;&lt;p&gt;Using v-html directive: &lt;span v-html=&quot;rawHtml&quot;&gt;&lt;/span&gt;&lt;/p&gt; 双大括号里面包含的内容，会以纯文本的形式显示出来，不会交由浏览器去解释。而想要浏览器去解释这些内容，则需要使用v-html，例如上例。 rawHtml的内容其实是&lt;span style=&quot;color: red&quot;&gt;This should be red.&lt;/span&gt;，则上例的实际显示如下（这个例子原帖讲的有一点不清楚）： Using mustaches: &lt;span style=”color: red”&gt;This should be red.&lt;/span&gt; Using v-html directive: This should be red.（这里应该是红色，为了让这里显示红色，我还研究了一下MD语法，参考这里） 不过一般不建议这么用，因为这样就太容易给XSS（跨站攻击，互联网最常见的一种攻击形式，将来有机会也会总结一下）攻击创造机会。 特性（attribute）这一节其实应该叫属性，不过可能是为了和property区别，这里刻意翻译成了特性，其实是指HTML里面元素的属性，关于HTML元素的名、值、属性的关系可以参考早年写的一篇帖子，那篇讲的是XML，HTML其实一种特殊化的XML，原理是一样的。因为习惯了，以下我还是称呼这个为属性。 属性没法使用Mustache语法，所以就需要有新的指令（directive），指令也应该是AngularJS引入的一个概念，其实是可以被Vue解释的一些固定的字符串，可以接收参数，具有一定的功能。 1&lt;div v-bind:id=&quot;dynamicId&quot;&gt;&lt;/div&gt; 这样id属性就和dynamicId绑定起来了。 不过，对于disabled属性，有点区别，只有当它为true的时候才会被渲染。 使用 JavaScript 表达式Vue支持单个表达式的绑定，如下：123&#123;&#123; number + 1 &#125;&#125;&#123;&#123; ok ? &apos;YES&apos; : &apos;NO&apos; &#125;&#125;&#123;&#123; message.split(&apos;&apos;).reverse().join(&apos;&apos;) &#125;&#125; 但是不支持：12&#123;&#123; var a = 1 &#125;&#125;&#123;&#123; if (ok) &#123; return message &#125; &#125;&#125; 有几点很关键： 这些表达式会在所属 Vue 实例的数据作用域下作为 JavaScript 被解析。有个限制就是，每个绑定都只能包含单个表达式，所以下面的例子都不会生效。 模板表达式都被放在沙盒中，只能访问全局变量的一个白名单，如 Math 和 Date 。你不应该在模板表达式中试图访问用户定义的全局变量。 指令 指令 (Directives) 是带有 v- 前缀的特殊特性。指令特性的值预期是单个 JavaScript 表达式 (v-for 是例外情况，稍后我们再讨论)。指令的职责是，当表达式的值改变时，将其产生的连带影响，响应式地作用于 DOM。 指令可以理解成为一些已经有固化逻辑的函数，它把DOM树和用户的变量关联起来。 参数&lt;a v-bind:href=&quot;url&quot;&gt;...&lt;/a&gt;&lt;a v-on:click=&quot;doSomething&quot;&gt;...&lt;/a&gt;上面这两个指令是带有参数的，分别是href和click。 &lt;p v-if=&quot;seen&quot;&gt;现在你看到我了&lt;/p&gt;上面这个指令是不带参数的。 修饰符 修饰符 (Modifiers) 是以半角句号 . 指明的特殊后缀，用于指出一个指令应该以特殊方式绑定。例如，.prevent 修饰符告诉 v-on 指令对于触发的事件调用 event.preventDefault()： &lt;form v-on:submit.prevent=&quot;onSubmit&quot;&gt;...&lt;/form&gt; 这个地方有点含糊，这里涉及到了Web API里面的event，这个地方的意思应该是对于submit事件，绑定onSubmit这个方法，并且调用event.preventDefault()，组织默认的行为发生。 缩写v-bind的缩写：12345&lt;!-- 完整语法 --&gt;&lt;a v-bind:href=&quot;url&quot;&gt;...&lt;/a&gt;&lt;!-- 缩写 --&gt;&lt;a :href=&quot;url&quot;&gt;...&lt;/a&gt; v-on的缩写：12345&lt;!-- 完整语法 --&gt;&lt;a v-on:click=&quot;doSomething&quot;&gt;...&lt;/a&gt;&lt;!-- 缩写 --&gt;&lt;a @click=&quot;doSomething&quot;&gt;...&lt;/a&gt; 总结 读了原帖大概两遍，阅读、理解加上写笔记，一共花费了大概三个小时，感觉再写下去，耐心就会降低，质量就会降低，会有一些应付的情绪，只好先告一段落，这个部分的内容分为两篇文章了。 今天感觉，剩余的内容也不是很多了，还是合为一篇笔记比较合理，便于将来复习。 参考https://vuejs.org/v2/guide/syntax.htmlhttps://cn.vuejs.org/v2/guide/components.htmlhttps://blog.csdn.net/liuhw4598/article/details/78279737https://developer.mozilla.org/en-US/docs/Web/API/GlobalEventHandlers/onsubmithttps://developer.mozilla.org/en-US/docs/Web/API/Event/preventDefault]]></content>
      <categories>
        <category>JavaScript</category>
        <category>Vue</category>
      </categories>
      <tags>
        <tag>JS</tag>
        <tag>Vue</tag>
        <tag>模板语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JS：对“this”的学习]]></title>
    <url>%2Fjs%2Fjs-this.html</url>
    <content type="text"><![CDATA[JS：对“this”的学习。 前言更多笔记，请参看IT老兵驿站。 有半个多月没有更新博客了，这半个多月一直在加班，实在没有精力更新，现在到了调整期，可以将前一段时间的工作进行一下整理。 之前对JS的this的理解一直有点模糊，这次总结一下，因为在工作中总遇到this的问题，如果一直这么模模糊糊，将会在以后的工作中带来麻烦，而对于这种躲不开的麻烦，早解决肯定要比晚解决好。 这篇帖子是针对参考中的w3schools的一篇帖子进行学习、翻译和理解，但我感觉w3schools这篇帖子层次有点不是太清楚。 正文this是什么例子：12345678var person = &#123; firstName: &quot;John&quot;, lastName : &quot;Doe&quot;, id : 5566, fullName : function() &#123; return this.firstName + &quot; &quot; + this.lastName; &#125;&#125;; 这里的this指代的是什么呢？ What is “this”?In a function definition, this refers to the “owner” of the function.In the example above, this refers to the person object.The person object “owns” the fullName method. 在函数定义中，this指代函数的“拥有者”，例如上面例子中，this就代表person这个对象。 默认绑定 Default BindingWhen used alone, this refers to the Global object.In a browser the Global object is [object Window]: 默认的绑定，单独使用时，this就指代全局对象。个人理解，这一条和上一条不矛盾，this还是指代拥有这个变量或者函数的对象，这个时候是全局变量拥有这个变量，所以就指向了全局变量。 In strict mode, this will be undefined, because strict mode does not allow default binding: 但是在严格模式下，this将会是undefined，因为严格模式不允许默认绑定。 明确绑定 Explicit Function BindingThe call() and apply() methods are predefined JavaScript methods.They can both be used to call an object method with another object as argument. 明确的函数绑定，call()和apply()是JS预定义的方法，他们可以被用于使用另外一个对象作为参数，调用这个对象的方法。 12345678910var person1 = &#123; fullName: function() &#123; return this.firstName + &quot; &quot; + this.lastName; &#125;&#125;var person2 = &#123; firstName:&quot;John&quot;, lastName: &quot;Doe&quot;,&#125;person1.fullName.call(person2); // Will return &quot;John Doe&quot; 看上面这个例子，this指向了person2，最终输出的是person2的属性。 总结这样一梳理，感觉对于this的理解就清晰了。 参考https://www.w3schools.com/js/js_this.asp]]></content>
      <categories>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>JS</tag>
        <tag>this</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vue：学习笔记（二）-实例]]></title>
    <url>%2Fjs%2Fjs-vue-note-instance.html</url>
    <content type="text"><![CDATA[Vue：学习笔记-实例。 提醒原帖完整收藏于IT老兵驿站，并会不断更新。 前言书接前文。继续学习Vue，距离上一篇笔记又有十几天了，因为最近实在是工作太忙了，但还是应该努力坚持。 正文创建Vue实例如何创建一个Vue的实例呢？ var vm = new Vue({ // options }) Vue参考了MVVM模型，这里的vm指代ViewModel。当你创建一个Vue实例的时候，你可以创建一个options对象给它，这个将来会再具体讨论。 数据和方法当一个Vue实例被创建时，它会把所有位于data对象里面的属性加入到Vue响应式系统里面，这样一旦这些属性发生了变化，视图会响应，并且更新相应的值。1234567891011121314151617181920212223// Our data object 这是一个自定义的对象 var data = &#123; a: 1 &#125; // The object is added to a Vue instance 这个对象被加入进了vm实例 var vm = new Vue(&#123; data: data // 这里是一个赋值语句，前面一个data是vm的关键属性对象，后面是上面我们定义的变量 &#125;) // Getting the property on the instance // returns the one from the original data //这里做了一个判断，判断vm的a属性和外面的data的a属性是否相等，因为它们其实是一致的，指向一个实际的对象，所以是相等的。不过，这里的写法是vm.a，而不是vm.data.a。 vm.a == data.a // =&gt; true // Setting the property on the instance // also affects the original data // 用赋值来进行判断 vm.a = 2 data.a // =&gt; 2 // ... and vice-versa // 上面这句话叫做反之亦然 data.a = 3 vm.a // =&gt; 3 这是官网的一个例子，加了一些翻译和注释，方便理解，从中可以看到变量data和vm的关系。 需要注意一个地方，data对象里面的属性只有是在Vue实例创建时就存在的，才会被纳入响应式系统里面去，这也就是说，后来加进去的属性，是不会具有上面这种响应式的能力的。所以，一旦你希望有一个属性能够具有这种能力，但是在一开始你又不确定它的值的话，做法就很明显了，你需要先定义这个属性，并且赋一个初始值，例如： data: { newTodoText: &apos;&apos;, visitCount: 0, hideCompletedTodos: false, todos: [], error: null } 例外的，还有一个用法，Object.freeze()，这个用法是用来不让属性被修改。 var obj = { foo: &apos;bar&apos; } Object.freeze(obj) new Vue({ el: &apos;#app&apos;, data: obj }) &lt;div id=&quot;app&quot;&gt; &lt;p&gt;{{ foo }}&lt;/p&gt; &lt;!-- this will no longer update `foo`! --&gt; &lt;button v-on:click=&quot;foo = &apos;baz&apos;&quot;&gt;Change it&lt;/button&gt; &lt;/div&gt; Vue自身还有一些实例属性和方法，为了和用户定义的区分开，以“$”为前缀。 var data = { a: 1 } var vm = new Vue({ el: &apos;#example&apos;, data: data }) vm.$data === data // =&gt; true vm.$el === document.getElementById(&apos;example&apos;) // =&gt; true // $watch is an instance method vm.$watch(&apos;a&apos;, function (newValue, oldValue) { // This callback will be called when `vm.a` changes }) 实例生命周期的钩子 Each Vue instance goes through a series of initialization steps when it’s created - for example, it needs to set up data observation, compile the template, mount the instance to the DOM, and update the DOM when data changes. Along the way, it also runs functions called lifecycle hooks, giving users the opportunity to add their own code at specific stages. 这里的意思实际是：实例的生命周期被定义为了几个阶段，每个阶段会有一个回调函数来暴露给用户，让用户来进行一些工作，这个很像安卓的设计。 例如： new Vue({ data: { a: 1 }, created: function () { // `this` points to the vm instance console.log(&apos;a is: &apos; + this.a) } }) 这个就是在Vue创建时暴露给用户。 完整的生命周期参考下图： 总结这么细细地读一遍，同时总结一遍，感觉很踏实，其实有些笔记是为了输出，以飨他人，虽然辛苦一点，总是有意义，“好好活，就是做好多有意义的事情；有意义，就是好好活” 参考https://vuejs.org/v2/guide/instance.html]]></content>
      <categories>
        <category>JavaScript</category>
        <category>Vue</category>
      </categories>
      <tags>
        <tag>JS</tag>
        <tag>Vue</tag>
        <tag>笔记</tag>
        <tag>实例</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vue：学习笔记（一）-介绍]]></title>
    <url>%2Fjs%2Fjs-vue-note-introduction.html</url>
    <content type="text"><![CDATA[Vue：学习笔记-介绍。 提醒原帖完整收藏于IT老兵驿站，并会不断更新。 前言17年上半年，学习了一些Vue的知识，但是现在反观回去，感觉在那个时候，因为着急做项目，很多东西消化的不够清楚，这一点同样体现在对angular的学习上，现在有点时间进行修整，那就花点时间去好好整理一下。 正文 Vue (pronounced /vjuː/, like view) is a progressive framework for building user interfaces. Unlike other monolithic frameworks, Vue is designed from the ground up to be incrementally adoptable. The core library is focused on the view layer only, and is easy to pick up and integrate with other libraries or existing projects. On the other hand, Vue is also perfectly capable of powering sophisticated Single-Page Applications when used in combination with modern tooling and supporting libraries. 大体翻译：Vue是一个进步的框架（progressive framework），用来构建用户界面。它不像别的大而全的框架，由很小的部分，逐步增量吸收完善。它的核心库仅仅专注于view层，很容易使用，或者说是和项目的其他库集成。 这段前言，好像是第一次这么清楚地读明白，枉费了作者的一番心血。 如何引入在你的index.html中引入1&lt;script src=&quot;https://cdn.jsdelivr.net/npm/vue/dist/vue.js&quot;&gt;&lt;/script&gt; 这个是开发版本，在控制台会有一些有用的输出。或者： 1&lt;script src=&quot;https://cdn.jsdelivr.net/npm/vue&quot;&gt;&lt;/script&gt; 生产版本，优化了大小和速度。 还有一些别的安装帮助，在Installation ，初学者不建议立刻使用vue-cli（类似一个脚手架），这样你会搞不清原理，但我相信，大多数的人还是会立刻去使用这个，因为立刻可以做出一些东西来，能做出东西来就行，谁会在意什么原理不原理呢？ 陈述式的渲染直接渲染数据到DOM树：html文件中（下文中，上面的代码段都表示是在html文件中，下面的代码段表示是在js文件中，可以在这个在线模拟器上进行尝试）：123&lt;div id=&quot;app&quot;&gt; &#123;&#123; message &#125;&#125;&lt;/div&gt; js文件中：123456var app = new Vue(&#123; el: &apos;#app&apos;, data: &#123; message: &apos;Hello Vue!&apos; &#125;&#125;) 绑定元素属性123456&lt;div id=&quot;app-2&quot;&gt; &lt;span v-bind:title=&quot;message&quot;&gt; Hover your mouse over me for a few seconds to see my dynamically bound title! &lt;/span&gt;&lt;/div&gt; 123456var app2 = new Vue(&#123; el: &apos;#app-2&apos;, data: &#123; message: &apos;You loaded this page on &apos; + new Date().toLocaleString() &#125;&#125;) 条件和循环条件123&lt;div id=&quot;app-3&quot;&gt; &lt;span v-if=&quot;seen&quot;&gt;Now you see me&lt;/span&gt;&lt;/div&gt; 123456var app3 = new Vue(&#123; el: &apos;#app-3&apos;, data: &#123; seen: true &#125;&#125;) 循环1234567&lt;div id=&quot;app-4&quot;&gt; &lt;ol&gt; &lt;li v-for=&quot;todo in todos&quot;&gt; &#123;&#123; todo.text &#125;&#125; &lt;/li&gt; &lt;/ol&gt;&lt;/div&gt; 12345678910var app4 = new Vue(&#123; el: &apos;#app-4&apos;, data: &#123; todos: [ &#123; text: &apos;Learn JavaScript&apos; &#125;, &#123; text: &apos;Learn Vue&apos; &#125;, &#123; text: &apos;Build something awesome&apos; &#125; ] &#125;&#125;) 处理用户输入1234&lt;div id=&quot;app-5&quot;&gt; &lt;p&gt;&#123;&#123; message &#125;&#125;&lt;/p&gt; &lt;button v-on:click=&quot;reverseMessage&quot;&gt;Reverse Message&lt;/button&gt;&lt;/div&gt; 1234567891011var app5 = new Vue(&#123; el: &apos;#app-5&apos;, data: &#123; message: &apos;Hello Vue.js!&apos; &#125;, methods: &#123; reverseMessage: function () &#123; this.message = this.message.split(&apos;&apos;).reverse().join(&apos;&apos;) &#125; &#125;&#125;) 1234&lt;div id=&quot;app-6&quot;&gt; &lt;p&gt;&#123;&#123; message &#125;&#125;&lt;/p&gt; &lt;input v-model=&quot;message&quot;&gt;&lt;/div&gt; 123456var app6 = new Vue(&#123; el: &apos;#app-6&apos;, data: &#123; message: &apos;Hello Vue!&apos; &#125;&#125;) 用组件来构成组件的概念，是一个预定义好的一些选项的Vue的实例。 定义一个组件，语法如下：1234// Define a new component called todo-itemVue.component(&apos;todo-item&apos;, &#123; template: &apos;&lt;li&gt;This is a todo&lt;/li&gt;&apos;&#125;) 其实，这个就相当于自定义了一个HTTP元素，并且这个元素是在js中得到解释的，解释成HTML原生的元素。这样可以把它组装在另外一个组件的模板里：1234&lt;ol&gt; &lt;!-- Create an instance of the todo-item component --&gt; &lt;todo-item&gt;&lt;/todo-item&gt;&lt;/ol&gt; 但是这样，这个组件的内容是固定的，这样没有太大意义，所以，这个内容应该是一个变量，由使用者来定义，所以，这里又设计一个props，来定义这个变量，如下：1234567Vue.component(&apos;todo-item&apos;, &#123; // The todo-item component now accepts a // &quot;prop&quot;, which is like a custom attribute. // This prop is called todo. props: [&apos;todo&apos;], template: &apos;&lt;li&gt;&#123;&#123; todo.text &#125;&#125;&lt;/li&gt;&apos;&#125;) 123456789101112131415&lt;div id=&quot;app-7&quot;&gt; &lt;ol&gt; &lt;!-- Now we provide each todo-item with the todo object it&apos;s representing, so that its content can be dynamic. We also need to provide each component with a &quot;key&quot;, which will be explained later. --&gt; &lt;todo-item v-for=&quot;item in groceryList&quot; v-bind:todo=&quot;item&quot; v-bind:key=&quot;item.id&quot;&gt; &lt;/todo-item&gt; &lt;/ol&gt;&lt;/div&gt; 1234Vue.component(&apos;todo-item&apos;, &#123; props: [&apos;todo&apos;], template: &apos;&lt;li&gt;&#123;&#123; todo.text &#125;&#125;&lt;/li&gt;&apos;&#125;) 12345678910var app7 = new Vue(&#123; el: &apos;#app-7&apos;, data: &#123; groceryList: [ &#123; id: 0, text: &apos;Vegetables&apos; &#125;, &#123; id: 1, text: &apos;Cheese&apos; &#125;, &#123; id: 2, text: &apos;Whatever else humans are supposed to eat&apos; &#125; ] &#125;&#125;) 参考https://vuejs.org/v2/guide/]]></content>
      <categories>
        <category>JavaScript</category>
        <category>Vue</category>
      </categories>
      <tags>
        <tag>JS</tag>
        <tag>Vue</tag>
        <tag>笔记</tag>
        <tag>介绍</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu16.04下升级Python到3.6.5]]></title>
    <url>%2Fpython%2Fupgrade-python-under-ubuntu1604.html</url>
    <content type="text"><![CDATA[原帖存于IT老兵博客。 Ubuntu16.04下升级Python到3.6.5 前言开发一个Python的系统，需要安装Python3.6以上的版本，由于使用的操作系统是Ubuntu16.04，默认带的Python是2.7.12和3.5，不满足需求，所以需要升级Python。 正文这里 有一篇帖子是说从源代码开始安装，这种方式原来尝试过，需要删除系统默认的软链命令，感觉比较粗暴，现在在想有没有更好的方式呢？ 找到一个帖子：http://ubuntuhandbook.org/index.php/2017/07/install-python-3-6-1-in-ubuntu-16-04-lts/，感觉简单了很多，经过了尝试，成功完成。 增加ppa仓库： 1sudo add-apt-repository ppa:jonathonf/python-3.6 add-apt-repository是一个增加apt仓库的命令，参考这里。 升级apt索引，更新python。 123sudo apt-get updatesudo apt-get install python3.6 更换系统默认的软链命令Python3到新的Python3.6。 123sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.5 1sudo update-alternatives --install /usr/bin/python3 python3 /usr/bin/python3.6 2 update-alternatives命令可以修改系统默认命令的软链指向，参考这里，上面两句指令就是修改了系统默认的/usr/bin/python3 的软链指向，指向了两个位置，最后面的1和2是优先级。 通过以下命令，可以切换Python3的指向。 1sudo update-alternatives --config python3 由此，配置完成。 总结初步感觉，这样的修改要好于源代码安装那种方式，这样三个版本的Python可以共存，并且可以切换。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Ubuntu16.04</tag>
        <tag>升级</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[区块链：比特币数据存储]]></title>
    <url>%2Fblockchain%2Fbitcoin-data-storage.html</url>
    <content type="text"><![CDATA[完整的比特币系列笔记收藏于IT老兵驿站。区块链：比特币数据存储。 前言研究一下比特币的数据存储的格式。 正文 There are basically four pieces of data that are maintained:blocks/blk*.dat: the actual Bitcoin blocks, in network format, dumped in raw on disk. They are only needed for rescanning missing transactions in a wallet, reorganizing to a different part of the chain, and serving the block data to other nodes that are synchronizing. 简单翻译： blocks/blk*.dat，实际的区块数据，使用网络格式，直接存储在磁盘上。他们仅仅被用于：一个钱包重新扫描丢失的交易，重新组织去区块链的一部分，给另外的节点进行同步提供区块数据。 blocks/index/*: this is a LevelDB database that contains metadata about all known blocks, and where to find them on disk. Without this, finding a block would be very slow. 简单翻译： blocks/index/*，这是一个LevelDB数据库，包含了所有知道的区块的元数据，和在磁盘的哪里可以找到它们。没有这个，寻找一个区块是非常慢的。 chainstate/*: this is a LevelDB database with a compact representation of all currently unspent transaction outputs and some metadata about the transactions they are from. The data here is necessary for validating new incoming blocks and transactions. It can theoretically be rebuilt from the block data (see the -reindex command line option), but this takes a rather long time. Without it, you could still theoretically do validation indeed, but it would mean a full scan through the blocks (7 GB as of may 2013) for every output being spent. 简单翻译： 这是一个levelDB数据库，以压缩的形式存储所有当前未花费的交易输出（UTXO）以及关于这些交易来源的一些元数据。这里的数据对于验证新传入的块和交易是必要的。这些数据理论上可以从区块数据中重建（参看-reindex 命令选项），但是这需要花费很长时间。没有这些数据，理论上你也可以进行验证，但是它意味着一个全面地对区块 (2013年5月已经达到7GB ) 的扫描，来检查每一笔输出是否被花费。 blocks/rev*.dat: these contain “undo” data. You can see blocks as ‘patches’ to the chain state (they consume some unspent outputs, and produce new ones), and see the undo data as reverse patches. They are necessary for rolling back the chainstate, which is necessary in case of reorganisations.Note that the LevelDB’s are redundant in the sense that they can be rebuilt from the block data. But validation and other operations would become intolerably slow without them. 简单翻译： blocks/rev*.dat，包含着“undo”数据。你可以把区块数据看成是区块链状态（它们消费一些未花费的输出，然后产生新的一些）的补丁，可以把这些undo数据看做是反向的补丁。它们对于回滚区块状态非常重要，而回滚对于重新组织构建这种情况又是非常重要的。 参考https://en.bitcoin.it/wiki/Bitcoin_Core_0.11_(ch_2):_Data_Storage]]></content>
      <categories>
        <category>Blockchain</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>比特币</tag>
        <tag>数据存储</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git：git-pull的用法总结]]></title>
    <url>%2Fgit%2Fgit-pull-1.html</url>
    <content type="text"><![CDATA[Git用法总结系列收藏于IT老兵驿站。Git：git-pull的用法总结。 前言本篇文章总结一下git-pull 的用法，主要过程是基于对官网的完整阅读，记录关键笔记和样例，加上自己的理解。整个过程是这样： 认真读完官网之后，才会知道它到底有多少内容，这样要比一次一次碎片化地去查要节省很多的时间，不这样读一遍，你怎么能知道git-pull有多少功能呢，如果不知道，回头遇到了需要这个功能的时候，都不知道怎么去查，要了解这个命令的外延。 当然，很多内容一下子是记不住的。记录适当的，或者说关键性的笔记来辅助记忆，将来可以多次去查看。 记录学习的心得。 粗读了一遍git-pull的文档，内容很多，恐怕一篇笔记不足以总结到位，可能要分为多篇笔记来总结。 正文语法git pull的作用是从一个仓库或者本地的分支拉取并且整合代码。 1git pull [&lt;options&gt;] [&lt;repository&gt; [&lt;refspec&gt;…​]] 描述git pull相当于 git fetch 跟着一个 git merge FETCH_HEAD。&lt;repository&gt;是仓库的名字，&lt;refspec&gt; 是分支的名字。如果都不写，会有一个默认值。 一个例子： 12345 A---B---C master on origin /D---E---F---G master ^ origin/master in your repository 远程的master分支到了C，本地的开发到了G。 123 A---B---C origin/master / \D---E---F---G---H master git pull之后会生成一个新的H，合并两个分支。 如果发生了冲突，可以使用git reset --merge进行回退。 options（选项）下面摘录几个常用的选项。 –allow-unrelated-historiesBy default, git merge command refuses to merge histories that do not share a common ancestor. This option can be used to override this safety when merging histories of two projects that started their lives independently. As that is a very rareoccasion, no configuration variable to enable this by default exists and will not be added. 允许无关的历史，这个选项，更多是在更改远程仓库的时候用到。 –ffWhen the merge resolves as a fast-forward, only update the branch pointer, without creating a merge commit. This is the default behavior.–no-ffCreate a merge commit even when the merge resolves as a fast-forward. This is the default behaviour when merging an annotated (and possibly signed) tag that is not stored in its natural place in refs/tags/ hierarchy.–ff-onlyRefuse to merge and exit with a non-zero status unless the current HEAD is already up to date or the merge can be resolved as a fast-forward. ff选项，这几个选项是说合并时是否开启fast-forward，快速合并，这个有在另外一篇帖子中详细讲解，这里就不赘述了。 实例实例：默认使用方式 1git pull 按照git branch 设置的默认跟踪的服务器和分支来拉取。 实例： 拉取远程服务器origin的master分支 1git pull origin master 总结git-pull的用法先总结到这里，还有很多需要细化的地方，一口吃不下，需要一口一口来。 参考https://git-scm.com/docs/git-pullhttps://www.atlassian.com/git/tutorials/syncing/git-pull]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>git pull</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB学习笔记（三）：文档]]></title>
    <url>%2Fmongodb%2Fmongodb-study-note-3.html</url>
    <content type="text"><![CDATA[完整的MongoDB学习笔记位于IT老兵博客。MongoDB学习笔记：文档。 前言最近有点忙，足有一周没有继续这个系列（而原计划是用一到两个月的时间完成这个系列的笔记的），按照20英里法则，这样的学习效果不好，今天抽空还是写了一篇，很多事，贵在坚持。 上一篇文章，其实题目起错了，不应该包含文档，因为上一篇文章的内容并没有文档的内容，不过CSDN的MD这种方式，修改题目总是不成功，只好在自己的博客修改，这样两篇文章的题目有些不一致了。 正文文档结构MongoDB的文档相当于MySQL的行，但是格式都是JSON的，而存储的格式是BSON，是二进制的保存JSON的格式。 文档的结构是域（field）-值（value）对，类似如下的结构： 1234567&#123; field1: value1, field2: value2, field3: value3, ... fieldN: valueN&#125; 值字段可以包含任意BSON数据类型，或者其他文档，或者数组，文档数组，例如： 12345678var mydoc = &#123; _id: ObjectId(&quot;5099803df3f4948bd2f98391&quot;), name: &#123; first: &quot;Alan&quot;, last: &quot;Turing&quot; &#125;, birth: new Date(&apos;Jun 23, 1912&apos;), death: new Date(&apos;Jun 07, 1954&apos;), contribs: [ &quot;Turing machine&quot;, &quot;Turing test&quot;, &quot;Turingery&quot; ], views : NumberLong(1250000) &#125; 域的名字和值各有一些限制，这个一般不会触及，所以暂时忽略—-当然，触及的时候，可以查一下手册。 点符号Array（数组）访问数组的方式，是数组名+“.”+索引（索引是从0开始），如下： 1&quot;&lt;array&gt;.&lt;index&gt;&quot; 举个例子（摘自官网）： 12345&#123; ... contribs: [ &quot;Turing machine&quot;, &quot;Turing test&quot;, &quot;Turingery&quot; ], ...&#125; 想访问数组的第三个元素“Turingery”，就使用“contribs.2”。 Embedded Documents（嵌入的文档）想访问嵌入的文档，使用文档名+“.”+“域名”的访问方式，语法如下： 1&quot;&lt;embedded document&gt;.&lt;field&gt;&quot; 举例： 123456&#123; ... name: &#123; first: &quot;Alan&quot;, last: &quot;Turing&quot; &#125;, contact: &#123; phone: &#123; type: &quot;cell&quot;, number: &quot;111-222-3333&quot; &#125; &#125;, ...&#125; “name.last”表示访问name的last域。“contact.phone.number”表示访问contact的phone域的number域。 文档的限制文档的大小最大的BSON文档的大小是16M。 文档域的顺序文档遵循着写的操作顺序 MongoDB preserves the order of the document fields following writeoperations… 文档保留着写操作的顺序–这句话有点没理解，是按照第一次写入的顺序吗？除了： _id域永远是第一位的。 更新有可能会改变顺序。 _id域_id域是主键，如果插入时忽略了，系统会自动加上这个字段。 By default, MongoDB creates a unique index on the _id field during the creation of a collection.The _id field is always the first field in the documents. If the server receives a document that does not have the _id field first, then the server will move the field to the beginning.The _id field may contain values of any BSON data type, other than an array. _id是作为唯一索引的。 _id永远是文档的第一个域。 _id可以是任何BSON类型，除了数组。 文档结构的其他使用用于查询过滤器（这篇帖子已经完成），更新规格文档、索引规格文档，这些需要将来细化，这里就不赘述了，官网这里也是给了一个引子，如果不具体看相应的内容，是没有用的。 总结足有一周没有继续这个系列了，心里有些慌，今天终于又完成一篇，心里略微踏实了一些—-尽快有些仓促。 参考https://docs.mongodb.com/manual/core/document/#bson-document-format]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
        <tag>文档</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下shell命令用法和实例总结：df]]></title>
    <url>%2Flinux%2Fshell-command-df.html</url>
    <content type="text"><![CDATA[完整的Linux下Shell命令总结归档于IT老兵博客。MongoDB如何设计数据模型。 前言关于Linux的命令，之前做过一些整理，为什么整理呢，因为总用，总要一步一步去查，感觉还是应该做些整理，这样查的效率也会高一些，另外做了整理，很多命令可能也就记住了。不过呢，之前的整理，总是感觉有些问题，一时却没有发觉问题在哪里，还是且行且发现吧。 正文df命令用于显示文件系统磁盘空间使用情况。 命令格式df [选项] [文件] 命令功能df（disk filesystem 的简称）用于显示文件系统磁盘空间使用情况。默认显示单位为KB。可以利用该命令来获取硬盘被占用了多少空间，目前还剩下多少空间等信息。 命令参数 -a或–all：全部文件系统列表。 -h或–human-readable：方便阅读方式显示。 -H或–si：等于“-h”，但是计算式，1K=1000，而不是1K=1024。 -i或–inodes：显示inode信息。 -k或–kilobytes：区块为1024字节。 -l或–local：只显示本地文件系统。 -m或–megabytes：区块为1048576字节。 –no-sync：忽略sync命令。 -P或–portability：输出格式为POSIX。 –sync：在取得磁盘信息前，先执行sync命令。 -T或–print-type：文件系统类型。 –block-size=&lt;区块大小&gt;：指定区块大小。 -t&lt;文件系统类型&gt;或–type=&lt;文件系统类型&gt;：只显示选定文件系统的磁盘信息。 -x&lt;文件系统类型&gt;或–exclude-type=&lt;文件系统类型&gt;：不显示选定文件系统的磁盘信息。 –help：显示帮助信息。 –version：显示版本信息。 实用命令常用的命令就是对以上命令参数的单独使用、结合使用。 实例： 检查文件系统磁盘空间使用情况命令：df输出： 123456789101112Filesystem 1K-blocks Used Available Use% Mounted onudev 8196892 0 8196892 0% /devtmpfs 1643224 181376 1461848 12% /run/dev/mapper/ubuntu--vg-root 48914748 37149080 9257892 81% /tmpfs 8216100 0 8216100 0% /dev/shmtmpfs 5120 0 5120 0% /run/locktmpfs 8216100 0 8216100 0% /sys/fs/cgroup/dev/sda1 482922 478464 0 100% /boottmpfs 100 0 100 0% /run/lxcfs/controllers/dev/sdb 980385892 73288 930488860 1% /mnt/datatmpfs 1643224 0 1643224 0% /run/user/0tmpfs 1643224 0 1643224 0% /run/user/1002 上面各列分别是设备名称、总块数、总磁盘空间、已用磁盘空间、可用磁盘空间和文件系统上的挂载点。 实例： 使用字节单位来显示（-h指令的解释是human-readable，就是使用字节单位K、M、G等单位来显示）命令：df -h输出：123456789101112Filesystem Size Used Avail Use% Mounted onudev 7.9G 0 7.9G 0% /devtmpfs 1.6G 178M 1.4G 12% /run/dev/mapper/ubuntu--vg-root 47G 36G 8.9G 81% /tmpfs 7.9G 0 7.9G 0% /dev/shmtmpfs 5.0M 0 5.0M 0% /run/locktmpfs 7.9G 0 7.9G 0% /sys/fs/cgroup/dev/sda1 472M 468M 0 100% /boottmpfs 100K 0 100K 0% /run/lxcfs/controllers/dev/sdb 935G 72M 888G 1% /mnt/datatmpfs 1.6G 0 1.6G 0% /run/user/0tmpfs 1.6G 0 1.6G 0% /run/user/1002 实例： 显示文件系统的类型命令：df -hT输出： 123456789101112Filesystem Type Size Used Avail Use% Mounted onudev devtmpfs 7.9G 0 7.9G 0% /devtmpfs tmpfs 1.6G 178M 1.4G 12% /run/dev/mapper/ubuntu--vg-root ext4 47G 36G 8.9G 81% /tmpfs tmpfs 7.9G 0 7.9G 0% /dev/shmtmpfs tmpfs 5.0M 0 5.0M 0% /run/locktmpfs tmpfs 7.9G 0 7.9G 0% /sys/fs/cgroup/dev/sda1 ext2 472M 468M 0 100% /boottmpfs tmpfs 100K 0 100K 0% /run/lxcfs/controllers/dev/sdb ext4 935G 72M 888G 1% /mnt/datatmpfs tmpfs 1.6G 0 1.6G 0% /run/user/0tmpfs tmpfs 1.6G 0 1.6G 0% /run/user/1002 实例： 显示特定分区的信息描述：-hT将以可读格式显示/root的信息。命令：df -hT /root输出： 1/dev/vda1 ext4 296G 197G 84G 71% / 总结以上总结了一些自己常用的命令，遇到别的需求，可以结合上面的参数，思考怎么可以达到目的，所以就没有必要一一列举了，以后遇到还有很常用的实例，再总结附上，嗯，感觉这样就差不多了。这样就有点思路了，关键是要把用法和参数都总结出来，至于实例，则是总结一些常用的就好了。 参考https://linux.die.net/man/1/df]]></content>
      <categories>
        <category>Linux</category>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>shell</tag>
        <tag>df</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB学习笔记（二）：数据库、集合]]></title>
    <url>%2Fmongodb%2Fmongodb-study-note-2.html</url>
    <content type="text"><![CDATA[完整的MongoDB学习笔记位于IT老兵博客。MongoDB学习笔记。 前言一直在想，这个笔记应该按照什么思路，或者说，原则来记录呢？如果说按照当时学习的路线，那么一定是一条非常弯曲的曲线。还是按照官网的路线，配合着书籍，结合着自己的学习和工作过程来记录吧，这应该是最高效的学习路线—-尽管一开始看上去可能是较为漫长的。 正文MongoDB推出了一个云服务，叫做Atlas，Atlas和本地安装是两种选择，因为基本用的是本地安装，对这一部分还没有深入研究，所以暂时先跳过。 基本概念MongoDB的三个概念：数据库、集合和文档，对应于关系型数据库中的数据库、表和行，这样更容易进行记忆。但是，它们是存在区别的。 如何创建数据库，总结在这里。 如何创建集合，总结在这里。 如何创建（插入）一条文档，总结在这里。 文档验证MongoDB的文档是没有predefined shemas的，没有预定义的模式，这和SQL型的数据库不一样，它的每一条文档的结构都是可以不一样的，同时，MongoDB也提供给你一些对文档进行约束的功能，帮助你可以去约束文档。 对于修改文档的结构，这个就更加简单了，你在更新文档的同时就可以去更新文档的结构，就不需要像MySQL那样去使用DDL语言。 总结重新整理了一下创建数据库、创建集合、创建文档，由这篇文章作为纲领，这样可以提纲挈领，看的比较明白。]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
        <tag>文档</tag>
        <tag>数据库</tag>
        <tag>集合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB学习笔记（一）：启程]]></title>
    <url>%2Fmongodb%2Fmongodb-study-note-1.html</url>
    <content type="text"><![CDATA[完整的MongoDB学习笔记位于IT老兵博客。MongoDB学习笔记。 前言先介绍一下学习MongoDB的历程。 对于MongoDB，是从14年听说的，当时大概地看了一下，没有仔细研究， 说实话，当时心里其实是有点排斥的。因为“浸淫”SQL多年（花了好些年去研究和使用MySQL、Oracle，研究各种范式，做的项目都是基于SQL的），突然出来一种NoSQL和反范式设计的概念，尤其是，突然有一堆刚毕业的，完全不懂范式，没有用范式做过系统的小朋友，跟你说“SQL已经过时”的时候，内心是非常排斥的，“你们连范式都还没有搞明白，都没有做出什么有点规模的系统，居然跟我奢谈说SQL已经过时”。 此外，还有一个因素，那就是一个老程序员，对于新技术的冲击，本能的有些排斥。新技术似乎会降低我们自身的价值，这个时候，我们就变成了保守派，想捍卫一些东西—这是不可取的。 16年，在一家小公司任职，带领着团队研究新技术（小公司往往有机会去研究和使用新技术），大概看了看（看了一本好像是国人写的MongoDB的书），自以为大体是掌握了—自以为是了。 18年，开始真正要用MongoDB做一个项目，才发现之前掌握的，完全不到位。这个时候，端正了心态，踏踏实实地开始学习，到现在有了一些小的心得。 这个时候回想，如果当初不要那么浮光略影地看书，而是踏踏实实地，结合着书籍，写一些实例应用，可能会掌握得更加清楚。这样，总共加起来，花费的学习时间应该会缩短很多，有的时候，要把有的事情做到位才会有效果，正是“纸上得来终觉浅，绝知此事要躬行”。 所以，为了总结这一个过程，记录笔记来跟踪整个学习的过程，到现在为止，已经总结了几篇MongoDB的使用方式，感觉还是不足以完整地记录整个学习过程，所以，再用这种方式记录一下，串联起来。 这个笔记，计划是花一个多月的时间，争取每周输出几篇，每一篇的篇幅不会太长，根据一个统一的原则来进行每篇内容的拆分，最终达到对MongoDB的外围和内延的认识达到一个深度。总共的篇幅，暂时还不确定，达到了最终的目的为止，最后输出一个可以对学习MongoDB很有帮助的系列性的笔记。 本篇笔记，稍微啰嗦一下，现在可以理解很多书籍的前言了，这个时候总想表达一下写作的目的，中间的经历和艰辛，很多心得和感悟，从这个角度来说，本篇其实就是前言了。 准备“工欲善其事必先利其器”，想学好MongoDB，先得选择好的学习资料。从从业十多年的经验中，我得到一个认知，“因快得慢”。举一个例子，当年快毕业，准备出去面试，需要学习linux的一些基本原理，这个时候，摆在面前的有几种资料，一种是《Linux与unix shell编程指南》，这是当时很经典的书籍，但是篇幅较长；另外一种是，速成的教程（原谅我连名字都不记得了，因为实在是没有太多的价值）。当时我果断的选择了后者，结果因为这种速成的教程往往只是讲了一些最没有价值的东西，就像快餐一样，真正有营养的东西，需要慢慢去吸收和消化。后来，其实又花了很多气力，踏踏实实地重来一遍，这样算来，第一遍花费的时间，一点都没有意义，所以，这就是计算机学习，为什么要去读经典的原理，这才是最节省时间的方式，走得越扎实，其实才是走的最快的方式。 官网，https://docs.mongodb.com/， 永远是学习的第一选择，MongoDB的手册官网做的稍微有些复杂，但是它的例子比较丰富，这对于学习起来，帮助很大。不过，官网是英文的，对于很多人来说，是有些困难的（当然，如果想成为一个好的程序员，这个困难是需要客服的）。 Stack Overflow网站，https://stackoverflow.com/， 寻找某些问题答案最好的网站，从10年开始，我已经把它看做是和官网差不多比重的资料网站了。 《MongoDB权威指南》，O’REILLY的书一般质量都还不错，当然，在京东上看看评论，找一本其他评价高的书来作为资料都是可以的。 好了，神器在手，天下我有，准备启程。]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
        <tag>学习笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《6 Rules of Thumb for MongoDB Schema Design》 Part 1 翻译和笔记]]></title>
    <url>%2Fmongodb%2Fmongodb-schema-design-note.html</url>
    <content type="text"><![CDATA[原帖位于IT老兵博客，沉淀着一个IT老兵对于这个行业的多年的认知。MongoDB如何设计数据模型。 前言在工作中遇到了要使用MongoDB，学习MongoDB，肯定不能仅仅停留于对一些指令的简单操作的掌握，就像当初学习MySQL一样，要了解一下如何使用MongoDB来设计数据库。这里，找到一篇很好的文章，转载在下面，配上一定的翻译和学习笔记，原文也不是很复杂，贴上原文，是为了不误导读者，也不误导自己，将来可以不断再纠正其中理解不准确的地方。 正文 By William Zola, Lead Technical Support Engineer at MongoDB “I have lots of experience with SQL, but I’m just a beginner with MongoDB. How do I model a one-to-N relationship?” This is one of the more common questions I get from users attending MongoDB office hours. I don’t have a short answer to this question, because there isn’t just one way, there’s a whole rainbow’s worth of ways. MongoDB has a rich and nuanced vocabulary for expressing what, in SQL, gets flattened into the term “One-to-N”. Let me take you on a tour of your choices in modeling One-to-N relationships. 笔记： MongoDB的新手往往会遇到一个问题，我应该怎么去定义一个one-to-N的关系呢？“there’s a whole rainbow’s worth of ways. ”这句应该怎么理解呢？ There’s so much to talk about here, I’m breaking this up into three parts. In this first part, I’ll talk about the three basic ways to model One-to-N relationships. In the second part I’ll cover more sophisticated schema designs, including denormalization and two-way referencing. And in the final part, I’ll review the entire rainbow of choices, and give you some suggestions for choosing among the thousands (really – thousands) of choices that you may consider when modeling a single One-to-N relationship. 笔记： 这里有很多需要讨论，笔记会将它分为三个部分来讨论。第一部分，也就是本篇文章，来讨论三种建立One-to-N关系模型的基本的方法；第二部分，讨论更复杂的模型设计，包括反范式（denormalization）和双向参考（two-way referencing）；最后一部分，将会复习整个选择的过程，并且给你们一些建立，来在上千的建立一个One-to-N关系的选择中做出判断。 Many beginners think that the only way to model “One-to-N” in MongoDB is to embed an array of sub-documents into the parent document, but that’s just not true. Just because you can embed a document, doesn’t mean you should embed a document. 笔记： 很多初学者会认为在MongoDB中建立一个“One-to-N”的模型只有一种方法，就是嵌入一个子文档的数组（array），这不是事实。确实是这样，看到的很多帖子就是这么去误导别人。 When designing a MongoDB schema, you need to start with a question that you’d never consider when using SQL: what is the cardinality of the relationship? Put less formally: you need to characterize your “One-to-N” relationship with a bit more nuance: is it “one-to-few”, “one-to-many”, or “one-to-squillions”? Depending on which one it is, you’d use a different format to model the relationship. 笔记： 在开始设计一个MongoDB的模式时，你需要考虑一个在使用SQL从来不需要考虑的问题：关系的基数是什么？具体来说，就是要考虑“one-to-few”，“one-to-many”, 或者“one-to-squillions”，这个基数不同，设计的格式也不同。 Basics: Modeling One-to-Few An example of “one-to-few” might be the addresses for a person. This is a good use case for embedding – you’d put the addresses in an array inside of your Person object: 123456789db.person.findOne()&#123; name: &apos;Kate Monster&apos;, ssn: &apos;123-456-7890&apos;, addresses : [ &#123; street: &apos;123 Sesame St&apos;, city: &apos;Anytown&apos;, cc: &apos;USA&apos; &#125;, &#123; street: &apos;123 Avenue Q&apos;, city: &apos;New York&apos;, cc: &apos;USA&apos; &#125; ]&#125; This design has all of the advantages and disadvantages of embedding. The main advantage is that you don’t have to perform a separate query to get the embedded details; the main disadvantage is that you have no way of accessing the embedded details as stand-alone entities. 笔记： 上面这是一个常见One-to-Few的例子，个人信息和地址的关系。好处在于你不用单独执行一个查询去获取嵌入的信息；坏处在于你无法根据作为一个单独的条目去访问一个嵌入的内容。这个例子很形象，在那本MySQL实例中，也涉及到人和地址的关系处理。就是说大千世界的一对多的关系其实不是那么一刀切的，而SQL对这个的处理能力是有限的，或者说SQL原本的设计是没有太多考虑这个因素的。这个应该结合那本书一起来讨论，待完成…… For example, if you were modeling a task-tracking system, each Person would have a number of Tasks assigned to them. Embedding Tasks inside the Person document would make queries like “Show me all Tasks due tomorrow” much more difficult than they need to be. I will cover a more appropriate design for this use case in the next post. Basics: One-to-Many An example of “one-to-many” might be parts for a product in a replacement parts ordering system. Each product may have up to several hundred replacement parts, but never more than a couple thousand or so. (All of those different-sized bolts, washers, and gaskets add up.) This is a good use case for referencing – you’d put the ObjectIDs of the parts in an array in product document. (For these examples I’m using 2-byte ObjectIDs because they’re easier to read: real-world code would use 12-byte ObjectIDs.) Each Part would have its own document: 12345678db.parts.findOne()&#123; _id : ObjectID(&apos;AAAA&apos;), partno : &apos;123-aff-456&apos;, name : &apos;#4 grommet&apos;, qty: 94, cost: 0.94, price: 3.99 Each Product would have its own document, which would contain an array of ObjectID references to the Parts that make up that Product: 1234567891011db.products.findOne()&#123; name : &apos;left-handed smoke shifter&apos;, manufacturer : &apos;Acme Corp&apos;, catalog_number: 1234, parts : [ // array of references to Part documents ObjectID(&apos;AAAA&apos;), // reference to the #4 grommet above ObjectID(&apos;F17C&apos;), // reference to a different Part ObjectID(&apos;D2AA&apos;), // etc ] You would then use an application-level join to retrieve the parts for a particular product: 1234// Fetch the Product document identified by this catalog numberproduct = db.products.findOne(&#123;catalog_number: 1234&#125;);// Fetch all the Parts that are linked to this Productproduct_parts = db.parts.find(&#123;_id: &#123; $in : product.parts &#125; &#125; ).toArray() ; 笔记： 这个例子是产品和配件的关系，是One-to-Many的关系。产品会有很多的配件，所以这里使用ObjectID来关联，这是一个单项关联。这个例子也是很常见的用来描述One-to-Many关系的。 For efficient operation, you’d need to have an index on ‘products.catalog_number’. Note that there will always be an index on ‘parts._id’, so that query will always be efficient. This style of referencing has a complementary set of advantages and disadvantages to embedding. Each Part is a stand-alone document, so it’s easy to search them and update them independently. One trade off for using this schema is having to perform a second query to get details about the Parts for a Product. (But hold that thought until we get to denormalizing in part 2.) 笔记： 好处在于每一个配件都有一个独立的文档，很容易查询和更新。交换就是需要单独执行一个查询去获取配件信息。 As an added bonus, this schema lets you have individual Parts used by multiple Products, so your One-to-N schema just became an N-to-N schema without any need for a join table! Basics: One-to-Squillions An example of “one-to-squillions” might be an event logging system that collects log messages for different machines. Any given host could generate enough messages to overflow the 16 MB document size, even if all you stored in the array was the ObjectID. This is the classic use case for “parent-referencing” – you’d have a document for the host, and then store the ObjectID of the host in the documents for the log messages. 12345678910111213db.hosts.findOne()&#123; _id : ObjectID(&apos;AAAB&apos;), name : &apos;goofy.example.com&apos;, ipaddr : &apos;127.66.66.66&apos;&#125;db.logmsg.findOne()&#123; time : ISODate(&quot;2014-03-28T09:42:41.382Z&quot;), message : &apos;cpu is on fire!&apos;, host: ObjectID(&apos;AAAB&apos;) // Reference to the Host document&#125; You’d use a (slightly different) application-level join to find the most recent 5,000 messages for a host: 1234// find the parent ‘host’ documenthost = db.hosts.findOne(&#123;ipaddr : &apos;127.66.66.66&apos;&#125;); // assumes unique index// find the most recent 5000 log message documents linked to that hostlast_5k_msg = db.logmsg.find(&#123;host: host._id&#125;).sort(&#123;time : -1&#125;).limit(5000).toArray() 笔记： 主机和日志的关系来体现One-to-Squillions，区别在于关系建立在了孩子身上，孩子指向了父亲。 Recap So, even at this basic level, there is more to think about when designing a MongoDB schema than when designing a comparable relational schema. You need to consider two factors: Will the entities on the “N” side of the One-to-N ever need to stand alone?What is the cardinality of the relationship: is it one-to-few; one-to-many; or one-to-squillions? 笔记： 在设计关系时，你需要考虑两个因素： One-to-N的“N”这边需要单独作为一个条目吗？关系的基数是什么：one-to-few；one-to-many；或者 one-to-squillions？Based on these factors, you can pick one of the three basic One-to-N schema designs: Embed the N side if the cardinality is one-to-few and there is no need to access the embedded object outside the context of the parent objectUse an array of references to the N-side objects if the cardinality is one-to-many or if the N-side objects should stand alone for any reasonsUse a reference to the One-side in the N-side objects if the cardinality is one-to-squillions笔记： 基于这些因素，你可以考虑这三个基本模式设计： 如果基数是one-to-few，并且在父对象的上下文之外没有访问嵌入的对象的需求，那么嵌入N边。如果基数是one-to-many，或者N边的对象基于一些原因需要单独展示，那么使用一个数组来指向N边的对象。如果基数是one-to-squillions，使用一个参考去指向One那边。 总结学习和梳理了这篇文章，感觉思路清晰了很多，MongoDB是在One-to-N这个领域做了很多设计，这可能也是跟当前的One-to-N的需求越来越多，而SQL对这个支持有限有关系。 待办的事情，配合总结一下MySQL的设计模式。]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
        <tag>schema</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java：Shiro的架构学习笔记]]></title>
    <url>%2Fjava%2Fjava-shiro-note.html</url>
    <content type="text"><![CDATA[原帖位于IT老兵博客，沉淀着一个IT老兵对于这个行业的认知。Java：Shiro的架构学习笔记。 前言张开涛的第一章 Shiro简介——《跟我学Shiro》，其实是解读了一下Shiro的架构这篇文章，本着寻根究底的态度，我再一次去阅读这篇文章。为什么说是再一次呢？因为之前读过好几次了，不过就是没有完全理解明白，自己也说不好卡在哪里了，包括张开涛的文章，我也读过两遍了，这次第三遍读，一下子豁然开朗，然后不明白之前为啥就没读明白。 正文3个主要的概念：Subject, SecurityManager和Realms。 Subject可以是一个用户，但不仅仅可以代表一个用户，所有对这个系统的外部请求的主体都可以看成是一个Subject，例如一个service，这里是做了一个抽象概括的设计，这个我能理解，如果你理解不了的话，那说明你还没有接触过相关的业务，例如SSO，那就先把它理解成一个用户，也没有关系。将来总有一天，你会明白，会回来和我一起唱这首《当当当》。 SecurityManager Shiro设计的核心的逻辑都在这里面，但是，我们应该可以先不理会它是怎么工作的，先把它当做一个黑匣子，它有它自己运行的逻辑。 Realms 这个单词的意思是领域，范围。原文这么说： Realms act as the ‘bridge’ or ‘connector’ between Shiro and your application’s security data. When it comes time to actually interact with security-related data like user accounts to perform authentication (login) and authorization (access control), Shiro looks up many of these things from one or more Realms configured for an application. In this sense a Realm is essentially a security-specific DAO: it encapsulates connection details for data sources and makes the associated data available to Shiro as needed. When configuring Shiro, you must specify at least one Realm to use for authentication and/or authorization. The SecurityManager may be configured with multiple Realms, but at least one is required. 就是说和安全相关数据（security-specific）打交道的是这个对象，有关认证、授权都是通过它来打交道，或者说，通过不同的realm来和相关的“机构”（打个比方）打交道，每个机构有自己的realm，再或者说，realm可以理解成DAO，去访问相关的数据。 更具体的分析： Subject：A security-specific ‘view’ of the entity (user, 3rd-party service, cron job, etc) currently interacting with the software. 一个实体的安全相关的view–这个概念还需要好好理解一下，怎么被称为一个view呢？ SecurityManager又分为了一些子模块： Authenticator (org.apache.shiro.authc.Authenticator)The Authenticator is the component that is responsible for executing and reacting to authentication (log-in) attempts by users. When a user tries to log-in, that logic is executed by the Authenticator. The Authenticator knows how to coordinate with one or more Realms that store relevant user/account information. The data obtained from these Realms is used to verify the user’s identity to guarantee the user really is who they say they are.Authentication Strategy (org.apache.shiro.authc.pam.AuthenticationStrategy)If more than one Realm is configured, the AuthenticationStrategy will coordinate the Realms to determine the conditions under which an authentication attempt succeeds or fails (for example, if one realm succeeds but others fail, is the attempt successful? Must all realms succeed? Only the first?). Authenticator：认证器，用来负责用户登录认证，它对应着一个或者多个Realm。Authentication Strategy：认证策略，如果多个Realm 被配置，那么Authentication Strategy来负责协调这些Realm 产生矛盾的时候，该如何处理，例如一个realm成功，而其它的失败了，改怎么办，等等。在这一点上，张开涛的文章解释的不是太准确。 Authrizer：授权器，负责确认用户的访问权限。 SessionManager (org.apache.shiro.session.mgt.SessionManager)The SessionManager knows how to create and manage user Session lifecycles to provide a robust Session experience for users in all environments. This is a unique feature in the world of security frameworks - Shiro has the ability to natively manage user Sessions in any environment, even if there is no Web/Servlet or EJB container available. By default, Shiro will use an existing session mechanism if available, (e.g. Servlet Container), but if there isn’t one, such as in a standalone application or non-web environment, it will use its built-in enterprise session management to offer the same programming experience. The SessionDAO exists to allow any datasource to be used to persist sessions.SessionDAO (org.apache.shiro.session.mgt.eis.SessionDAO)The SessionDAO performs Session persistence (CRUD) operations on behalf of the SessionManager. This allows any data store to be plugged in to the Session Management infrastructure. SessionManager：session管理器，Shiro没有完全依赖HTTP的session，而是设计了一个独立的session。SessionDAO：session的DAO，用来处理session数据的保存。 CacheManager：缓存管理器。 Cryptography：加密模块。 Realms：上面介绍过。 SecurityManager这个是核心，需要反复理解的是这个，下面又用了一些篇幅来介绍这个，不过在没有完全实践之前，总还是不明白，所以就先不总结了。 总结又阅读了一遍架构这篇文章，结合着张开涛的文章，感觉明白了不少，现在感觉Shiro 还是挺简单的，有个两三天应该就大体理解了，不明白当时怎么就堵住了，陷入了思维的死胡同。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>shiro</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git：git-reflog的用法总结]]></title>
    <url>%2Fgit%2Fgit-reflog.html</url>
    <content type="text"><![CDATA[原帖收藏于IT老兵驿站，传递一个IT老兵在凋零前的光和氧。git-reflog的用法总结。 前言git-reflog是用来恢复本地错误操作很重要的一个命令，所以在这里对它进行一下整理。 正文概要管理reflog信息。 语法1git reflog &lt;subcommand&gt; &lt;options&gt; 具体的用法 1234git reflog [show] [log-options] [&lt;ref&gt;]git reflog expire [--expire=&lt;time&gt;] [--expire-unreachable=&lt;time&gt;] [--rewrite] [--updateref] [--stale-fix] [--dry-run | -n] [--verbose] [--all | &lt;refs&gt;…​]git reflog delete [--rewrite] [--updateref] [--dry-run | -n] [--verbose] ref@&#123;specifier&#125;…​git reflog exists &lt;ref&gt; Reference logs, or “reflogs”, record when the tips of branches and other references were updated in the local repository. 这句话怎么理解呢，记录了“when”，时间？ 翻译：Reference logs（参考日志），或者叫做”reflogs”，记录了分支的tips（提示信息？）或者其他参考在本地仓库被更新的时间（when）。 问题来了，这个参考日志的作用是什么，和日志又有什么区别呢？ 找到了这篇帖子： 1234567git log shows the current HEAD and its ancestry. That is, it prints the commit HEAD points to, then its parent, its parent, and so on. It traverses back through the repo&apos;s ancestry, by recursively looking up each commit&apos;s parent.(In practice, some commits have more than one parent. To see a more representative log, use a command like git log --oneline --graph --decorate.)git reflog doesn&apos;t traverse HEAD&apos;s ancestry at all. The reflog is an ordered list of the commits that HEAD has pointed to: it&apos;s undo history for your repo. The reflog isn&apos;t part of the repo itself (it&apos;s stored separately to the commits themselves) and isn&apos;t included in pushes, fetches or clones; it&apos;s purely local.Aside: understanding the reflog means you can&apos;t really lose data from your repo once it&apos;s been committed. If you accidentally reset to an older commit, or rebase wrongly, or any other operation that visually &quot;removes&quot; commits, you can use the reflog to see where you were before and git reset --hard back to that ref to restore your previous state. Remember, refs imply not just the commit but the entire history behind it. 上面就讲的比较清楚了，总结一下： git log是显示当前的HEAD和它的祖先的，递归是沿着当前指针的父亲，父亲的父亲，……，这样的原则。git reflog根本不遍历HEAD的祖先。它是HEAD所指向的一个顺序的提交列表：它的undo历史。reflog并不是repo（仓库）的一部分，它单独存储，而且不包含在pushes，fetches或者clones里面，它纯属是本地的。reflog可以很好地帮助你恢复你误操作的数据，例如你错误地reset了一个旧的提交，或者rebase，……，这个时候你可以使用reflog去查看在误操作之前的信息，并且使用git reset --hard 去恢复之前的状态。下面研究一下这个命令的具体用法。 先了解一下git的版本表示方法： HEAD@{2} means “where HEAD used to be two moves ago”, master@{one.week.ago}means “where master used to point to one week ago in this local repository” HEAD@{2}表示HEAD指针在两次移动之前的情况；而 master@{one.week.ago}表示master在本地仓库一周之前的情况。 “show”子命令显示所指定的参考的日志。 实例： 显示HEAD的reflog。 123456789101112$ git reflog showef64f10 (HEAD -&gt; BlueLake_theme) HEAD@&#123;0&#125;: commit: 新增ethereum-programming-intr oduction122e0ec (origin/BlueLake_theme) HEAD@&#123;1&#125;: commit: 移除了冗余的ethereum-rationale 文章c17fbbb HEAD@&#123;2&#125;: commit: 新增git-change-server-password文章1603d1a HEAD@&#123;3&#125;: pull: Merge made by the &apos;recursive&apos; strategy.0ce1e93 HEAD@&#123;4&#125;: commit: 新增了以太坊原理c73503c HEAD@&#123;5&#125;: commit: 修改了-X-Frame-Options的关键字6af02f6 HEAD@&#123;6&#125;: commit: 新增了git-tag的文章；修改了git其他的文章，规范了名字、 关键字9087fbd HEAD@&#123;7&#125;: commit: 新增了gti-reset文章039d95c HEAD@&#123;8&#125;: commit: 移除了没用的目录ff72601 HEAD@&#123;9&#125;: commit: 修改成了next主题ef64f10 (HEAD -&gt; BlueLake_theme) HEAD@&#123;0&#125;: commit: 新增ethereum-programming-intr oduction 从上图可以看到，几乎所有的操作都记录在其中，这个就像MySQL，随时可以回滚。 “expire”子命令会删除掉更老的reflog条目。 “delete”子命令从reflog中删除一个条目。 “exists”子命令检查一个ref是否有一个reflog。 这几个命令就相对比较简单了，以后再尝试了。 参考https://git-scm.com/docs/git-reflog]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>用法</tag>
        <tag>git reflog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[区块链：教程 | 以太坊智能合约编程之菜鸟教程及学习笔记]]></title>
    <url>%2Fblockchain%2Fethereum-programming-introduction.html</url>
    <content type="text"><![CDATA[区块链：教程 | 以太坊智能合约编程之菜鸟教程及学习笔记。 这篇介绍以太坊合约的文章写得很好，在查找了这么多资料，进行对比之后，感觉阅读这一篇就可以大体理解以太坊编程的原理，如果对个别的知识点还有点含糊，可以相应地去查一查，就是以这篇为主干，别的资料为辅。稍微整理了一下格式，以及修改了一些半角符号。 译注：原文首发于ConsenSys开发者博客，原作者为Eva以及ConsenSys的开发团队。如果您想要获取更多及时信息，可以访问ConsenSys首页点击左下角Newsletter订阅邮件。本文的翻译获得了ConsenSys创始人Lubin先生的授权。 有些人说以太坊太难对付，于是我们(译注：指Consensys, 下同)写了这篇文章来帮助大家学习如何利用以太坊编写智能合约和应用。这里所用到的工具，钱包，应用程序以及整个生态系统仍处于开发状态，它们将来会更好用！ 第一部分概述，讨论了关键概念，几大以太坊客户端以及写智能合约用到的编程语言。 第二部分讨论了总体的工作流程，以及目前流行的一些DApp框架和工具。 第三部分主要关于编程，我们将学习如何使用Truffle来为智能合约编写测试和构建DApp。 第一部分 概述如果你对诸如比特币以及其工作原理等密码学货币的概念完全陌生，我们建议你先看看Andreas Antonopoulos所著的Bitcoin Book的头几章，然后读一下以太坊白皮书。(译注：以太坊白皮书中文版请看 http://ethfans.org/posts/ethereum-whitepaper) 如果你觉得白皮书中的章节太晦涩，也可以直接动手来熟悉以太坊。在以太坊上做开发并不要求你理解所有那些“密码经济计算机科学”(crypto economic computer science)，而白皮书的大部分是关于以太坊想对于比特币架构上的改进。 新手教程ethereum.org提供了官方的新手入门教程，以及一个代币合约和众筹合约的教程。合约语言Solidity也有官方文档。学习智能合约的另一份不错的资料（也是我的入门资料）是dappsForBeginners，不过现在可能有些过时了。 这篇文章的目的是成为上述资料的补充，同时介绍一些基本的开发者工具，使入门以太坊，智能合约以及构建DApps(decentralized apps, 分布式应用)更加容易。我会试图按照我自己(依然是新手)的理解来解释工作流程中的每一步是在做什么，我也得到了ConsenSys酷酷的开发者们的许多帮助。 基本概念了解这些名词是一个不错的开始： 公钥加密系统。 Alice有一把公钥和一把私钥。她可以用她的私钥创建数字签名，而Bob可以用她的公钥来验证这个签名确实是用Alice的私钥创建的，也就是说，确实是Alice的签名。当你创建一个以太坊或者比特币钱包的时候，那长长的0xdf...5f地址实质上是个公钥，对应的私钥保存某处。类似于Coinbase的在线钱包可以帮你保管私钥，你也可以自己保管。如果你弄丢了存有资金的钱包的私钥，你就等于永远失去了那笔资金，因此你最好对私钥做好备份。过来人表示：通过踩坑学习到这一点是非常痛苦的… 点对点网络。 就像BitTorrent, 以太坊分布式网络中的所有节点都地位平等，没有中心服务器。(未来会有半中心化的混合型服务出现为用户和开发者提供方便，这我们后面会讲到。) 区块链。 区块链就像是一个全球唯一的帐簿，或者说是数据库，记录了网络中所有交易历史。 以太坊虚拟机(EVM)。 它让你能在以太坊上写出更强大的程序（比特币上也可以写脚本程序）。它有时也用来指以太坊区块链，负责执行智能合约以及一切。 节点。 你可以运行节点，通过它读写以太坊区块链，也即使用以太坊虚拟机。完全节点需要下载整个区块链。轻节点仍在开发中。 矿工。 挖矿，也就是处理区块链上的区块的节点。这个网页可以看到当前活跃的一部分以太坊矿工：stats.ethdev.com。 工作量证明。 矿工们总是在竞争解决一些数学问题。第一个解出答案的(算出下一个区块)将获得以太币作为奖励。然后所有节点都更新自己的区块链。所有想要算出下一个区块的矿工都有与其他节点保持同步，并且维护同一个区块链的动力，因此整个网络总是能达成共识。(注意：以太坊正计划转向没有矿工的权益证明系统(POS)，不过那不在本文讨论范围之内。) 以太币。 缩写ETH。一种你可以购买和使用的真正的数字货币。这里是可以交易以太币的其中一家交易所的走势图。在写这篇文章的时候，1个以太币价值65美分。 Gas。(汽油) 在以太坊上执行程序以及保存数据都要消耗一定量的以太币，Gas是以太币转换而成。这个机制用来保证效率。 DApp。 以太坊社区把基于智能合约的应用称为去中心化的应用程序(Decentralized App)。DApp的目标是(或者应该是)让你的智能合约有一个友好的界面，外加一些额外的东西，例如IPFS（可以存储和读取数据的去中心化网络，不是出自以太坊团队但有类似的精神)。DApp可以跑在一台能与以太坊节点交互的中心化服务器上，也可以跑在任意一个以太坊平等节点上。(花一分钟思考一下：与一般的网站不同，DApp不能跑在普通的服务器上。他们需要提交交易到区块链并且从区块链而不是中心化数据库读取重要数据。相对于典型的用户登录系统，用户有可能被表示成一个钱包地址而其它用户数据保存在本地。许多事情都会与目前的web应用有不同架构。) 如果想看看从另一个新手视角怎么理解这些概念，请读Just Enough Bitcoin for Ethereum。 以太坊客户端，智能合约语言编写和部署智能合约并不要求你运行一个以太坊节点。下面有列出基于浏览器的IDE和API。但如果是为了学习的话，还是应该运行一个以太坊节点，以便理解其中的基本组件，何况运行节点也不难。 运行以太坊节点可用的客户端以太坊有许多不同语言的客户端实现（即多种与以太坊网络交互的方法），包括C++, Go, Python, Java, Haskell等等。为什么需要这么多实现？不同的实现能满足不同的需求（例如Haskell实现的目标是可以被数学验证），能使以太坊更加安全，能丰富整个生态系统。 在写作本文时，我使用的是Go语言实现的客户端geth (go-ethereum)，其他时候还会使用一个叫testrpc的工具, 它使用了Python客户端pyethereum。后面的例子会用到这些工具。 注: 我曾经使用过C++的客户端，现在仍然在用其中的ethminer组件和geth配合挖矿，因此这些不同的组件是可以一起工作的。关于挖矿：挖矿很有趣，有点像精心照料你的室内盆栽，同时又是一种了解整个系统的方法。虽然以太币现在的价格可能连电费都补不齐，但以后谁知道呢。人们正在创造许多酷酷的DApp, 可能会让以太坊越来越流行。 交互式控制台。 客户端运行起来后，你就可以同步区块链，建立钱包，收发以太币了。使用geth的一种方式是通过Javascript控制台（JavaScript console, 类似你在chrome浏览器里面按F12出来的那个，只不过是跑在终端里）。此外还可以使用类似cURL的命令通过JSON RPC来与客户端交互。本文的目标是带大家过一边DApp开发的流程，因此这块就不多说了。但是我们应该记住这些命令行工具是调试，配置节点，以及使用钱包的利器。 在测试网络运行节点。 如果你在正式网络运行geth客户端，下载整个区块链与网络同步会需要相当时间。（你可以通过比较节点日志中打印的最后一个块号和stats.ethdev.com上列出的最新块来确定是否已经同步。) 另一个问题是在正式网络上跑智能合约需要实实在在的以太币。在测试网络上运行节点的话就没有这个问题。此时也不需要同步整个区块链，创建一个自己的私有链就勾了，对于开发来说更省时间。 testrpc。 用geth可以创建一个测试网络，另一种更快的创建测试网络的方法是使用testrpc。Testrpc可以在启动时帮你创建一堆存有资金的测试账户。它的运行速度也更快因此更适合开发和测试。你可以从testrpc起步，然后随着合约慢慢成型，转移到geth创建的测试网络上 - 启动方法很简单，只需要指定一个networkid：geth --networkid &quot;12345&quot;。这里是testrpc的代码仓库，下文我们还会再讲到它。 接下来我们来谈谈可用的编程语言，之后就可以开始真正的编程了。 写智能合约用的编程语言用Solidity就好。 要写智能合约有好几种语言可选：有点类似Javascript的Solidity, 文件扩展名是.sol和Python接近的Serpent, 文件名以.se结尾。还有类似Lisp的LLL。Serpent曾经流行过一段时间，但现在最流行而且最稳定的要算是Solidity了，因此用Solidity就好。听说你喜欢Python? 用Solidity。 solc编译器。 用Solidity写好智能合约之后，需要用solc来编译。它是一个来自C++客户端实现的组件（又一次，不同的实现产生互补），这里是安装方法。如果你不想安装solc也可以直接使用基于浏览器的编译器，例如Solidity real-time compiler或者Cosmo。后文有关编程的部分会假设你安装了solc。 注意：以太坊正处于积极的开发中，有时候新的版本之间会有不同步。确认你使用的是最新的dev版本，或者稳定版本。如果遇到问题可以去以太坊项目对应的Gitter聊天室或者forums.ethereum.org上问问其他人在用什么版本。 web3.js API。 当Solidity合约编译好并且发送到网络上之后，你可以使用以太坊的web3.js JavaScript API来调用它，构建能与之交互的web应用。 以上就是在以太坊上编写智能合约和构建与之交互的DApp所需的基本工具。 第二部分 DApp框架，工具以及工作流程DApp开发框架虽然有上文提到的工具就可以进行开发了，但是使用社区大神们创造的框架会让开发更容易。 Truffle and Embark。 是Truffle把我领进了门。在Truffle出现之前的那个夏天，我目睹了一帮有天分的学生是如何不眠不休的参加一个hackathon（编程马拉松）活动的，虽然结果相当不错，但我还是吓到了。然后Truffle出现了，帮你处理掉大量无关紧要的小事情，让你可以迅速进入写代码-编译-部署-测试-打包DApp这个流程。另外一个相似的DApp构建与测试框架是Embark。我只用过Truffle, 但是两个阵营都拥有不少DApp大神。 Meteor。 许多DApp开发者使用的另一套开发栈由web3.js和Meteor组成，Meteor是一套通用webapp开发框架（ethereum-meteor-wallet项目提供了一个很棒的入门实例，而SilentCiero正在构建大量Meteor与web3.js和DApp集成的模板）。我下载并运行过一些不错的DApp是以这种方式构造的。在11月9日至13日的以太坊开发者大会ÐΞVCON1上将有一些有趣的讨论，是关于使用这些工具构建DApp以及相关最佳实践的（会议将会在YouTube上直播）。 APIs。 BlockApps.net打算提供一套RESTful API给DApp使用以免去开发者运行本地节点的麻烦，这个中心化服务是基于以太坊Haskell实现的。这与DApp的去中心化模型背道而驰，但是在本地无法运行以太坊节点的场合非常有用，比如在你希望只有浏览器或者使用移动设备的用户也能使用你的DApp的时候。BlockApps提供了一个命令行工具bloc，注册一个开发者帐号之后就可以使用。 许多人担心需要运行以太坊节点才能使用DApp的话会把用户吓跑，其实包括BlockApps在内的许多工具都能解决这个问题。Metamask允许你在浏览器里面使用以太坊的功能而无需节点，以太坊官方提供的AlethZero或者AlethOne是正在开发中有易用界面的客户端，ConsenSys正在打造一个轻钱包LightWallet，这些工具都会让DApp的使用变得更容易。轻客户端和水平分片(sharding)也在计划和开发之中。这是一个能进化出混合架构的P2P生态系统。 智能合约集成开发环境 (IDE)IDE。 以太坊官方出品了用来编写智能合约的Mix IDE，我还没用过但会尽快一试。 基于浏览器的IDE。 Solidity real-time compiler和Cosmo都可以让你快速开始在浏览器中编写智能合约。你甚至可以让这些工具使用你的本地节点，只要让本地节点开一个端口（注意安全！这些工具站点必须可信，而且千万不要把你的全部身家放在这样一个本地节点里面！Cosmo UI上有如何使用geth做到这一点的指引）。在你的智能合约调试通过之后，可以用开发框架来给它添加用户界面和打包成DApp，这正是Truffle的工作，后面的编程章节会有详细讲解。 Ether.Camp正在开发另一个强大的企业级浏览器IDE。他们的IDE将支持沙盒测试网络，自动生成用于测试的用户界面（取代后文将展示的手动编写测试），以及一个测试交易浏览器test.ether.camp。当你的合约准备正式上线之前，使用他们的测试网络会是确保你的智能合约在一个接近真实的环境工作正常的好方法。他们也为正式网络提供了一个交易浏览器frontier.ether.camp，上面可以看到每一笔交易的细节。在本文写作时Ether.Camp的IDE还只能通过邀请注册，预计很快会正式发布。 合约和Dapp示例。 在Github上搜索DApp仓库和.sol文件可以看到进行中的有趣东西。这里有一个DApp大列表：dapps.ethercasts.com，不过其中一些项目已经过时。Ether.fund/contracts上有一些Solidity和Serpent写的合约示例，但是不清楚这些例子有没有经过测试或者正确性验证。11月12日的开发者大会ÐΞVCON1将会有一整天的DApp主题演讲。 部署智能合约的流程流程如下： 启动一个以太坊节点 (例如geth或者testrpc)。 使用solc 编译 智能合约。 =&gt; 获得二进制代码。 将编译好的合约部署到网络。（这一步会消耗以太币，还需要使用你的节点的默认地址或者指定地址来给合约签名。） =&gt; 获得合约的区块链地址和ABI（合约接口的JSON表示，包括变量，事件和可以调用的方法）。(译注：作者在这里把ABI与合约接口弄混了。ABI是合约接口的二进制表示。) 用web3.js提供的JavaScript API来调用合约。（根据调用的类型有可能会消耗以太币。） 下图详细描绘了这个流程： 你的DApp可以给用户提供一个界面先部署所需合约再使用之（如图1到4步），也可以假设合约已经部署了（常见方法），直接从使用合约（如图第6步）的界面开始。 第三部分 编程在Truffle中进行测试Truffle用来做智能合约的测试驱动开发(TDD)非常棒，我强烈推荐你在学习中使用它。它也是学习使用JavaScript Promise的一个好途径，例如deferred和异步调用。Promise机制有点像是说“做这件事，如果结果是这样，做甲，如果结果是那样，做乙… 与此同时不要在那儿干等着结果返回，行不？”。Truffle使用了包装web3.js的一个JS Promise框架Pudding（因此它为为你安装web3.js）。(译注：Promise是流行于JavaScript社区中的一种异步调用模式。它很好的封装了异步调用，使其能够灵活组合，而不会陷入callback hell.) Transaction times。 Promise对于DApp非常有用，因为交易写入以太坊区块链需要大约12-15秒的时间。即使在测试网络上看起来没有那么慢，在正式网络上却可能会要更长的时间（例如你的交易可能用光了Gas，或者被写入了一个孤儿块）。 下面让我们给一个简单的智能合约写测试用例吧。 使用Truffle首先确保你 1.安装好了solc以及 2.testrpc。（testrpc需要Python和pip。如果你是Python新手，你可能需要用virtualenv来安装，这可以将Python程序库安装在一个独立的环境中。） PS：在windows安装这个非常麻烦，要有mingw环境（在windows上模拟linux的环境），要安装python和pip，然后还会报告pkg-config的错误，参考这里的帖子，最后还是存在问题。后来在这里找到一个js的版本，终于解决。 接下来安装 3.Truffle（你可以使用NodeJS’s npm来安装：npm install -g truffle, -g开关可能会需要sudo）。安装好之后，在命令行中输入truffle list来验证安装成功。然后创建一个新的项目目录（我把它命名为’conference’），进入这个目录，运行truffle init。该命令会建立如下的目录结构： 现在让我们在另一个终端里通过执行testrpc来启动一个节点（你也可以用geth）： 回到之前的终端中，输入truffle deploy。这条命令会部署之前truffle init产生的模板合约到网络上。任何你可能遇到的错误信息都会在testrpc的终端或者执行truffle的终端中输出。 在开发过程中你随时可以使用truffle compile命令来确认你的合约可以正常编译（或者使用solc YourContract.sol），truffle deploy来编译和部署合约，最后是truffle test来运行智能合约的测试用例。 PS：运行之后，是什么样呢？怎么查看呢？我的终端上显示如下，这个说明什么呢？ 1234567891011121314151617181920212223242526272829net_versioneth_accountsnet_versioneth_accountseth_accountseth_accountsnet_versionnet_versioneth_sendTransaction Transaction: 0x86d59c95d54482646fb1cca5b81a72123f833cb35168b2de9249921845643c20 Contract created: 0x4b46552283603e7f90da3d41c33b7b19d68bf248 Gas usage: 277462 Block Number: 1 Block Time: Fri Aug 10 2018 10:56:31 GMT+0800 (中国标准时间)eth_newBlockFiltereth_getFilterChangeseth_getTransactionReceipteth_getCodeeth_uninstallFiltereth_sendTransaction Transaction: 0x66d6279e0d0bb0798395af14a7092c9d6ce35ceb243ec57d7ce0cc9c18f6b31e Gas usage: 42008 Block Number: 2 Block Time: Fri Aug 10 2018 10:56:32 GMT+0800 (中国标准时间)eth_getTransactionReceipt PS：关于truffle的内容有些过时，需要重新整理一篇文章。 第一个合约下面是一个针对会议的智能合约，通过它参会者可以买票，组织者可以设置参会人数上限，以及退款策略。本文涉及的所有代码都可以在这个代码仓库找到。 contract Conference { address public organizer; mapping (address =&gt; uint) public registrantsPaid; uint public numRegistrants; uint public quota; event Deposit(address _from, uint _amount); // so you can log these events event Refund(address _to, uint _amount); function Conference() { // Constructor organizer = msg.sender; quota = 500; numRegistrants = 0; } function buyTicket() public returns (bool success) { if (numRegistrants &gt;= quota) { return false; } registrantsPaid[msg.sender] = msg.value; numRegistrants++; Deposit(msg.sender, msg.value); return true; } function changeQuota(uint newquota) public { if (msg.sender != organizer) { return; } quota = newquota; } function refundTicket(address recipient, uint amount) public { if (msg.sender != organizer) { return; } if (registrantsPaid[recipient] == amount) { address myAddress = this; if (myAddress.balance &gt;= amount) { recipient.send(amount); registrantsPaid[recipient] = 0; numRegistrants--; Refund(recipient, amount); } } } function destroy() { // so funds not locked in contract forever if (msg.sender == organizer) { suicide(organizer); // send funds to organizer } } } 接下来让我们部署这个合约。（注意：本文写作时我使用的是Mac OS X 10.10.5, solc 0.1.3+ (通过brew安装)，Truffle v0.2.3, testrpc v0.1.18 (使用venv)） 部署合约 (译注：图中步骤翻译如下：） 使用truffle部署智能合约的步骤：1. truffle init (在新目录中) =&gt; 创建truffle项目目录结构2. 编写合约代码，保存到contracts/YourContractName.sol文件。3. 把合约名字加到config/app.json的’contracts’部分。4. 启动以太坊节点（例如在另一个终端里面运行testrpc）。5. truffle deploy（在truffle项目目录中) 添加一个智能合约。 在truffle init执行后或是一个现有的项目目录中，复制粘帖上面的会议合约到contracts/Conference.sol文件中。然后打开config/app.json文件，把’Conference’加入’deploy’数组中。 启动testrpc。 在另一个终端中启动testrpc。 编译或部署。 执行truffle compile看一下合约是否能成功编译，或者直接truffle deploy一步完成编译和部署。这条命令会把部署好的合约的地址和ABI（应用接口）加入到配置文件中，这样之后的truffle test和truffle build步骤可以使用这些信息。 出错了？ 编译是否成功了？记住，错误信息即可能出现在testrpc终端也可能出现在truffle终端。 重启节点后记得重新部署！ 如果你停止了testrpc节点，下一次使用任何合约之前切记使用truffle deploy重新部署。testrpc在每一次重启之后都会回到完全空白的状态。 合约代码解读让我们从智能合约头部的变量声明开始： address public organizer; mapping (address =&gt; uint) public registrantsPaid; uint public numRegistrants; uint public quota; address。 地址类型。第一个变量是会议组织者的钱包地址。这个地址会在合约的构造函数function Conference()中被赋值。很多时候也称呼这种地址为’owner’（所有人）。 uint。 无符号整型。区块链上的存储空间很紧张，保持数据尽可能的小。 public。 这个关键字表明变量可以被合约之外的对象使用。private修饰符则表示变量只能被本合约(或者衍生合约)内的对象使用。如果你想要在测试中通过web3.js使用合约中的某个变量，记得把它声明为public。 Mapping或数组。（译注：Mapping类似Hash, Directory等数据类型，不做翻译。）在Solidity加入数组类型之前，大家都使用类似mapping (address =&gt; uint)的Mapping类型。这个声明也可以写作address registrantsPaid[]，不过Mapping的存储占用更小(smaller footprint)。这个Mapping变量会用来保存参加者（用他们的钱包地址表示）的付款数量以便在退款时使用。 关于地址。 你的客户端（比如testrpc或者geth）可以生成一个或多个账户/地址。testrpc启动时会显示10个可用地址： 第一个地址, accounts[0]，是发起调用的默认地址，如果没有特别指定的话。 组织者地址 vs 合约地址。 部署好的合约会在区块链上拥有自己的地址（与组织者拥有的是不同的地址）。在Solidity合约中可以使用this来访问这个合约地址，正如refundTicket函数所展示的：address myAddress = this; Suicide, Solidity的好东西。（译注：suicide意为’自杀’，Solidity提供的关键字，不做翻译。）转给合约的资金会保存于合约（地址）中。最终这些资金通过destroy函数被释放给了构造函数中设置的组织者地址。这是通过suicide(orgnizer);这行代码实现的。没有这个，资金可能被永远锁定在合约之中（reddit上有些人就遇到过），因此如果你的合约会接受资金一定要记得在合约中使用这个方法！ 如果想要模拟另一个用户或者对手方（例如你是卖家想要模拟一个买家），你可以使用可用地址数组中另外的地址。假设你要以另一个用户，accounts[1], 的身份来买票，可以通过from参数设置： conference.buyTicket({ from: accounts[1], value: some_ticket_price_integer }); 函数调用可以是交易。 改变合约状态（修改变量值，添加记录，等等）的函数调用本身也是转账交易，隐式的包含了发送人和交易价值。因此web3.js的函数调用可以通过指定{ from: __, value: __ }参数来发送以太币。在Solidity合约中，你可以通过msg.sender和msg.value来获取这些信息： function buyTicket() public { ... registrantsPaid[msg.sender] = msg.value; ... } 事件(Event)。 可选的功能。合约中的Deposit（充值）和Send（发送）事件是会被记录在以太坊虚拟机日志中的数据。它们实际上没有任何作用，但是用事件(Event)把交易记录进日志是好的做法。 好了，现在让我们给这个智能合约写一个测试，来确保它能工作。 写测试把项目目录test/中的example.js文件重命名为conference.js，文件中所有的’Example’替换为’Conference’。 contract(&apos;Conference&apos;, function(accounts) { it(&quot;should assert true&quot;, function(done) { var conference = Conference.at(Conference.deployed_address); assert.isTrue(true); done(); // stops tests at this point }); }); 在项目根目录下运行truffle test，你应该看到测试通过。在上面的测试中truffle通过Conference.deployed_address获得合约部署在区块链上的地址。 让我们写一个测试来初始化一个新的Conference，然后检查变量都正确赋值了。将conference.js中的测试代码替换为： contract(&apos;Conference&apos;, function(accounts) { it(&quot;Initial conference settings should match&quot;, function(done) { var conference = Conference.at(Conference.deployed_address); // same as previous example up to here Conference.new({ from: accounts[0] }) .then(function(conference) { conference.quota.call().then( function(quota) { assert.equal(quota, 500, &quot;Quota doesn&apos;t match!&quot;); }).then( function() { return conference.numRegistrants.call(); }).then( function(num) { assert.equal(num, 0, &quot;Registrants should be zero!&quot;); return conference.organizer.call(); }).then( function(organizer) { assert.equal(organizer, accounts[0], &quot;Owner doesn&apos;t match!&quot;); done(); // to stop these tests earlier, move this up }).catch(done); }).catch(done); }); }); 构造函数。 Conference.new({ from: accounts[0] })通过调用合约构造函数创造了一个新的Conference实例。由于不指定from时会默认使用accounts[0]，它其实可以被省略掉： Conference.new({ from: accounts[0] }); // 和Conference.new()效果相同 Promise。 代码中的那些then和return就是Promise。它们的作用写成一个深深的嵌套调用链的话会是这样： conference.numRegistrants.call().then( function(num) { assert.equal(num, 0, &quot;Registrants should be zero!&quot;); conference.organizer.call().then( function(organizer) { assert.equal(organizer, accounts[0], &quot;Owner doesn&apos;t match!&quot;); }).then( function(...)) }).then( function(...)) // Because this would get hairy... Promise减少嵌套，使代码变得扁平，允许调用异步返回，并且简化了表达“成功时做这个”和“失败时做那个”的语法。Web3.js通过回调函数实现异步调用，因此你不需要等到交易完成就可以继续执行前端代码。Truffle借助了用Promise封装web3.js的一个框架，叫做Pudding，这个框架本身又是基于Bluebird的，它支持Promise的高级特性。 call。 我们使用call来检查变量的值，例如conference.quota.call().then(...，还可以通过传参数，例如call(0), 来获取mapping在index 0处的元素。Solidity的文档说这是一种特殊的“消息调用”因为 1.不会为矿工记录和 2.不需要从钱包账户/地址发起（因此它没有被账户持有者私钥做签名）。另一方面，交易/事务(Transaction)会被矿工记录，必须来自于一个账户（也就是有签名），会被记录到区块链上。对合约中数据做的任何修改都是交易。仅仅是检查一个变量的值则不是。因此在读取变量时不要忘记加上call()！否则会发生奇怪的事情。（此外如果在读取变量是遇到问题别忘记检查它是否是public。）call()也能用于调用不是交易的函数。如果一个函数本来是交易，但你却用call()来调用，则不会在区块链上产生交易。 断言。 标准JS测试中的断言（如果你不小心拼成了复数形式’asserts’，truffle会报错，让你一头雾水），assert.equal是最常用的，其他类型的断言可以在Chai的文档中找到。 再一次运行truffle test确保一切工作正常。 测试合约函数调用现在我们测试一下改变quote变量的函数能工作。在tests/conference.js文件的contract(&#39;Conference&#39;, function(accounts) {...};)的函数体中添加如下测试用例： it(&quot;Should update quota&quot;, function(done) { var c = Conference.at(Conference.deployed_address); Conference.new({from: accounts[0] }).then( function(conference) { conference.quota.call().then( function(quota) { assert.equal(quota, 500, &quot;Quota doesn&apos;t match!&quot;); }).then( function() { return conference.changeQuota(300); }).then( function(result) { // result here is a transaction hash console.log(result); // if you were to print this out it’d be long hex - the transaction hash return conference.quota.call() }).then( function(quota) { assert.equal(quota, 300, &quot;New quota is not correct!&quot;); done(); }).catch(done); }).catch(done); }); 这里的新东西是调用changeQuota函数的那一行。console.log对于调试很有用，用它能在运行truffle的终端中输出信息。在关键点插入console.log可以查看执行到了哪一步。记得把Solidity合约中changeQuota函数被声明为public，否则你不能调用它： function changeQuota(uint newquota) public { } 测试交易现在让我们调用一个需要发起人发送资金的函数。 Wei。 以太币有很多种单位（这里有个很有用的转换器）,在合约中通常用的是Wei，最小的单位。Web3.js提供了在各单位与Wei之间互相转换的便利方法，形如web3.toWei(.05, &#39;ether&#39;)。JavaScript在处理很大的数字时有问题，因此web3.js使用了程序库BigNumber，并建议在代码各处都以Wei做单位，直到要给用户看的时候（文档。 账户余额。 Web3.js提供了许多提供方便的方法，其中另一个会在下面测试用到的是web3.eth.getBalance(some_address)。记住发送给合约的资金会由合约自己持有直到调用suicide。 在contract(Conference, function(accounts) {...};)的函数体中插入下面的测试用例。在高亮显示的方法中，测试用例让另一个用户(accounts[1])以ticketPrice的价格买了一张门票。然后它检查合约的账户余额增加了ticketPrice，以及购票用户被加入了参会者列表。 这个测试中的buyTicket是一个交易函数： it(&quot;Should let you buy a ticket&quot;, function(done) { var c = Conference.at(Conference.deployed_address); Conference.new({ from: accounts[0] }).then( function(conference) { var ticketPrice = web3.toWei(.05, &apos;ether&apos;); var initialBalance = web3.eth.getBalance(conference.address).toNumber(); conference.buyTicket({ from: accounts[1], value: ticketPrice }).then( function() { var newBalance = web3.eth.getBalance(conference.address).toNumber(); var difference = newBalance - initialBalance; assert.equal(difference, ticketPrice, &quot;Difference should be what was sent&quot;); return conference.numRegistrants.call(); }).then(function(num) { assert.equal(num, 1, &quot;there should be 1 registrant&quot;); return conference.registrantsPaid.call(accounts[1]); }).then(function(amount) { assert.equal(amount.toNumber(), ticketPrice, &quot;Sender&apos;s paid but is not listed&quot;); done(); }).catch(done); }).catch(done); }); 交易需要签名。 和之前的函数调用不同，这个调用是一个会发送资金的交易，在这种情况下购票用户(accounts[1])会用他的私钥对buyTicket()调用做签名。（在geth中用户需要在发送资金之前通过输入密码来批准这个交易或是解锁钱包的账户。） toNumber()。 有时我们需要把Solidity返回的十六进制结果转码。如果结果可能是个很大的数字可以用web3.toBigNumber(numberOrHexString)来处理因为JavaScript直接对付大数要糟。 测试包含转账的合约最后，为了完整性，我们确认一下refundTicket方法能正常工作，而且只有会议组织者能调用。下面是测试用例： it(&quot;Should issue a refund by owner only&quot;, function(done) { var c = Conference.at(Conference.deployed_address); Conference.new({ from: accounts[0] }).then( function(conference) { var ticketPrice = web3.toWei(.05, &apos;ether&apos;); var initialBalance = web3.eth.getBalance(conference.address).toNumber(); conference.buyTicket({ from: accounts[1], value: ticketPrice }).then( function() { var newBalance = web3.eth.getBalance(conference.address).toNumber(); var difference = newBalance - initialBalance; assert.equal(difference, ticketPrice, &quot;Difference should be what was sent&quot;); // same as before up to here // Now try to issue refund as second user - should fail return conference.refundTicket(accounts[1], ticketPrice, {from: accounts[1]}); }).then( function() { var balance = web3.eth.getBalance(conference.address).toNumber(); assert.equal(web3.toBigNumber(balance), ticketPrice, &quot;Balance should be unchanged&quot;); // Now try to issue refund as organizer/owner - should work return conference.refundTicket(accounts[1], ticketPrice, {from: accounts[0]}); }).then( function() { var postRefundBalance = web3.eth.getBalance(conference.address).toNumber(); assert.equal(postRefundBalance, initialBalance, &quot;Balance should be initial balance&quot;); done(); }).catch(done); }).catch(done); }); 这个测试用例覆盖的Solidity函数如下： function refundTicket(address recipient, uint amount) public returns (bool success) { if (msg.sender != organizer) { return false; } if (registrantsPaid[recipient] == amount) { address myAddress = this; if (myAddress.balance &gt;= amount) { recipient.send(amount); Refund(recipient, amount); registrantsPaid[recipient] = 0; numRegistrants--; return true; } } return false; } 合约中发送以太币。 address myAddress = this展示了如何获取该会议合约实例的地址，以变接下来检查这个地址的余额（或者直接使用this.balance）。合约通过recipient.send(amount)方法把资金发回了购票人。 交易无法返回结果给web3.js。 注意这一点！refundTicket函数会返回一个布尔值，但是这在测试中无法检查。因为这个方法是一个交易函数（会改变合约内数据或是发送以太币的调用），而web3.js得到的交易运行结果是一个交易哈希（如果打印出来是一个长长的十六进制/怪怪的字符串）。既然如此为什么还要让refundTicket返回一个值？因为在Solidity合约内可以读到这个返回值，例如当另一个合约调用refundTicket()的时候。也就是说Solidity合约可以读取交易运行的返回值，而web3.js不行。另一方面，在web3.js中你可以用事件机制（Event, 下文会解释）来监控交易运行，而合约不行。合约也无法通过call()来检查交易是否修改了合约内变量的值。 关于sendTransaction()。 当你通过web3.js调用类似buyTicket()或者refundTicket()的交易函数时（使用web3.eth.sendTransaction），交易并不会立即执行。事实上交易会被提交到矿工网络中，交易代码直到其中一位矿工产生一个新区块把交易记录进区块链之后才执行。因此你必须等交易进入区块链并且同步回本地节点之后才能验证交易执行的结果。用testrpc的时候可能看上去是实时的，因为测试环境很快，但是正式网络会比较慢。 事件/Event。 在web3.js中你应该监听事件而不是返回值。我们的智能合约示例定义了这些事件： event Deposit(address _from, uint _amount); event Refund(address _to, uint _amount); 它们在buyTicket()和refundTicket()中被触发。触发时你可以在testrpc的输出中看到日志。要监听事件，你可以使用web.js监听器(listener)。在写本文时我还不能在truffle测试中记录事件，但是在应用中没问题： Conference.new({ from: accounts[0] }).then( function(conference) { var event = conference.allEvents().watch({}, &apos;&apos;); // or use conference.Deposit() or .Refund() event.watch(function (error, result) { if (error) { console.log(&quot;Error: &quot; + error); } else { console.log(&quot;Event: &quot; + result.event); } }); // ... 过滤器/Filter。 监听所有事件可能会产生大量的轮询，作为替代可以使用过滤器。它们可以更灵活的开始或是停止对事件的监听。更多过滤器的信息可查看Solidity文档。 总的来说，使用事件和过滤器的组合比检查变量消耗的Gas更少，因而在验证正式网络的交易运行结果时非常有用。 Gas。 （译注：以太坊上的燃料，因为代码的执行必须消耗Gas。直译为汽油比较突兀，故保留原文做专有名词。）直到现在我们都没有涉及Gas的概念，因为在使用testrpc时通常不需要显式的设置。当你转向geth和正式网络时会需要。在交易函数调用中可以在{from: __, value: __, gas: __}对象内设置Gas参数。Web3.js提供了web3.eth.gasPrice调用来获取当前Gas的价格，Solidity编译器也提供了一个参数让你可以从命令行获取合约的Gas开销概要：solc --gas YouContract.sol。下面是Conference.sol的结果： 为合约创建DApp界面下面的段落会假设你没有网页开发经验。 上面编写的测试用例用到的都是在前端界面中也可以用的方法。你可以把前端代码放到app/目录中，运行truffle build之后它们会和合约配置信息一起编译输出到build/目录。在开发时可以使用truffle watch命令在app/有任何变动时自动编译输出到build/目录。然后在浏览器中刷新页面即可看到build/目录中的最新内容。（truffle serve可以启动一个基于build/目录的网页服务器。） app/目录中有一些样板文件帮助你开始： index.html会加载app.js： 因此我们只需要添加代码到app.js就可以了。 默认的app.js会在浏览器的console(控制台)中输出一条”Hello from Truffle!”的日志。在项目根目录中运行truffle watch，然后在浏览器中打开build/index.html文件，再打开浏览器的console就可以看到。（大部分浏览器例如Chrome中，单击右键 -&gt; 选择Inspect Element然后切换到Console即可。） 在app.js中，添加一个在页面加载时会运行的window.onload调用。下面的代码会确认web3.js已经正常载入并显示所有可用的账户。（注意：你的testrpc节点应该保持运行。） window.onload = function() { var accounts = web3.eth.accounts; console.log(accounts); } 看看你的浏览器console中看看是否打印出了一组账户地址。 现在你可以从tests/conference.js中复制一些代码过来（去掉只和测试有关的断言），将调用返回的结果输出到console中以确认代码能工作。下面是个例子： window.onload = function() { var accounts = web3.eth.accounts; var c = Conference.at(Conference.deployed_address); Conference.new({ from: accounts[0] }).then( function(conference) { var ticketPrice = web3.toWei(.05, &apos;ether&apos;); var initialBalance = web3.eth.getBalance(conference.address).toNumber(); console.log(&quot;The conference&apos;s initial balance is: &quot; + initialBalance); conference.buyTicket({ from: accounts[1], value: ticketPrice }).then( function() { var newBalance = web3.eth.getBalance(conference.address).toNumber(); console.log(&quot;After someone bought a ticket it&apos;s: &quot; + newBalance); return conference.refundTicket(accounts[1], ticketPrice, {from: accounts[0]}); }).then( function() { var balance = web3.eth.getBalance(conference.address).toNumber(); console.log(&quot;After a refund it&apos;s: &quot; + balance); }); }); }; 上面的代码应该输出如下： (console输出的warning信息可忽略。) 现在起你就可以使用你喜欢的任何前端工具，jQuery, ReactJS, Meteor, Ember, AngularJS，等等等等，在app/目录中构建可以与以太坊智能合约互动的DApp界面了！接下来我们给出一个极其简单基于jQuery的界面作为示例。 这里是index.html的代码，这里是app.js的代码。 通过界面测试了智能合约之后我意识到最好加入检查以保证相同的用户不能注册两次。另外由于现在是运行在testrpc节点上，速度很快，最好是切换到geth节点并确认交易过程依然能及时响应。否则的话界面上就应该显示提示信息并且在处理交易时禁用相关的按钮。 尝试geth。 如果你使用geth, 可以尝试以下面的命令启动 - 在我这儿(geth v1.2.3)工作的很好： build/bin/geth --rpc --rpcaddr=&quot;0.0.0.0&quot; --rpccorsdomain=&quot;*&quot; --mine --unlock=&apos;0 1&apos; --verbosity=5 --maxpeers=0 --minerthreads=&apos;4&apos; --networkid &apos;12345&apos; --genesis test-genesis.json 这条命令解锁了两个账户, 0和1。1. 在geth控制台启动后你可能需要输入这两个账户的密码。2. 你需要在test-genesis.json文件里面的’alloc’配置中加入你的这两个账户，并且给它们充足的资金。3. 最后，在创建合约实例时加上gas参数： Conference.new({from: accounts[0], gas: 3141592}) 然后把整个truffle deploy, truffle build流程重来一遍。 教程中的代码。 在这篇基础教程中用到的所有代码都可以在这个代码仓库中找到。 自动为合约生成界面。 SilentCicero制作了一个叫做DApp Builder的工具，可以用Solidity合约自动生成HTML, jQuery和web.js的代码。这种模式也正在被越来越多的正在开发中的开发者工具采用。 教程到此结束！ 最后一章我们仅仅学习了一套工具集，主要是Truffle和testrpc. 要知道即使在ConsenSys内部，不同的开发者使用的工具和框架也不尽相同。你可能会发现更适合你的工具，这里所说的工具可能很快也会有改进。但是本文介绍的工作流程帮助我走上了DApp开发之路。 (⊙ω⊙) wonk wonk 感谢Joseph Chow的校阅和建议，Christian Lundkvist, Daniel Novy, Jim Berry, Peter Borah和Tim Coulter帮我修改文字和debug，以及Tim Coulter, Nchinda Nchinda和Mike Goldin对DApp前端步骤图提供的帮助。]]></content>
      <categories>
        <category>Blockchain</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>以太坊</tag>
        <tag>智能合约</tag>
        <tag>编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git：Repository not found.]]></title>
    <url>%2Fgit%2Fgit-change-server-password.html</url>
    <content type="text"><![CDATA[原帖收藏于IT老兵驿站，传递一个IT老兵在凋零前的光和氧。Git：服务端更换密码后，报告“remote: Repository not found.”。 昨天Github提醒我需要修改密码，所以我将Github的密码修改了，结果，回到家，在mac笔记本上git pull代码时报告remote: Repository not found.，在网上找了半天，都是在说git路径存在问题，这肯定不是我的问题，我的问题应该就是更换了密码，只不过git 报告了一个奇怪的错误，应该是需要修改本地原本保存的密码。 找到一个帖子说： 分别打开下面2个文件,将[User]部分完全删除后保存,再使用Git命令的时候就会提示输入帐号密码了.$ vi .git/config (工程当前路径的Git配置文件) $ vi ~/.gitconfig (全局的Git配置文件) 这里是删除掉了用户信息，不过，不管用。 继续寻找原因：12xxx$ git config -lcredential.helper=osxkeychain 这里有个变量credential.helper，凭证帮助者，怀疑是这里保存了密码，后面指向了电脑的keychain。 查看官网解释： credential.helperSpecify an external helper to be called when a username or password credential is needed; the helper may consult external storage to avoid prompting the user for the credentials. Note that multiple helpers may be defined. See gitcredentials[7] for details. 这里确认了，这里是外部的一个凭证助手，用来保存用户名和密码。 然后找到mac的keychain（钥匙串访问），果然发现了一条Github的条目，这里应该保存在原本的用户名和密码，把它删掉（这里也是可以直接修改密码的，只是第一次尝试的是删除），这个时候再git pull就出现了提示请输入用户名了，至此，问题解决，相关的疑问也搞明白了。]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>Repository not found</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[区块链：以太坊的工作原理（转）--阅读笔记]]></title>
    <url>%2Fblockchain%2Fethereum-rationale-introduction.html</url>
    <content type="text"><![CDATA[区块链：以太坊的工作原理–阅读笔记。 前言找到一篇写的很好的对以太坊的介绍，6月21日阅读了一遍，并且进行了转帖，今天感觉还有很多内容没有读明白，开始第二遍研究，记录一些笔记。当然，会对原文中的一些有点问题的格式进行一下调整。 正文这篇文章主要讲解以太坊的基本原理，对技术感兴趣的朋友可以看看。 翻译作者: 许莉原文地址：How does Ethereum work, anyway? 简介不管你们知不知道以太坊（Ethereum blockchain）是什么，但是你们大概都听说过以太坊。最近在新闻里出现过很多次，包括一些专业杂志的封面，但是如果你们对以太坊到底是什么没有一个基本的了解的话，看这些文章就会感觉跟看天书一样。 所以，什么是以太坊？本质上，就是一个保存数字交易永久记录的公共数据库。重要的是，这个数据库不需要任何中央权威机构来维持和保护它。相反的它以一个“无信任”的交易系统来运行—一个个体在不需要信任任何第三方或对方的情况下进行点对点交易的架构。（PS：加了标红，感觉这句话需要着重理解） 依然感到很困惑？这就是这篇文章存在的理由。我的目标是在技术层面来解释以太坊的工作原理，但是不会出现很复杂的数学问题或看起来很可怕的公式。即使你不是一个程序员，我希望你看完之后最起码对技术有个更好的认识。如果有些部分技术性太强不好理解，这是非常正常的，真的没有必要完全理解每一个小细节。我建议只要宏观的理解一下事物就行了。 这篇文章中的很多议点都是以太坊黄皮书中讨论过的概念的细分。我添加了我自己的解释和图表使理解以太坊更加简单一点。那些足够勇敢的人可以挑战一下技术，去阅读一下以太坊的黄皮书。 好了，让我们开始吧！ 区块链定义区块链就是一个具有共享状态的密码性安全交易的单机(cryptographically secure transactional singleton machine with shared-state)。[1]这有点长，是吧？让我们将它分开来看： “密码性安全(Cryptographically secure)”是指用一个很难被解开的复杂数学机制算法来保证数字货币生产的安全性。将它想象成类似于防火墙的这种。它们使得欺骗系统近乎是一个不可能的事情（比如：构造一笔假的交易，消除一笔交易等等）。 “交易的单机(Transactional singleton machine)”是指只有一个权威的机器实例为系统中产生的交易负责任。换句话说，只有一个全球真相是大家所相信的。 “具有共享状态(With shared-state)”是指在这台机器上存储的状态是共享的，对每个人都是开放的。 以太坊实现了区块链的这个范例。 PS：这段概念说的有些绕，理解起来有点费劲。对这里面的singleton machine with shared-state不是太理解。同时发现了以太坊总是在强调一个概念，就是state。 以太坊模型说明以太坊的本质就是一个基于交易的状态机(transaction-based state machine)。（PS：比特币不也是这样吗？）在计算机科学中，一个 状态机是指可以读取一系列的输入，然后根据这些输入，会转换成一个新的状态出来的东西。 根据以太坊的状态机，我们从创世纪状态(genesis state)开始。这差不多类似于一片空白的石板，在网络中还没有任何交易的产生状态。当交易被执行后，这个创世纪状态就会转变成最终状态。在任何时刻，这个最终状态都代表着以太坊当前的状态。 以太坊的状态有百万个交易。这些交易都被“组团”到一个区块中。一个区块包含了一系列的交易，每个区块都与它的前一个区块链接起来。 为了让一个状态转换成下一个状态，交易必须是有效的。为了让一个交易被认为是有效的，它必须要经过一个验证过程，此过程也就是挖矿。挖矿就是一组节点（即电脑）用它们的计算资源来创建一个包含有效交易的区块出来。 任何在网络上宣称自己是矿工的节点都可以尝试创建和验证区块。世界各地的很多矿工都在同一时间创建和验证区块。每个矿工在提交一个区块到区块链上的时候都会提供一个数学机制的“证明”，这个证明就像一个保证：如果这个证明存在，那么这个区块一定是有效的。 为了让一个区块添加到主链上，一个矿工必须要比其他矿工更快的提供出这个“证明”。通过矿工提供的一个数学机制的“证明”来证实每个区块的过程称之为工作量证明(proof of work)。 证实了一个新区块的矿工都会被奖励一定价值的奖赏。奖赏是什么？以太坊使用一种内在数字代币—以太币(Ether)作为奖赏。每次矿工证明了一个新区块，那么就会产生一个新的以太币并被奖励给矿工。 你也许会在想：什么能确保每个人都只在区块的同一条链上呢？我们怎么能确定不会存在一部分矿工创建一个他们自己的链呢？ 前面，我们定义了区块链就是一个具有共享状态的交易单机。使用这个定义，我们可以知道正确的当前状态是一个全球真相，所有人都必须要接受它。拥有多个状态（或多个链）会摧毁这个系统，因为它在哪个是正确状态的问题上不可能得到统一结果。如果链分叉了，你有可能在一条链上拥有10个币，一条链上拥有20个币，另一条链上拥有40个币。在这种场景下，是没有办法确定哪个链才是最”有效的“。 不论什么时候只要多个路径产生了，一个”分叉“就会出现。我们通常都想避免分叉，因为它们会破坏系统，强制人们去选择哪条链是他们相信的链。 为了确定哪个路径才是最有效的以及防止多条链的产生，以太坊使用了一个叫做“GHOST协议(GHOST protocol)”的数学机制。 GHOST = Greedy Heaviest Observed Subtree 简单来说，GHOST协议就是让我们必须选择一个在其上完成计算最多的路径。一个方法确定路径就是使用最近一个区块（叶子区块）的区块号，区块号代表着当前路径上总的区块数（不包含创世纪区块）。区块号越大，路径就会越长，就说明越多的挖矿算力被消耗在此路径上以达到叶子区块。使用这种推理就可以允许我们赞同当前状态的权威版本。 PS：以上是总体的一个概念。 现在你大概对区块链是什么有个理性的认识，让我们在再深入地了解一下以太坊系统主要组成部分： 账户(accounts) 状态(state) 损耗和费用(gas and fees) 交易(transactions) 区块(blocks) 交易执行(transaction execution) 挖矿(mining) 工作量证明(proof of work) 在开始之前需要注意的是：每当我说某某的Hash， 我指的都是KECCAK-256 hash, 以太坊就是使用这个Hash算法。 账户以太坊的全局“共享状态”是有很多小对象（账户）来组成的，这些账户可以通过消息传递来与对方进行交互。每个账户都有一个与之关联的状态(state)和一个20字节的地址(address)。在以太坊中一个地址是160位的标识符，用来识别账户。（PS：这个状态又是怎么呈现的呢？外部拥有账户是有一个余额的概念，那么合约账户呢？怎么呈现当前的状态呢？需要检索以前所有和这个合约发生过关系的交易？） 两种不同类型的账户： 外部拥有的账户，被私钥控制且没有任何代码与之关联 合约账户，被它们的合约代码控制且有代码与之关联 外部拥有账户与合约账户的比较理解外部拥有账户和合约账户的基本区别是很重要的。一个外部拥有账户可以通过创建和用自己的私钥来对交易进行签名，来发送消息给另一个外部拥有账户或合约账户。在两个外部拥有账户之间传送的消息只是一个简单的价值转移。但是从外部拥有账户到合约账户的消息会激活合约账户的代码，允许它执行各种动作。（比如转移代币，写入内部存储，挖出一个新代币，执行一些运算，创建一个新的合约等等）。 不像外部拥有账户，合约账户不可以自己发起一个交易。相反，合约账户只有在接收到一个交易之后(从一个外部拥有账户或另一个合约账户处)，为了响应此交易而触发一个交易。我们将会在“交易和消息”章节来了解关于合约与合约之间的通信。 因此，在以太坊上任何的动作，总是被外部拥有账户触发的交易所发动的。 账户状态账户状态有四个组成部分，不论账户类型是什么，都存在这四个组成部分： nonce：如果账户是一个外部拥有账户，nonce代表从此账户地址发送的交易序号。如果账户是一个合约账户，nonce代表此账户创建的合约序号 balance： 此地址拥有Wei的数量。1Ether=10^18Wei storageRoot： Merkle Patricia树的根节点Hash值（我们后面在解释Merkle树）。Merkle树会将此账户存储内容的Hash值进行编码，默认是空值 codeHash：此账户EVM（以太坊虚拟机，后面细说）代码的hash值。对于合约账户，就是被Hash的代码并作为codeHash保存。对于外部拥有账户，codeHash域是一个空字符串的Hash值 （PS：这个地方存在几个问题： storageRoot和codeHash存储的都是hash值，那么原本的内容被存在哪里？ 合约代码会发生改变吗？代码里面的状态值是怎样体现改变的？ 账户的唯一性是由nonce来确定的吗？） （PS：账户的信息又是怎么保存在区块链上呢？） 世界状态好了，我们知道了以太坊的全局状态就是由账户地址和账户状态组成的一个映射。这个映射被保存在一个叫做Merkle Patricia树的数据结构中 Merkle Tree（也被叫做Merkle trie）是一种由一系列节点组成的二叉树，这些节点包括： 在树底的大量叶子节点，这些叶子节点包含了源数据 一系列的中间节点，这些节点是两个子节点的Hash值 一个根节点，同样是两个子节点的Hash值，代表着整棵树 树底的数据是通过分开我们想要保存到chunks的数据产生的，然后将chunks分成buckets，再然后获取每个bucket的hash值并一直重复直到最后只剩下一个Hash：根Hash。 PS：这段话翻译得不好，原文是： The data at the bottom of the tree is generated by splitting the data that we want to store into chunks, then splitting the chunks into buckets, and then taking the hash of each bucket and repeating the same process until the total number of hashes remaining becomes only one: the root hash. 不是分开，是把我们想要保存的数据分隔开（splitting），保存到chunks上，然后再分隔chunks到bucket上。这是两个组织数据的单位。不过怎么体现在区块上呢？ 这棵树要求存在里面的值（value）都有一个对应的key。从树的根节点开始，key会告诉你顺着哪个子节点可以获得对应的值，这个值存在叶子节点。在以太坊中，key/value是地址和与地址相关联的账户之间状态的映射，包括每个账户的balance, nonce, codeHash和storageRoot（storageRoot自己就是一颗树）。 （PS：到这里明白了，账户信息是保存在state树中的） 同样的树结构也用来存储交易和收据。更具体的说，每个块都有一个头(header)，头中保存了三个Merkle树结构的根节点Hash，三个Merkle树分别为： 状态树 交易树 收据树 Merkle树中存储信息的高效性在以太坊的“轻客户端”和“轻节点”中相当的有用。记住区块链就是一群节点来维持的。广泛的说，有两种节点类型：全节点和轻节点。 全节点通过下载整条链来进行同步，从创世纪块到当前块，执行其中包含的所有交易。通常，矿工会存储全节点，因为他们在挖矿过程中需要全节点。也有可能下载一个全节点而不用执行所有的交易。无论如何，一个全节点包含了整个链。（PS：为什么要执行交易呢？交易的结果状态没有被记录吗？） 不过除非一个节点需要执行所有的交易或轻松访问历史数据，不然没必要保存整条链。这就是轻节点概念的来源。比起下载和存储整个链以及执行其中所有的交易，轻节点仅仅下载链的头，从创世纪块到当前块的头，不执行任何的交易或检索任何相关联的状态。由于轻节点可以访问区块头，而头中包含了3个Merkle树的根Hash值，所有轻节点依然可以很容易生成和接收关于交易、事件、余额等可验证的答案。 这个可以行的通是因为在Merkle树中Hash值是向上传播的—如果一个恶意用户试图用一个假交易来交换Merkle树底的交易，这个会改变它上面节点的Hash值，而它上面节点的值的改变也会导致上上一个节点Hash值的改变，以此类推，一直到树的根节点。 任何节点想要验证一些数据都可以通过Merkle证明来进行验证，Merkle 证明的组成： 一块需要验证的数据 树的根节点Hash值 一个“分支”（从 chunk到根这个路径上所有的Hash值） 任何可以读取证明的人都可以验证分支的Hash值是连贯的，因此给出的块在树中实际的位置就是在此处。 总之，使用Merkle Patricia树的好处就是该结构的根节点加密取决于存储在树中的数据，而且根节点的Hash值还可以作为该数据的安全标识。由于块的头包含了状态树、交易树、收据树的根Hash值，所以任何节点都可以验证以太坊的一小部分状态而不用保存整个状态，这整个状态的的大小可能是非常大的。 Gas和费用在以太坊中一个比较重要的概念就是费用(fees)，由以太坊网络上的交易而产生的每一次计算，都会产生费用—没有免费的午餐。这个费用是以”gas”来支付。 Gas就是用来衡量在一个具体计算中要求的费用单位。gas price就是你愿意在每个gas上花费Ether的数量，以“gwei”进行衡量。“Wei”是Ether的最小单位，1Ether=10^18Wei，1gwei=1,000,000,000 Wei。 对每个交易，发送者设置gas limit和gas price。gas limit和gas price就代表着发送者愿意为执行交易支付的Wei的最大值。 例如，假设发送者设置gas limit为50,000，gas price为20gwei。这就表示发送者愿意最多支付50,000 * 20gwei = 1,000,000,000,000,000 Wei = 0.001 Ether来执行此交易。 记住gas limit代表用户愿意花费在gas上费用的最大值。如果在他们的账户余额中有足够的Ether来支付这个最大值费用，那么就没问题。在交易结束时任何未使用的gas都会被返回给发送者，以原始费率兑换。 在发送者没有提供足够的gas来执行交易，那么交易执行就会出现“gas不足”然后被认为是无效的。在这种情况下，交易处理就会被终止以及所有已改变的状态将会被恢复，最后我们就又回到了交易之前的状态—完完全全的之前状态就像这笔交易从来没有发生。因为机器在耗尽gas之前还是为计算做出了努力，所以理论上，将不会有任何的gas被返回给发送者。 这些gas的钱到底去了哪里？发送者在gas上花费的所有费用都被发送到“受益人”的地址，通常情况下就是矿工的地址。因为矿工为了计算和验证交易做出了努力，所以矿工接收gas的费用作为奖励。 通常，发送者愿意支付更高的gas price，矿工从这笔交易中就能获得更多的价值。因此，矿工也就更加愿意选择这笔交易。这样的话，矿工可以自由的选择自己愿意验证或忽略的交易。为了引导发送者设置合理的gas price，矿工可以选择建议一个最小的gas值，此值代表自己愿意执行交易的最低价格。 存储也有费用Gas不仅仅是用来支付计算这一步的费用，而且也用来支付存储的费用。存储的总费用与所使用的32位字节的最小倍数成比例。 存储费用有一些比较细微的方面。比如，由于增加的存储增加了所有节点上的以太坊状态数据库的大小，所以激励保持数据存储量小。为了这个原因，如果一个交易的执行有一步是清除一个存储实体，那么为执行这个操作的费用就会被放弃，并且由于释放存储空间的退款就会被返回给发送者。 费用的作用是什么？以太坊可以运作的一个重要方面就是每个网络执行的操作同时也被全节点所影响。然而，计算的操作在以太坊虚拟机上是非常昂贵的。因此，以太坊智能合约最好是用来执行最简单的任务，比如运行一个简单的业务逻辑或者验证签名和其他密码对象，而不是用于复杂的操作，比如文件存储，电子邮件，或机器学习，这些会给网络造成压力。施加费用防止用户使网络超负荷。 以太坊是一个图灵完备语言（短而言之，图灵机器就是一个可以模拟任何电脑算法的机器。对于图灵机器不太熟悉的人可以看看这个和这个）。这就允许有循环，并使以太坊受到停机问题的影响，这个问题让你无法确定程序是否无限制的运行。如果没有费用的话，恶意的执行者通过执行一个包含无限循环的交易就可以很容易的让网络瘫痪而不会产生任何反响。因此，费用保护网络不受蓄意攻击。 你也许会想，“为什么我们还需要为存储付费？”其实就像计算一样，以太坊网络上的存储是整个网络都必须要负担的成本。 交易和消息之前说过以太坊是一个基于交易的状态机。换句话说，在两个不同账户之间发生的交易才让以太坊的全局状态从一个状态转换成另一个状态。 最基本的概念，一个交易就是指被外部拥有账户生成的加密签名的一段指令，序列化之后提交给区块链。 有两种类型的交易：消息通信(message calls)和合约创建(contract creations)(也就是交易产生一个新的以太坊合约)。 不管什么类型的交易，都包含： nonce：发送者发送交易数的计数 gasPrice：发送者愿意支付执行交易所需的每个gas的Wei数量 gasLimit：发送者愿意为执行交易支付gas数量的最大值。此值设置之后在任何计算完成之前就会被提前扣掉 to：接收者的地址。在合约创建交易中，合约账户的地址还没有存在，所以值先空着 value：从发送者转移到接收者Wei的数量。在合约创建交易中，value作为新建合约账户的开始余额 v,r,s：用于产生标识交易发送者的签名 init（只有在合约创建交易中存在）：用来初始化新合约账户的EVM代码片段。init值会执行一次，然后就会被丢弃。当init第一次执行的时候，它返回一个账户代码体，也就是永久与合约账户关联的一段代码。 data（可选域，只有在消息通信中存在）：消息通信中的输入数据(也就是参数)。例如，如果智能合约就是一个域名注册服务，那么调用合约可能就会期待输入参数：域名和IP地址 在“账户”这个章节中我们学到交易—消息通信和合约创建交易两者都总是被外部拥有账户触发并提交到区块链的。换种思维思考就是，交易是外部世界和以太坊内部状态的桥梁。 但是这也并不代表一个合约与另一个合约无法通信。在以太坊状态全局范围内的合约可以与在相同范围内的合约进行通信。他们是通过“消息”或者“内部交易”进行通信的。（PS：没看懂）我们可以认为消息或内部交易类似于交易，不过与交易有着最大的不同点—它们不是由外部拥有账户产生的。相反，他们是被合约产生的。它们是虚拟对象，与交易不同，没有被序列化而且只存在于以太坊执行环境。 当一个合约发送一个内部交易给另一个合约，存在于接收者合约账户相关联的代码就会被执行。 一个需要注意的重要事情是内部交易或者消息不包含gasLimit。因为gas limit是由原始交易的外部创建者决定的（也就是外部拥有账户）。外部拥有账户设置的gas limit必须要高到足够将交易完成，包括由于此交易而产生的任何”子执行”，例如合约到合约的消息。如果，在一个交易或者信息链中，其中一个消息执行造成gas不足，那么这个消息的执行会被还原，包括任何被此执行触发的子消息。不过，父执行没必要被还原。 区块所有的交易都被组成一个”块”。一个区块链包含了一系列这样链在一起的区块。 在以太坊中，一个区块包含： 区块头 关于包含在此区块中交易集的信息 与当前块的ommers相关的一系列其他区块头 Ommers解释“ommer”到底是什么？ ommer就是一个区块的父区块与当前区块父区块的父区块是相同的。让我们快速了解一下ommers是用来干嘛的，并且为什么一个区块需要为ommers包含区块头。 由于以太坊的构造，它的区块生产时间（大概15秒左右）比其他的区块链例如Bitcoin（大概10分钟左右）要快很多。这使得交易的处理更快。但是，更短的区块生产时间的一个缺点就是：更多的竞争区块会被矿工发现。这些竞争区块同样也被称为“孤区块”（也就是被挖出来但是不会被添加到主链上的区块）。 Ommers的目的就是为了帮助奖励矿工纳入这些孤区块。矿工包含的ommers必须是有效的，也就是ommers必须是往上数6代之内或更小范围内父区块的子区块。 一个孤区块在第6个子区块之后，这种陈旧的孤区块将不会再被引用（因为包含老旧的交易会使事情变得复杂一点）。 Ommer区块会收到比全区块少一点的奖励。不管怎样，依然存在激励来让矿工们纳入孤区块并能从中获得一些报酬。 区块头让我们再回到区块的问题上。我们前面提到每个区块都有一个“区块头”，但这究竟是什么？ 区块头是区块的一部分，包含了： parentHash：父区块头的Hash值（这也是使得区块变成区块链的原因） ommerHash：当前区块ommers列表的Hash值 beneficiary：接收挖此区块费用的账户地址 stateRoot：状态树根节点的Hash值（回忆一下我们之前所说的保存在头中的状态树以及它使得轻客户端认证任何关于状态的事情都变得非常简单） transactionsRoot：包含此区块所有交易的Merkle树的根节点Hash值 receiptsRoot：包含此区块所有交易收据的Merkle树的根节点Hash值 logsBloom：由日志信息组成的一个Bloom过滤器 (一种数据结构) difficulty： 此区块的难度级别 number：当前区块的计数（创世纪块的区块序号为0，对于每个后续区块，区块序号都增加1） gasLimit：每个区块的当前gas limit gasUsed： 此区块中交易所用的总gas量 timestamp：此区块成立时的unix的时间戳 extraData：与此区块相关的附加数据 mixHash：一个Hash值，当与nonce组合时，证明此区块已经执行了足够的计算 nonce：一个Hash值，当与mixHash组合时，证明此区块已经执行了足够的计算 注意每个区块是如何包含三个树结构的，三个树结构分别对应： 状态（stateRoot） 交易（transactionsRoot） 收据（receiptsRoot）这三个树结构就是我们前面讨论的Merkle Patricia树。 另外，上面描述的有几个术语值得说明一下，下面来看一下。 日志以太坊允许日志可以跟踪各种交易和信息。一个合约可以通过定义“事件”来显示的生成日志。 一个日志的实体包含： 记录器的账户地址 代表本次交易执行的各种事件的一系列主题以及与这些事件相关的任何数据 日志被保存在bloom过滤器中，过滤器高效的保存了无尽的日志数据。（PS：这得保留多少？不是越来越大） 交易收据包含着日志信息的交易收据的根Hash值保存在头中。 就像你在商店买东西时收到的收据一样，以太坊为每笔交易都产生一个收据。像你期望的那样，每个收据包含关于交易的特定信息，这些信息为： 区块序号 区块Hash值 交易Hash值 当前交易使用了的gas 在当前交易执行完之后当前块使用的累计gas 执行当前交易时创建的日志 等等 区块难度区块的难度是被用来在验证区块时加强一致性。创世纪区块的难度是131,072，有一个特殊的公式用来计算之后的每个块的难度。如果某个区块比前一个区块验证的更快，以太坊协议就会增加区块的难度。 区块的难度影响nonce，它是在挖矿时必须要使用工作量证明算法计算出的一个Hash值。 区块难度和nonce之间的关系用数学形式表达就是：Hd代表的是难度。 找到符合难度阈值的nonce唯一方法就是使用工作量证明算法来列举所有的可能性。找到解决方案预期时间与难度成正比—难度越高，找到nonce就越困难，因此验证一个区块也就越难，这又相应地增加了验证新块所需的时间。所以，通过调整区块难度，协议可以调整验证区块所需的时间。 另一方面，如果验证时间变的越来越慢，协议就会降低难度。这样的话，验证时间自我调节以保持恒定的速率—平均每15s一个块。 交易执行我们已经到了以太坊协议最复杂的部分：交易的执行。假设你发送了一笔交易给以太坊网络处理，将以太坊状态转换成包含你的交易这个过程到底发生了什么？ 首先，为了可以被执行所有的交易必须都要符合最基础的一系列要求，包括： 交易必须是正确格式化的RLP。”RLP”代表Recursive Length Prefix，它是一种数据格式，用来编码二进制数据嵌套数组。以太坊就是使用RLP格式序列化对象。 有效的交易签名。 有效的交易序号。回忆一下账户中的nonce就是从此账户发送出去交易的计数。如果有效，那么交易序号一定等于发送账户中的nonce。 交易的gas limit 一定要等于或者大于交易使用的intrinsic gas，intrinsic gas包括：1.执行交易预订费用为21,000gas2.随交易发送的数据的gas费用（每字节数据或代码为0的费用为4gas，每个非零字节的数据或代码费用为68gas）3.如果是合约创建交易，还需要额外的32,000gas 发送账户余额必须有足够的Ether来支付”前期”gas费用。前期gas费用的计算比较简单：首先，交易的gas limit乘以交易的gas价格得到最大的gas费用。然后，这个最大的gas费用加上从发送方传送给接收方的总值。 如果交易符合上面的所有要求，那么我们进行下面的步骤。 第一步，我们从发送者的余额中扣除执行的前期费用，并为当前交易将发送者账户中的nonce增加1。此时，我们可以计算剩余的gas，将交易的总gas减去使用的intrinsic gas。 第二步，开始执行交易。在交易执行的整个过程中，以太坊保持跟踪“子状态”。子状态是记录在交易中生成的信息的一种方式，当交易完成时会立即需要这些信息。具体来说，它包含： 自毁集：在交易完成之后会被丢弃的账户集（如果存在的话） 日志系列：虚拟机的代码执行的归档和可检索的检查点 退款余额：交易完成之后需要退还给发送账户的总额。回忆一下我们之前提到的以太坊中的存储需要付费，发送者要是清理了内存就会有退款。以太坊使用退款计数进行跟踪退款余额。退款计数从0开始并且每当合约删除了一些存储中的东西都会进行增加。 第三步，交易所需的各种计算开始被处理。 当交易所需的步骤全部处理完成，并假设没有无效状态，通过确定退还给发送者的未使用的gas量，最终的状态也被确定。除了未使用的gas，发送者还会得到上面所说的“退款余额”中退还的一些津贴。 一旦发送者得到退款之后： gas的Ether就会给矿工 交易使用的gas会被添加到区块的gas计数中（计数一直记录当前区块中所有交易使用的gas总量，这对于验证区块时是非常有用的） 所有在自毁集中的账户（如果存在的话）都会被删除 最后，我们就有了一个新的状态以及交易创建的一系列日志。 现在我们已经介绍了交易执行的基本知识，让我们再看看合约创建交易和消息通信的一些区别。 合约创建(Contract creation) 回忆一下在以太坊中，有两种账户类型：合约账户和外部拥有账户。当我们说一个交易是“合约创建”，是指交易的目的是创建一个新的合约账户。 为了创建一个新的合约账户，我们使用一个特殊的公式来声明新账户的地址。然后我们使用下面的方法来初始化一个账户： 设置nonce为0 如果发送者通过交易发送了一定量的Ether作为value，那么设置账户的余额为value 将存储设置为0 设置合约的codeHash为一个空字符串的Hash值 一旦我们完成了账户的初始化，使用交易发送过来的init code（查看”交易和消息”章节来复习一下init code），实际上就创造了一个账户。init code的执行过程是各种各样的。取决于合约的构造器，可能是更新账户的存储，也可能是创建另一个合约账户，或者发起另一个消息通信等等。 当初始化合约的代码被执行之后，会使用gas。交易不允许使用的gas超过剩余gas。如果它使用的gas超过剩余gas，那么就会发生gas不足异常(OOG)并退出。如果一个交易由于gas不足异常而退出，那么状态会立刻恢复到交易前的一个点。发送者也不会获得在gas用完之前所花费的gas。 不过，如果发送者随着交易发送了Ether，即使合约创建失败Ether也会被退回来。 如果初始化代码成功的执行完成，最后合约创建的花费会被支付。这些是存储成本，与创建的合约代码大小成正比（再一次，没有免费的午餐）。如果没有足够的剩余gas来支付最后的花费，那么交易就会再次宣布gas不足异常并中断退出。 如果所有的都正常进行没有任何异常出现，那么任何剩余的未使用gas都会被退回给原始的交易发送者，现在改变的状态才被允许永久保存。 消息通信(Message calls)消息通信的执行与合约创建比较类似，只不过有一点点区别。 由于没有新账户被创建，所以消息通信的执行不包含任何的init code。不过，它可以包含输入数据，如果交易发送者提供了此数据的话。一旦执行，消息通信同样会有一个额外的组件来包含输出数据，如果后续执行需要此数据的话组件就会被使用。 就像合约创建一样，如果消息通信执行退出是因为gas不足或交易无效（例如栈溢出，无效跳转目的地或无效指令），那么已使用的gas是不会被退回给原始触发者的。相反，所有剩余的未使用gas也会被消耗掉，并且状态会被立刻重置为余额转移之前的那个点。 没有任何方法停止或恢复交易的执行而不让系统消耗你提供的所有gas，直到最新的以太坊更新。例如，假设你编写了一个合约，当调用者没有授权来执行这些交易的时候抛出一个错误。在以太坊的前一个版本中，剩余的gas也会被消耗掉，并且没有任何gas退回给发送者。但是拜占庭更新包括了一个新的“恢复”代码，允许合约停止执行并且恢复改变的状态而不消耗剩余的gas，此代码还拥有返回交易失败原因的能力。如果一个交易是由于恢复而退出，那么未使用的gas就会被退回给发送者。 执行模式到目前为止，我们了解了从开始到结束交易的执行必须经历的一系列步骤。现在，我们来看看交易究竟是如何在虚拟机(VM)中执行的。 协议实际操作交易处理的部分是以太坊自己的虚拟机，称之为以太坊虚拟机(EVM)。 像之前定义的那样，EVM是图灵完备虚拟机器。EVM存在而典型图灵完备机器不存在的唯一限制就是EVM本质上是被gas束缚。因此，可以完成的计算总量本质上是被提供的gas总量限制的。 此外，EVM具有基于堆栈的架构。堆栈机器就是使用后进先出来保存临时值的计算机。 EVM中每个堆栈项的大小为256位，堆栈有一个最大的大小，为1024位。 EVM有内存，各项按照可寻址字节数组来存储。内存是易失性的，也就是数据是不持久的。 EVM也有一个存储器。不像内存，存储器是非易失性的，并作为系统状态的一部分进行维护。EVM分开保存程序代码，在虚拟ROM 中只能通过特殊指令来访问。这样的话，EVM就与典型的冯·诺依曼架构不同，此架构将程序的代码存储在内存或存储器中。 EVM同样有属于它自己的语言：“EVM字节码”，当一个程序员比如你或我写一个在以太坊上运行的智能合约时，我们通常都是用高级语言例如Solidity来编写代码。然后我们可以将它编译成EVM可以理解的EVM字节码。 好了现在来说执行。 在执行特定的计算之前，处理器会确定下面所说的信息是否有效和是否可获取： 系统状态 用于计算的剩余gas 拥有执行代码的账户地址 原始触发此次执行的交易发送者的地址 触发代码执行的账户地址（可能与原始发送者不同） 触发此次执行的交易gas price 此次执行的输入数据 Value(单位为Wei)作为当前执行的一部分传递给该账户 待执行的机器码 当前区块的区块头 当前消息通信或合约创建堆栈的深度 执行刚开始时，内存和堆栈都是空的，程序计数器为0。 1 PC: 0 STACK: [] MEM: [], STORAGE: {} 然后EVM开始递归的执行交易，为每个循环计算系统状态和机器状态。系统状态也就是以太坊的全局状态(global state)。机器状态包含： 可获取的gas 程序计数器 内存的内容 内存中字的活跃数 堆栈的内容 堆栈中的项从系列的最左边被删除或者添加。 每个循环，剩余的gas都会被减少相应的量，程序计数器也会增加。在每个循环的结束，都有三种可能性： 机器到达异常状态（例如 gas不足，无效指令，堆栈项不足，堆栈项会溢出1024，无效的JUMP/JUMPI目的地等等）因此停止，并丢弃所有更改 进入后续处理下一个循环 机器到达了受控停止（到达执行过程的终点） 假设执行没有遇到异常状态，达到一个“可控的”或正常的停止，机器就会产生一个合成状态，执行之后的剩余gas、产生的子状态、以及组合输出。 呼。我们终于过了一遍以太坊最难的部分了。如果你不能完全理解这个部分，也没关系。除非你在研究非常深层次的东西，否则你真的没有必要去理解交易执行的每个细节。 一个块是如何完成的？最后，让我们看看一个包含许多交易的块是如何完成的。 当我们说“完成”，取决于此块是新的还是已存在的，可以指两个不同的事情。如果是个新块，就是指挖这个块所需的处理。如果是已存在的块，就是指验证此块的处理。不论哪种情况，一个块的“完成”都有4个要求：1）验证（或者，如果是挖矿的话，就是确定）ommers在区块头中的每个ommer都必须是有效的并且必须在当前块往上6代之内 2）验证（或者，如果是挖矿的话，就是确定）交易区块中的gasUsed数量必须与区块中所列交易使用的累积gas量相等。（回忆一下，当执行一个交易的时候，我们会跟踪区块的gas计数器，也就跟踪了区块中所有交易使用的gas总数量） 3）申请奖励（只有挖矿时）受益人的地址会因为挖矿而获得5Ether（在以太坊EIP-649 提案中，5ETH很快将会被减少为3ETH）。另外，对于每个ommer，当前块的受益人会获得额外的1/32当前块奖励金的奖励。最近，每个ommer区块的受益人能够得到一定量的奖励（有个特殊公式可以进行计算）。 4）校验（或者，如果是挖矿的话，就是计算一个有效的）状态和nonce确保所有的交易和改变的结果状态都被应用了，然后在区块奖励被应用于最终交易结果状态之后定义一个新块为状态。通过检查最终状态与存储在头中的状态树来进行验证。 工作量证明挖矿在“区块”这个章节简短的说明了一下区块难度这个概念。给予区块难度意义的算法叫做工作量证明（PoW）。 以太坊的工作量证明算法称之为“Ethash” （之前叫做Dagger-Hashimoto）。算法正式定义为：m代表的是mixHash，n代表的是nonce，Hn代表的是新区块的头（不包含需要计算的nonce和mixHash），Hn是区块头的nonce，d是DAG ，就是一个大数据集。 在”区块”章节，我们讨论了存在于区块头中的多项。其中两项叫做mixHash和nonce。也许你会回忆起： mixHash：一个Hash值，当与nonce组合时，证明此区块已经执行了足够的计算 nonce：一个Hash值，当与mixHash组合时，证明此区块已经执行了足够的计算 PoW函数就是用来估算这两项的。mixHash和nonce到底是如何使用PoW函数来计算出来的有点复杂，如果深入了解的话，我们可以另写一篇文章来讲解了。但是在一个高层面上，它大致就是这样计算的：会为每个区块计算一个”种子”。每个“时期”的种子都不一样，每个时期是30,000个区块长度。对于第一时期，种子就是32位0的Hash值。对于后续的每个时期，种子就是前一个种子Hash值的Hash值。使用这个种子，节点可以计算出一个伪随机“缓存”。 这个缓存是非常有用的，因为它可以使“轻节点”的概念变成现实，轻节点概念在这篇文章的前面讨论过。轻节点的目的就是让某个节点有能力高效的校验交易而用不着存储整个区块链的数据集。一个轻节点可以仅基于缓存来校验一个交易的有效性，因为缓存可以重新生成需要校验的特定块。 使用这个缓存，节点可以生成DAG“数据集”，数据集中的每项取决于缓存中少量伪随机选择项。为了成为矿工，你需要要生成全数据集，所有全客户端和矿工都保存这个数据集，并且这个数据集随着时间线性增长。 然后矿工可以随机抽取数据集中的部分并将它们放入一个数学函数中Hash出一个”mixHash”。矿工会重复生成mixHash直到输出的值小于想要的目标值nonce。当输出的值符合这个条件的时候，nonce就被认为是有效的，然后区块就被添加到链中。 挖矿作为安全机制总的来说，PoW的目的就是以加密安全的方式证明生成的一些输出（也就是nonce）是经过了一定量的计算的。因为除了列举所有的可能性，没有更好的其他方法来找到一个低于要求阈值的nonce。重复应用Hash函数的输出均匀分布，所以我们可以确保，在平均值上，找到满足要求的nonce所需时间取决于难度阈值。难度系数越大，所需时间越长。这样的话，PoW算法就给予难度这个概念意义了：用来加强区块链的安全。 我们所说的区块链的安全又是什么意思？这非常简单：我们想要创造一个每个人都信任的区块链。像我们之前在这篇文章中讨论的那样，如果存在超过1条以上的链，用户的信任就会消失，因为他们没有能力合理的确认哪条链才是“有效的”。为了让一群用户接受存储在区块链中的潜在状态，我们需要有一群人信任的一个权威区块链。 这完完全全就是Pow算法所做的事情：它确保特定的区块链直到未来都一直保持着权威性，让攻击者创造一个新区块来重写某个历史部分（例如清除一个交易或者创建一个假的交易）或者保持一个分叉变得非常困难。为了首先让他们的区块被验证，攻击者需要总是比网络上的其他人更快的解决掉nonce问题，这样网络就会相信他们的链是最重的链（基于我们之前提到的GHOST协议原则）。除非攻击者拥有超过一半的网络挖矿能力（这种场景也被称为大多数51%攻击），要不然这基本上是不可能的。 挖矿作为财富分配机制除了提供一个安全的区块链，PoW同样也是分配财富给那些为提供这个安全而花费自己计算力的人的一种方法。回忆一下，一个矿工挖出一个区块的时候会获得奖励，包括： 为“获胜”区块提供的5 ether静态区块奖励（马上就会变成3 ether） 区块中的交易在区块内所消耗的gas 纳入ommers作为区块的一部分的额外奖励 为了保证PoW共识算法机制对安全和财富分配的使用是长期可持续的，以太坊努力灌输这两个特性： 尽可能的让更多的人可访问。换句话说，人们不需要特殊的或者与众不同的硬件来运行这个算法。这样做的目的是为了让财富分配模式变的尽可能的开放，以便任何人都可以提供一些算力而获得Ether作为回报。 降低任何单个节点（或小组）能够创造与其不成比例的利润可能性。任何可以创造不成比例的利润的节点拥有比较大的影响力来决定权威区块链。这是件麻烦的事情，因为这降低了网络的安全性。 在区块链网络中，与上面两个特性有关的一个问题是PoW算法是SHA256哈希函数。这种函数的缺点就是它使用特殊的硬件（也被称之为ASCIs）可以更加快速高效的解决nonce问题。 为了减轻这个问题，以太坊选择让PoW算法(Ethhash) 提高内存级别难度。意思是此算法被设计为计算出要求的nonce需要大量的内存和带宽。大量内存的需求让电脑平行的使用内存同时计算多个nonce变得极其困难，高带宽的需求让即使是超级电脑同时计算多个nonce也变得十分艰难。这种方式降低了中心化的风险，并为正在进行验证的节点提供了更加公平的竞争环境。 有一件值得注意的事情是以太坊正在从PoW共识机制渐渐转换为一个叫做“权益证明(PoS)”的共识算法。这就是一个比较野心的话题了，我们希望可以在未来的文章中探索这个话题。 总结（PS：原文的总结）呼！ 你终于坚持到最后了。我希望如此？ 这篇文章中有很多的地方需要消化。如果需要你阅读好几遍才能理解怎么回事，这完全正常。我个人重复阅读了好几次以太坊黄皮书，白皮书，以及代码的不同部分才渐渐明白是怎么回事。 无论如何，我希望你觉得这篇文章对你有帮助。如果你发现了任何的错误或失误，我很乐意你给我写个私人消息或者直接在评论区评论（我保证我会查看所有评论）。 记住，我是个人类（对，这是真的），我会犯错误。为了社区的利益，我花时间免费写了这篇文章。所以请你在反馈时不要带着没必要的攻击性，尽量是建设性的反馈。 以太坊的黄皮书 总结（自己的总结）第二遍读完，又多消化了一些内容，也总结了一些问题，列在下面： storageRoot和codeHash存储的都是hash值，那么原本的内容被存在哪里？ 合约代码会发生改变吗？代码里面的状态值是怎样体现改变的？ 账户的唯一性是由nonce来确定的吗？ 账户的信息又是怎么保存在区块链上呢？ 什么时候需要重新执行交易呢？交易的结果状态没有被记录吗？ 日志是如何保留的？ 下一步，一个问题一个问题去研究。]]></content>
      <categories>
        <category>Blockchain</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>以太坊</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git：git-checkout的用法总结（2）]]></title>
    <url>%2Fgit%2Fgit-checkout-2.html</url>
    <content type="text"><![CDATA[原帖收藏于IT老兵驿站，传递一个IT老兵在凋零前的光和氧。Git的git-checkout的用法总结。 前言结合前一篇文章，再认真总结一下git-checkout的用法，因为可能一次总结到不了位，那么就不怕啰嗦，不怕重复，多总结几次，这样可能会造成每篇文章内容之间的分布不是那么清晰，将来再做更好的整理吧，因为现在这种方式，对于当前的学习是有帮助的，是从浅入深的。 正文概要1git-checkout - Switch branches or restore working tree files 从上面可见，git checkout是用来切换分支或者回复工作目录的，看到这里，记住这一点，会有很大帮助。（备注：我发现，有的时候，学习的节奏放慢一些，反而其实是更有效率的，反而是更快的。多思考一些，记的更准确，因慢得快） 语法1234567git checkout [-q] [-f] [-m] [&lt;branch&gt;]git checkout [-q] [-f] [-m] --detach [&lt;branch&gt;]git checkout [-q] [-f] [-m] [--detach] &lt;commit&gt;git checkout [-q] [-f] [-m] [[-b|-B|--orphan] &lt;new_branch&gt;] [&lt;start_point&gt;]git checkout [-f|--ours|--theirs|-m|--conflict=&lt;style&gt;] [&lt;tree-ish&gt;] [--] &lt;paths&gt;…​git checkout [&lt;tree-ish&gt;] [--] &lt;pathspec&gt;…​git checkout (-p|--patch) [&lt;tree-ish&gt;] [--] [&lt;paths&gt;…​] 用法11git checkout &lt;branch&gt; 用来切换到一个分支上。切换index和工作目录，还有HEAD 指针到这个分支上。本地发生的修改也会被保留。如果本地不存在这个分支而远程存在同名分支的话，则这个命令相当于： 1$ git checkout -b &lt;branch&gt; --track &lt;remote&gt;/&lt;branch&gt; 1git checkout -b|-B &lt;new_branch&gt; [&lt;start point&gt;] -b表示创建新分支；如果分支存在的话，不进行任何处理。-B 在创建新分支的功能和-b 是一样的；但是，如果分支存在的话，它会重置&lt;start_point&gt;。 1234567Specifying -b causes a new branch to be created as if git-branch[1] were called and then checked out. In this case you can use the --track or --no-track options, which will be passed to git branch. As a convenience, --track without -b implies branch creation; see the description of --track below.If -B is given, &lt;new_branch&gt; is created if it doesn’t exist; otherwise, it is reset. This is the transactional equivalent of$ git branch -f &lt;branch&gt; [&lt;start point&gt;]$ git checkout &lt;branch&gt;that is to say, the branch is not reset/created unless &quot;git checkout&quot; is successful. 这里涉及到track 和&lt;start point&gt;的概念。track表示的是远程仓库与之对应的分支，这个信息被称为upstream，上游，远程仓库的，是上游。本地的，是下游，有一个对应的关系。track 本意是轨迹、跟踪的意思，使用了--track或者--no-track 来设置这个，这个信息会传递给git branch。 用法212git checkout --detach [&lt;branch&gt;]git checkout [--detach] &lt;commit&gt; 切换代码到某一个提交号或者分支上，并且分离了HEAD指针，指向了这个提交。这块有点复杂，还需要理解深度理解一下，这个可能要留到下一篇帖子来完成了，争取每天整理一些（2018-08-03）。 整理完成，可以参考这里（2018-08-04）。 用法312git checkout [&lt;tree-ish&gt;] [--] &lt;pathspec&gt;…​git checkout (-p|--patch) [&lt;tree-ish&gt;] [--] [&lt;pathspec&gt;…​] 从index或者&lt;tree-ish&gt; 检出代码来替换&lt;pathspec&gt; 处的代码。如果&lt;tree-ish&gt; 被指定了，那么index和工作空间的代码都会被更新。 The index may contain unmerged entries because of a previous failed merge. By default, if you try to check out such an entry from the index, the checkout operation will fail and nothing will be checked out. Using -f will ignore these unmerged entries. The contents from a specific side of the merge can be checked out of the index by using –ours or –theirs. With -m, changes made to the working tree file can be discarded to re-create the original conflicted merge result. index区域可能还有一些没有merge的条目，因为之前有失败的merge。 后一种用法使用互动的方式来完成这个功能。 到此，这个命令的用法基本整理完，下一步，要实践一些实例。]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>用法</tag>
        <tag>checkout</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git：DETACHED HEAD的概念]]></title>
    <url>%2Fgit%2Fgit-DETACHED-HEAD.html</url>
    <content type="text"><![CDATA[原帖收藏于IT老兵驿站，传递一个IT老兵在凋零前的光和氧。Git：DETACHED HEAD的概念。 原帖收藏于IT老兵驿站，传递一个IT老兵凋零前的光和氧。 前言在git使用的时候，经常会碰到DETACHED HEAD，在此总结一下。 正文 HEAD normally refers to a named branch (e.g. master). Meanwhile, each branch refers to a specific commit. Let’s look at a repo with three commits, one of them tagged, and with branch master checked out: 1234567 HEAD (refers to branch &apos;master&apos;) | va---b---c branch &apos;master&apos; (refers to commit &apos;c&apos;) ^ | tag &apos;v2.0&apos; (refers to commit &apos;b&apos;) 上面是一个常见的例子，三个提交，HEAD指针指向c，往往是这个分支上最后的提交。然后又进行了一次修改和提交，生成了d。 123456789$ edit; git add; git commit HEAD (refers to branch &apos;master&apos;) | va---b---c---d branch &apos;master&apos; (refers to commit &apos;d&apos;) ^ | tag &apos;v2.0&apos; (refers to commit &apos;b&apos;) 这个时候我们需要重新检出v2.0版本（这种可能性是很大，经常容易出现的），如下： 12$ git checkout v2.0 # or$ git checkout master^^ 1234567 HEAD (refers to commit &apos;b&apos;) | va---b---c---d branch &apos;master&apos; (refers to commit &apos;d&apos;) ^ | tag &apos;v2.0&apos; (refers to commit &apos;b&apos;) 这个时候HEAD指针就指向了b，这就是detached HEAD状态，这意味着HEAD指向了某一个提交了，而不再指向当前分支的最后一个提交了。 然后我们又进行了一次提交，就会变成这样： 1234567891011$ edit; git add; git commit HEAD (refers to commit &apos;e&apos;) | v e /a---b---c---d branch &apos;master&apos; (refers to commit &apos;d&apos;) ^ | tag &apos;v2.0&apos; (refers to commit &apos;b&apos;) one more time，再来一次：1$ edit; git add; git commit 123456789 HEAD (refers to commit &apos;f&apos;) | v e---f /a---b---c---d branch &apos;master&apos; (refers to commit &apos;d&apos;) ^ | tag &apos;v2.0&apos; (refers to commit &apos;b&apos;) 我们可以做任何正常的git操作，如果你想回到master分支，那么。 123456789$ git checkout master HEAD (refers to branch &apos;master&apos;) e---f | / va---b---c---d branch &apos;master&apos; (refers to commit &apos;d&apos;) ^ | tag &apos;v2.0&apos; (refers to commit &apos;b&apos;) 这个时候要意识到没有指针指向f提交，最后e和f 都会被常规的Git垃圾回收所删除掉，除非我们创建一个指针，例如: 123$ git checkout -b foo (1)$ git branch foo (2)$ git tag foo (3) 创建了一个新的分支指向f，并且更新了HEAD指针，这样HEAD指针就不再是detached状态了 简单创建了一个新的分支指向f，这个时候HEAD指针仍然是detached状态。3.创建了一个新tag，指向f，这个时候HEAD指针仍然是detached状态。 If we have moved away from commit f, then we must first recover its object name (typically by using git reflog), and then we can create a reference to it. For example, to see the last two commits to which HEAD referred, we can use either of these commands: 如果f已经被移除了，我们首先需要恢复它的对象名，使用git reflog，然后我们创建一个指针指向它。例如，想看到HEAD之前的最后两个提交，我们可以使用下面的命令（二选一）： 12$ git reflog -2 HEAD # or$ git log -g -2 HEAD 总结这篇总结基本上还是以翻译为主，留了一个问题，就是reflog。]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>DETACHED HEAD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git：git-tag的用法总结]]></title>
    <url>%2Fgit%2Fgit-tag.html</url>
    <content type="text"><![CDATA[原帖收藏于IT老兵驿站，传递一个IT老兵在凋零前的光和氧。Git：git-tag的用法总结。 前言Git的tag和SVN不一样，SVN的tag其实还是一个分支，Git的tag则真的是一个标签，是给某一个commit打上一个标签，这个说明了Linus的巧妙设计，那么，对这个tag做一个笔记。 正文记录几个主要的命令，用于速查：实例：列显已有的标签 1$ git tag 实例：只看某一个tag 1$ git tag -l &apos;v1.4.2.*&apos; 实例：新建含附注的标签 1$ git tag -a v1.4 -m &apos;my version 1.4&apos; -a相当于给标签起个名字，-m是写一些注释。 实例：查看相应标签的版本信息，并连同显示打标签时的提交对象 1$ git show v1.4 实例：签署标签1$ git tag -s v1.5 -m &apos;my signed 1.5 tag&apos; 实例：轻量级标签1$ git tag v1.4-lw 实例：验证标签1$ git tag -v v1.4.2.1 这个功能的具体意义还没有搞明白。 实例：后期加注标签 1$ git tag -a v1.2 9fceb02 实例：推送某一标签到服务器1$ git push origin v1.5 实例：推送所有标签到服务器1$ git push origin --tags 参考https://git-scm.com/book/zh/v1/Git-%E5%9F%BA%E7%A1%80-%E6%89%93%E6%A0%87%E7%AD%BE]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>git tag</tag>
        <tag>标签</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git：git-reset的用法总结]]></title>
    <url>%2Fgit%2Fgit-reset.html</url>
    <content type="text"><![CDATA[原帖收藏于IT老兵驿站，传递一个IT老兵在凋零前的光和氧。Git：git-reset的用法总结。 前言Git reset感觉是相当复杂的一个指令，用了快一年了，总感觉还没有用明白，所以，需要好好总结一下。 语法123git reset [-q] [&lt;tree-ish&gt;] [--] &lt;paths&gt;…​git reset (--patch | -p) [&lt;tree-ish&gt;] [--] [&lt;paths&gt;…​]git reset [--soft | --mixed [-N] | --hard | --merge | --keep] [-q] [&lt;commit&gt;] In the first and second form, copy entries from to the index. In the third form, set the current branch head (HEAD) to , optionally modifying index and working tree to match. The / defaults to HEAD in all forms. 这个命令有三种用法，前两种用来从&lt;tree-ish&gt;所指定的地方拷贝条目到index（其实是说从仓库的某一个版本获取到index区域）。第三种格式，将当前分支的HEAD指针设定为&lt;commit&gt; 这个提交号，同时可以选择性地修改index和工作区域。 tree-ish是什么意思呢？要参考这里，是Git所使用的指明路径的语法。类似以下这样的格式： 123&lt;rev&gt;:&lt;path&gt;, e.g. HEAD:README, :README, master:./README A suffix : followed by a path names the blob or tree at the given path in the tree-ish object named by the part before the colon. 备注：但是感觉这里这个解释放在这里不是很准确，这里的&lt;tree-ish&gt; 似乎是指类似HEAD、master~3、&lt;sha1&gt; 而不包含冒号以及后面的部分。 用法1git reset [-q] [&lt;tree-ish&gt;] [--] &lt;paths&gt;…​ This form resets the index entries for all to their state at . (It does not affect the working tree or the current branch.) This means that git reset is the opposite of git add . After running git reset to update the index entry, you can use git-checkout[1] to check the contents out of the index to the working tree. Alternatively, using git-checkout[1] and specifying a commit, you can copy the contents of a path out of a commit to the index and to the working tree in one go. 这个用法将index区域所有符合的条目修改为&lt;tree-ish&gt; 的状态。（这并不影响工作目录或者当前分支。）这个reset是更新index条目，更新后，可以从index中通过checkout指令获取内容到工作目录。如果git checkout指定了一个提交号，那么就可以根据这个提交号更新内容到index和工作目录。 关于ORIG_HEAD的介绍：需要参考这里。 HEAD is (direct or indirect, i.e. symbolic) reference to the current commit. It is a commit that you have checked in the working directory (unless you made some changes, or equivalent), and it is a commit on top of which “git commit” would make a new one. Usually HEAD is symbolic reference to some other named branch; this branch is currently checked out branch, or current branch. HEAD can also point directly to a commit; this state is called “detached HEAD”, and can be understood as being on unnamed, anonymous branch. And @ alone is a shortcut for HEAD, since Git 1.8.5 ORIG_HEAD is previous state of HEAD, set by commands that have possibly dangerous behavior, to be easy to revert them. It is less useful now that Git has reflog: HEAD@{1} is roughly equivalent to ORIG_HEAD (HEAD@{1} is always last value of HEAD, ORIG_HEAD is last value of HEAD before dangerous operation). For more information read git(1) manpage, Git User’s Manual, the Git Community Book and Git Glossary HEAD是指当前分支上当前的提交号。ORIG_HEAD 是指上一个HEAD所指向的提交号。这其实是两个指针，第二个指针的设计其实是为了做保护，一旦第一个指针被误操作了，还有机会去挽回。 实例：将发生改变的文件 _config.yml加入index ：1$ git add _config.yml 这样_config.yml 文件就被加入到index区域中，显示成：1234Changes to be committed: (use &quot;git reset HEAD &lt;file&gt;...&quot; to unstage) modified: _config.yml 撤销上面的操作，恢复_config.yml为版本库中的状态：1$ git reset _config.yml 这种用法相当于&lt;tree-ish&gt;的参数设置为HEAD。 用法2git reset (--patch | -p) [&lt;tree-ish&gt;] [--] [&lt;paths&gt;…​] Interactively select hunks in the difference between the index and (defaults to HEAD). The chosen hunks are applied in reverse to the index. This means that git reset -p is the opposite of git add -p, i.e. you can use it to selectively reset hunks. See the “Interactive Mode” section of git-add[1] to learn how to operate the –patch mode. 这个用法是以patch 的方式展示出来需要reset的代码， git reset -p 和git add -p 就是一对互为反向的操作，后者是把工作目录下变更的代码以patch 的方式展示出来，以互动的方式应用到index上，前者则是一个反向操作。 实例：将发生改变的文件 _config.yml加入index ：1$ git add -p _config.yml 撤销上面的操作：1$ git reset -p _config.yml 可以看到，这种用法相对上面那一种用法其实是增加了互动的提醒。 用法3git reset [&lt;mode&gt;] [&lt;commit&gt;] This form resets the current branch head to and possibly updates the index (resetting it to the tree of ) and the working tree depending on . If is omitted, defaults to “–mixed”. The must be one of the following: 这个用法是用来设置当前的分支的HEAD指针，或者index 的指向当前版本的指针，或者工作空间指向当前版本的指针。 –softDoes not touch the index file or the working tree at all (but resets the head to , just like all modes do). This leaves all your changed files “Changes to be committed”, as git status would put it. soft参数用来设置HEAD指针。 –mixedResets the index but not the working tree (i.e., the changed files are preserved but not marked for commit) and reports what has not been updated. This is the default action. mixed参数用来设置index指针，文件的修改仍然会被保留，但是没有纳入到index中。 If -N is specified, removed paths are marked as intent-to-add (see git-add[1]). –hardResets the index and working tree. Any changes to tracked files in the working tree since are discarded. hard重置index和工作区域，所有在这个&lt;commit&gt;之后的修改将被丢弃。 –mergeResets the index and updates the files in the working tree that are different between and HEAD, but keeps those which are different between the index and working tree (i.e. which have changes which have not been added). If a file that is different between and the index has unstaged changes, reset is aborted. In other words, –merge does something like a git read-tree -u -m , but carries forward unmerged index entries. merge重置index ，并且更新那些工作区的文件（在&lt;commit&gt;和HEAD中不同的）。这个还需要进一步理解一下。 –keepResets index entries and updates files in the working tree that are different between and HEAD. If a file that is different between and HEAD has local changes, reset is aborted. If you want to undo a commit other than the latest on a branch, git-revert[1] is your friend. 实例 版本库中的提交如下：1234567891011121314151617181920212223commit cac453cf6501c3ea3b626636bc4399ed48704543 (HEAD -&gt; master, origin/master, origin/HEAD)Author: xxx &lt;xxx@xxx.xxx&gt;Date: Fri Jul 27 18:08:46 2018 +0800 从版本库中移除项目配置文件和日志配置文件commit cd36b7297106a871ae331f487179fd5584fb38cdAuthor: xxx &lt;xxx@xxx.xxx&gt;Date: Fri Jul 27 18:06:37 2018 +0800 暂时参考原来的逻辑，使用硬编码的方式，新增了权限commit 24f19e80b5b8e2c05faf04706d95b5ac538ddbdd (f_1486)Author: xxx &lt;xxx@xxx.xxx&gt;Date: Wed Jul 11 22:00:43 2018 +0800 修改了login的登录按钮的宽度commit e948bb044676ff917be862d9fae8391ba1b82351Author: xxx &lt;xxx@xxx.xxx&gt;Date: Tue Jul 10 23:39:28 2018 +0800 完成初步的修改 现在发现最后三次提交是存在问题的，不应该直接提交到master上，这个时候需要把HEAD指针恢复到倒数第四次提交上。1git reset --soft e948bb044676ff917be862d9fae8391ba1b82351 这样后面三次提交的改变从版本库还原出来，变成尚未提交的状态，这样我们就可以新开一个临时的dev分支，继续我们之前的工作（参考Git Flow一篇文章）。]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>用法</tag>
        <tag>git reset</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[区块链：比特币难度的概念]]></title>
    <url>%2Fblockchain%2Fbitcoin-difficulty.html</url>
    <content type="text"><![CDATA[原帖收藏于IT老兵驿站，传递一个IT老兵在凋零前的光和氧。区块链：比特币难度的概念。 前言这篇笔记记录一下对于比特币难度的学习，参考这里，记录下来自己的理解，哩哩啦啦地写了两天，边看边查，还是没有理解到位，等待之后再补充吧。 正文 Difficulty is a measure of how difficult it is to find a hash below a given target. Difficulty 是用来衡量找到一个低于给定目标的hash的困难程度。 难度公式： difficulty = difficulty_1_target / current_target(target is a 256 bit number) 有许多不同测量难度的方法，得到的difficulty_1_target可能不同。传统地，它表示一个HASH值，前32位为0，后面都为1（也就是被称为“矿池难度”或“pdiff”的值），比特币协议把目标HASH表示成一个有限精度的自定义浮点类型。因而，比特币客户端用该值来估计难度(称之为：“bdiff”)。 难度如何保存在区块上呢？每一个区块会用一种压缩的格式（被称为“Bits”）来表示实际的16进制的目标值。目标值通过一个预先定义好的公式，从这个压缩值中得出。举一个例子，压缩值为0x1b0404cb，16进制的目标值则是： 10x0404cb * 2**(8*(0x1b - 3)) = 0x00000000000404CB000000000000000000000000000000000000000000000000 Note that the 0x0404cb value is a signed value in this format. The largest legal value for this field is 0x7fffff. To make a larger value you must shift it down one full byte. Also 0x008000 is the smallest positive valid value. 注意0x0404cb 是一个符号数，最大值是0x7fffff，这个明白，下面两句就不明白了：如果想生成一个更大的值，你需要向下移动一整个字节。同时，0x008000 是最小的正值（为什么不是0x000001呢？）。 难度如何计算？最大目标难度（1）被定义成0x1d00ffff， 那么 10x00ffff * 2**(8*(0x1d - 3)) = 0x00000000FFFF0000000000000000000000000000000000000000000000000000 这个是截断后的目标值，就是上文所说的比特币协议定义的格式，如果没有截断，那么就是： 10x00000000FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF 所以0x1b0404cb 位置的难度是： 1230x00000000FFFF0000000000000000000000000000000000000000000000000000 /0x00000000000404CB000000000000000000000000000000000000000000000000 = 16307.420938523983 (bdiff) 或者： 1230x00000000FFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFF /0x00000000000404CB000000000000000000000000000000000000000000000000 = 16307.669773817162 (pdiff) 当前难度是什么Current difficulty。这个是比特币浏览器提供的接口，给出了当前难度。 什么是最大难度 There is no minimum target. The maximum difficulty is roughly: maximum_target / 1 (since 0 would result in infinity), which is a ridiculously huge number (about 2^224). The actual maximum difficulty is when current_target=0, but we would not be able to calculate the difficulty if that happened. (fortunately it never will, so we’re ok.) 不存在最小的目标。最大难度可以粗暴地认为是：maximum_target / 1（因为0会产生无限值），这个数很大，大约是2的224次方。 网络难度是否可以降低可以，参考上面的内容。 最小难度是什么 The minimum difficulty, when the target is at the maximum allowed value, is 1. 当targe是最大允许值的时候，最小难度，也就是1。这里说的target应该是分母，分子的最大值是确定的，上文已经说过了。 在给定难度的情况下，网络hash率是如何得出的根据10分钟一块的平均速度，产生2016个块应该需要两周。每产生2016个块，会调整一下难度，根据之前产生这2016个块花费的时间，和理论上应该花费的时间–两周做一下对比。 难度为1时的目标值（上文提到的）： 10xffff * 2**208 难度为D时的目标值应该是： 1(0xffff * 2**208) / D 所需要的hash计算数（2**256是最大hash计算数，除以当前的目标值，也是一个256位的数，例如上面的0x00000000000404CB000000000000000000000000000000000000000000000000 ，这个地方不是太理解，这样除，就可以算出总共需要的计算数？翻了一些帖子，还是没有找到答案）1D * 2**256 / (0xffff * 2**208) 简化为： 1D * 2**48 / 0xffff 以上是10分钟的hash数，hash率是以秒为单位的，所以：1D * 2**48 / 0xffff / 600 最后简化为： 1D * 2**32 / 600 如果难度为1的话，每秒钟7 Mhashes。原文写作时，难度是 22012.4941572，那么过去2016个块的hash率是： 122012.4941572 * 2**32 / 600 = around 157 Ghashes per second. 参考https://en.bitcoin.it/wiki/Difficulty。]]></content>
      <categories>
        <category>Blockchain</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>比特币</tag>
        <tag>难度</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git：git-branch的用法总结]]></title>
    <url>%2Fgit%2Fgit-branch.html</url>
    <content type="text"><![CDATA[原帖收藏于IT老兵驿站，传递一个IT老兵在凋零前的光和氧。git-branch的用法总结。 前言git branch的用法。这个命令使用频度很高，还有一些没有搞明白，在这里总结梳理一下。 PS：之前的文章题目命名都用空格，以前一直不理解git的官网为什么多加一个“-”，现在明白了，为了用作文章名和题目比较方便，解了一个惑。 正文用法12345678910111213git branch [--color[=&lt;when&gt;] | --no-color] [-r | -a] [--list] [-v [--abbrev=&lt;length&gt; | --no-abbrev]] [--column[=&lt;options&gt;] | --no-column] [--sort=&lt;key&gt;] [(--merged | --no-merged) [&lt;commit&gt;]] [--contains [&lt;commit]] [--no-contains [&lt;commit&gt;]] [--points-at &lt;object&gt;] [--format=&lt;format&gt;] [&lt;pattern&gt;…​] // 列出分支（这个用法有点复杂） git branch [--track | --no-track] [-l] [-f] &lt;branchname&gt; [&lt;start-point&gt;] // 设置分支本地和远程的关系（上流）git branch (--set-upstream-to=&lt;upstream&gt; | -u &lt;upstream&gt;) [&lt;branchname&gt;] // 设置分支上流git branch --unset-upstream [&lt;branchname&gt;] // 取消分支上流的设置git branch (-m | -M) [&lt;oldbranch&gt;] &lt;newbranch&gt; // 重命名分支git branch (-c | -C) [&lt;oldbranch&gt;] &lt;newbranch&gt; // 拷贝分支git branch (-d | -D) [-r] &lt;branchname&gt;…​ // 删除分支git branch --edit-description [&lt;branchname&gt;] //修改分支描述 git branch有以上这么多种用法，原本我看了几遍，也感觉云山雾绕，需要在上面加了一些备注。 常用实例实例： 展示分支最简单的形式：12$ git branch* master 较为详细的形式：12$ git branch -v* master cac453c 从版本库中移除项目配置文件和日志配置文件 可以看到，加了-v，显示出了提交号。 更为详细的形式：12$ git branch -vv* master cac453c [origin/master] 从版本库中移除项目配置文件和日志配置文件 可以看到，加两个v，除了显示出了提交号，还显示出了上流分支（upstream）的名称。。 实例： 查看所有分支（包括远程的） 12345678910111213$ git branch -a* master remotes/origin/HEAD -&gt; origin/master remotes/origin/dev remotes/origin/f_1123 remotes/origin/f_1268 remotes/origin/f_1316 remotes/origin/f_1317 remotes/origin/f_1346 remotes/origin/f_1347 remotes/origin/f_1490 remotes/origin/f_english remotes/origin/master -a就是-all的意思，显示所有。 实例： 查看远程分支 123456789101112$ git branch -r origin/HEAD -&gt; origin/master origin/dev origin/f_1123 origin/f_1268 origin/f_1316 origin/f_1317 origin/f_1346 origin/f_1347 origin/f_1490 origin/f_english origin/master 比上面那个指令少了一项master。-r的意思是remote，显示远程的分支情况。 实例：修改分支名把master分支名称修改成dev，这里仅仅是举一个例子，正常工作中一般是不应该发生这样的修改。1git branch -m master dev 实例：删除分支删除dev分支。1git branch -D dev 参考https://git-scm.com/docs/git-branch。]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>git branch</tag>
        <tag>用法</tag>
        <tag>分支</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java：“目标服务器没有返回一个X-Frame-Options头”的解决方案]]></title>
    <url>%2Fjava%2Fjava-springmvc-X-Frame-Options.html</url>
    <content type="text"><![CDATA[原帖位于IT老兵博客，沉淀着一个IT老兵对于这个行业的认知。 Java：“目标服务器没有返回一个X-Frame-Options头”的解决方案。 前言在涉及网站安全时遇到一个问题（360网站安全测试也会报告），“目标服务器没有返回一个X-Frame-Options头”，找了网上的帖子，说的都不是太清楚，所以研究总结一下，方便后人。 正文问题描述以下摘录一下对于安全网站这个问题的描述和建议解决方案： 概要目标服务器没有返回一个X-Frame-Options头。攻击者可以使用一个透明的、不可见的iframe，覆盖在目标网页上，然后诱使用户在该网页上进行操作，此时用户将在不知情的情况下点击透明的iframe页面。通过调整iframe页面的位置，可以诱使用户恰好点击iframe页面的一些功能性按钮上，导致被劫持。解决方案修改web服务器配置，添加X-frame-options响应头。赋值有如下三种：（1）DENY：不能被嵌入到任何iframe或frame中。（2）SAMEORIGIN：页面只能被本站页面嵌入到iframe或者frame中。（3）ALLOW-FROM uri：只能被嵌入到指定域名的框架中。也可在代码中加入，在PHP中加入：header(‘X-Frame-Options: deny’); 具体实例但是我们的环境是Java的Springmvc，这个应该怎么解决呢？其实Spring框架中的security本身有对这个问题的解决方案，但是这是之前的Spring框架中的（SSH那会的），现在用了SpringMVC了，应该怎么去解决这个问题呢？ 参考这里，这里介绍说配置项目的web.xml文件如下，即可解决问题： 1234567891011121314&lt;filter&gt; &lt;filter-name&gt;httpHeaderSecurity&lt;/filter-name&gt; &lt;filter-class&gt;org.apache.catalina.filters.HttpHeaderSecurityFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;antiClickJackingOption&lt;/param-name&gt; &lt;param-value&gt;SAMEORIGIN&lt;/param-value&gt; &lt;/init-param&gt; &lt;async-supported&gt;true&lt;/async-supported&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;httpHeaderSecurity&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 但是我这里又引出一个新的问题： cvc-complex-type.2.4.a: Invalid content was found starting with element ‘async-supported’. One of ‘{“http://java.sun.com/xml/ns/javaee&quot;:run-as, “http://java.sun.com/xml/ns/javaee&quot;:security-role-ref}&#39; is expected. 意思是说async-supported这个元素不被识别。继续探索，找到这里说的： xmlns中再加两行：http://www.springmodules.org/schema/cache/springmodules-cache.xsdhttp://www.springmodules.org/schema/cache/springmodules-ehcache.xsd 要在web.xml顶部的xmlns里面再加两行，问题才真正得到了解决。 分析问题是解决了，但是问题产生的原因和解决的方法又是什么呢？ ###首先，这样设置web.xml的目的是什么？ 找到Tomcat官网的讲解： org.apache.catalina.filters.HttpHeaderSecurityFilter .//过滤器的类名……antiClickJackingOption //参数配置，可以设置成DENY（拒绝），SAMEORIGIN（同源），ALLOW-FROM（允许从哪里来的）What value should be used for the anticlick-jacking header? Must be one of DENY, SAMEORIGIN, ALLOW-FROM (case-insensitive). If not specified, the default value of DENY will be used. 意思是说HttpHeaderSecurityFilter 这个过滤器是用来做anticlick-jacking（防止点击劫持，Java做Web服务的优越性就在这里，很多功能都已经做成了工具类，只需要配置一下即可）。三个配置选项，我们上文中配置成了SAMEORIGIN（同源），安全性就大大提高了。那么，上面配置这个过滤器就搞明白了，那么后面出现的那个问题又是怎么回事呢？ 其次，web.xml的这个设置错误又是怎么回事？这里要研究一下这段语句的意思，在web.xml的头部，可能很多人总会看到它，但不会去思考它：1234567&lt;web-app version=&quot;3.0&quot; xmlns=&quot;http://java.sun.com/xml/ns/javaee http://www.springmodules.org/schema/cache/springmodules-cache.xsd http://www.springmodules.org/schema/cache/springmodules-ehcache.xsd&quot; xmlns:xsi=&quot;http://www.w3.org/2001/XMLSchema-instance&quot; xsi:schemaLocation=&quot;http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_3_0.xsd&quot;&gt; xmlns：xml的namespace，这个是为了解决多个开发者对于xml的命名会产生冲突的问题。xmlns:xsi：定义了xml的标准前缀。xsi:schemaLocation：xml的schema定义的位置。 简言之，Java对于xml的名值设置了一套定义规则，发布在上面的地方，我们上面使用的这个元素名async-supported ，在之前的web.xml中所定义的位置是没有找到的，加了那两行的命名空间的定义，才可以找到这个元素定义的位置。 至此，问题基本搞明白了。 参考https://www.w3schools.com/xml/schema_intro.asp。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>tomcat</tag>
        <tag>linux</tag>
        <tag>X-Frame-Options</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git：git diff发现windows下会出现"^M"符号]]></title>
    <url>%2Fgit%2Fgit-diff-m-symbol.html</url>
    <content type="text"><![CDATA[原帖收藏于IT老兵驿站，传递一个IT老兵凋零前的光和氧。 Git：git diff发现windows下会出现”^M”符号。 前言在不同操作系统上编译Git仓库的文件，经常在git diff 时发现很多文件的变化是尾部多了一个^M 的符号。这给工作带来很多困扰，研究一下这个问题。 正题翻到这个帖子： GitHub suggests that you should make sure to only use \n as a newline character in git-handled repos. There’s an option to auto-convert: 1$ git config --global core.autocrlf true 大体翻译：GitHub建议你应该只用\n 来做为新行的开始，用上面那样的设置就可以做到自动的转换，这样也就解决了问题，Git不会再报告差异。 那这是为什么呢？ 阅读一下这里所介绍的这个帖子。 If you’re using Git to collaborate with others on GitHub, ensure that Git is properly configured to handle line endings. Every time you press return on your keyboard you’re actually inserting an invisible character called a line ending. Historically, different operating systems have handled line endings differently. When you view changes in a file, Git handles line endings in its own way. Since you’re collaborating on projects with Git and GitHub, Git might produce unexpected results if, for example, you’re working on a Windows machine, and your collaborator has made a change in OS X. 这里大概是说每个操作系统有自己的换行符（就是当你按下”回车”后，系统会自动插入一些不可见的符号来表示一行的结束），Linux和Mac都是使用LF ，Windows 则是CRLF ，这样就造成了差异。 Git会对此进行一些处理，但是做什么处理呢？这里没有说清楚，只是说要用 1git config core.autocrlf 来控制，和上面说的是一样的，但是原理还是没有搞明白。 只好来看官网。 core.autocrlfSetting this variable to “true” is the same as setting the text attribute to “auto” on all files and core.eol to “crlf”. Set to true if you want to have CRLF line endings in your working directory and the repository has LF line endings. This variable can be set to input, in which case no output conversion is performed. 这个变量设置为true 等同于在所有文件上设置text attribute 为auto 并且把core.eol 设置为crlf。设成true ， 如果你的工作空间用的是CRLF 作为行结束符，同时仓库用的是LF 行结束符。这个变量也可以设置成input，这样在输出时就不做转换了。 对上面说的core.eol 又不明白了，继续查看： core.eolSets the line ending type to use in the working directory for files that have the text property set when core.autocrlf is false. Alternatives are lf, crlf and native, which uses the platform’s native line ending. The default value is native. See gitattributes[5] for more information on end-of-line conversion. 这个变量是用来设置行结束符的，在core.autocrlf 是false的时候。可以设置成lf，crlf和native ， native是说使用当前平台自己的行结束符。 到这里，大体就明白了，还留有一个问题，就是attribute的问题，留在下一次来研究。]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>diff</tag>
        <tag>windows</tag>
        <tag>^M</tag>
        <tag>符号</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[区块链：Base64编码和Base58编码]]></title>
    <url>%2Fblockchain%2Fbase64-base58.html</url>
    <content type="text"><![CDATA[区块链：Base64编码和Base58编码。 前言接触base64有很久了，其实一直没有理解base64这种编码的根本原理，或者说是设计意图，今天又读了一遍，终于开窍了，请看下图。 Base64 table 原始值 显示值 原始值 显示值 原始值 显示值 原始值 显示值 0 A 16 Q 32 g 48 w 1 B 17 R 33 h 49 x 2 C 18 S 34 i 50 y 3 D 19 T 35 j 51 z 4 E 20 U 36 k 52 0 5 F 21 V 37 l 53 1 6 G 22 W 38 m 54 2 7 H 23 X 39 n 55 3 8 I 24 Y 40 o 56 4 9 J 25 Z 41 p 57 5 10 K 26 a 42 q 58 6 11 L 27 b 43 r 59 7 12 M 28 c 44 s 60 8 13 N 29 d 45 t 61 9 14 O 30 e 46 u 62 + 15 P 31 f 47 v 63 / 什么意思呢？我这样理解，在计算机里面，所有信息都是以二进制的方式承载的，即0和1，这二进制如何去表达我们想要显示（printable）的信息呢？这个时候ASCII码就出现了，以及后来的UniCode等等，它们是以字节为单位来处理，一个字节是8位，这也是计算机系统里面的一个标准处理单位。 而Base64的目的不是这个，它是要把一段信息显示成另外的一个形式，变成不可直接读，这样尤其是在邮件传输时，可以增加一点安全性。所以，它是以6位为一个单位来处理，对应上面的这个码表，来显示的。Base58是Base64的子集，它的码表元素就更少了，少了8个（ 0 , O (大写O)，I (大写i) ，l (小写L) ， + (加号) ，/ (后倒线)），现在被用于区块链领域。 6位的处理会造成有的时候，不够一个字节，后面需要多补一个到两个字节的0来补齐长度，统一用=显示。 以下这个例子取自维基百科，一个表用MD不好展示，分成了两个表： Source text (ASCII) M a Source octets 77 (0x4d) 97 (0x61) Bit pattern 0 1 0 0 1 1 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 Source text (ASCII) M a Bit pattern 0 1 0 0 1 1 0 1 0 1 1 0 0 0 0 1 0 0 0 0 0 0 0 0 Index 19 22 4 (padding) Base64-encoded T W E = Encoded octets 84 (0x54) 87 (0x57) 69 (0x45) 61 (0x3D) 这样MA就变成了TWE=，这样就清楚了。]]></content>
      <categories>
        <category>Blockchain</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>Base48</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下shell命令用法及常见用例：which]]></title>
    <url>%2Flinux%2Fshell-command-which.html</url>
    <content type="text"><![CDATA[which命令用于查找并显示给定命令的绝对路径，环境变量$PATH中保存了查找命令时需要遍历的目录。which指令会在环境变量$PATH设置的目录里查找符合条件的文件。也就是说，使用which命令，就可以看到某个系统命令是否存在，以及执行的到底是哪一个位置的命令。 备注今天有点累，也已经很晚了，总结一个较为简单的命令吧，20英里法则，每天尽量坚持往前走一点。 命令功能which命令是查找某个命令的完整路径。它是用来在当前登录用户的$PATH环境变量记录的路径中查找可执行文件（即二进制文件）的路径。默认情况下，只返回第一个搜索结果。 1234WHICH(1) General Commands Manual WHICH(1)NAME which - shows the full path of (shell) commands. 命令格式which [选项] 命令 实例实例：查看ls命令的位置 123[root@iZwz90drrwkerfi7bc8mqiZ ~]# which lsalias ls=&apos;ls --color=auto&apos; /usr/bin/ls 第一行输出暂时没有搞明白是哪里来的，第二行就是ls命令的位置了。]]></content>
      <categories>
        <category>Linux</category>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git：修改远程仓库地址]]></title>
    <url>%2Fgit%2Fgit-remote-set-url.html</url>
    <content type="text"><![CDATA[Git：修改远程仓库地址。 前言有的时候，我们会遇到Git远程仓库IP发生改变，这样的改变可能是： 远程服务器挂了：远程服务器上的Git仓库被一个爱折腾的同事给删掉了，这个时候把他骂死也没用了，这要是SVN就没办法了，还好是Git，可以从本机的仓库去恢复这个远程仓库。 远程服务器迁移了，IP变了。这个时候就要用到这个命令了。 命令1git-remote - Manage set of tracked repositories（管理被追踪的仓库集合） 概要123git remote set-url [--push] &lt;name&gt; &lt;newurl&gt; [&lt;oldurl&gt;]git remote set-url --add [--push] &lt;name&gt; &lt;newurl&gt;git remote set-url --delete [--push] &lt;name&gt; &lt;url&gt; 修改远程仓库的url只是这个命令的一个功能。 记得很久以前（刚毕业的时候）从一本书中看到，中括号表示是可选项，尖括号表示为必选项，现在找不到了，上网查了查，可以参考这里。关于这个问题，接触过的很多同事都是糊里糊涂的，我觉得这样总是不好，搞计算机，应该严谨一些，做事情，还是应该寻根究底。 所以，要修改远程仓库，只需要进入代码目录： 12345678git remote -v# 查看当前的远程仓库git remote set-url origin https://where you want to put your repository to.git# 修改为想要设置的远程仓库git remote -v#验证一下 大功告成，亲个嘴（韦小宝语）。 参考https://git-scm.com/docs/git-remote。]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>修改</tag>
        <tag>远程仓库地址</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git：git-revert的用法总结]]></title>
    <url>%2Fgit%2Fgit-revert.html</url>
    <content type="text"><![CDATA[Git：git-revert的用法总结。 介绍1git-revert - Revert some existing commits // 撤销一些已经存在的提交 语法1234git revert [--[no-]edit] [-n] [-m parent-number] [-s] [-S[&lt;keyid&gt;]] &lt;commit&gt;…​git revert --continuegit revert --quitgit revert --abort 理解 Given one or more existing commits, revert the changes that the related patches introduce, and record some new commits that record them. This requires your working tree to be clean (no modifications from the HEAD commit).Note: git revert is used to record some new commits to reverse the effect of some earlier commits (often only a faulty one). If you want to throw away all uncommitted changes in your working directory, you should see git-reset[1], particularly the –hard option. If you want to extract specific files as they were in another commit, you should see git-checkout[1], specifically the git checkout – syntax. Take care with these alternatives as both will discard uncommitted changes in your working directory. 这个工具的使用场景有一点复杂，所以把原本的介绍贴在这里，下面附上翻译：给定一个或多个现有提交，还原由这些提交引入的更改，并用新的提交去记录。 这需要您的工作树是干净的（没有对于HEAD的修改）。注意：git revert用于记录一些新的提交以还原某些早期提交的效果（通常是一个错误的提交）。 如果你想丢弃工作目录中所有未提交的更改，你应该看到git-reset [1]，特别是–hard选项。 如果你想在另一个提交中提取特定文件，你应该看到git-checkout [1]，特别是git checkout &lt;commit&gt; - &lt;filename&gt;语法。 请注意这些替代方案，因为它们都会丢弃工作目录中未提交的更改。 意思是，如果你想撤销之前的一个或几个提交带来的修改，那么使用这个工具；如果想放弃工作目录的修改（并没有提交），那么你应该使用git reset；或者你只是想检出一个文件的某一个版本，那么使用git checkout。 实例摘录了官网的两个例子：实例： 撤销HEAD指针之前的第3个提交，并且生成一个新的提交。 1git revert HEAD~3 Revert the changes specified by the fourth last commit in HEAD and create a new commit with the reverted changes. 实例： 撤销从master之前第5个提交到之前第3个提交的变化（这么看来，前面是开区间，第6个没有被包含；后面是闭区间，包含了第3个）。 1git revert -n master~5..master~2 Revert the changes done by commits from the fifth last commit in master (included) to the third last commit in master (included), but do not create any commit with the reverted changes. The revert only modifies the working tree and the index. 实例： 撤销某个提交带来的修改1git revert &lt;commit&gt;]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>用法</tag>
        <tag>git revert</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[区块链：教程 | 以太坊智能合约编程之菜鸟教程]]></title>
    <url>%2Fblockchain%2Fblock-chain-ethereum-contract-program.html</url>
    <content type="text"><![CDATA[区块链：教程 | 以太坊智能合约编程之菜鸟教程。 这篇介绍以太坊合约的文章写得很好，在查找了这么多资料，进行对比之后，感觉阅读这一篇就可以大体理解以太坊编程的原理，如果对个别的知识点还有点含糊，可以相应地去查一查，就是以这篇为主干，别的资料为辅。稍微整理了一下格式，以及修改了一些半角符号。 译注：原文首发于ConsenSys开发者博客，原作者为Eva以及ConsenSys的开发团队。如果您想要获取更多及时信息，可以访问ConsenSys首页点击左下角Newsletter订阅邮件。本文的翻译获得了ConsenSys创始人Lubin先生的授权。 有些人说以太坊太难对付，于是我们(译注：指Consensys, 下同)写了这篇文章来帮助大家学习如何利用以太坊编写智能合约和应用。这里所用到的工具，钱包，应用程序以及整个生态系统仍处于开发状态，它们将来会更好用！ 第一部分概述，讨论了关键概念，几大以太坊客户端以及写智能合约用到的编程语言。 第二部分讨论了总体的工作流程，以及目前流行的一些DApp框架和工具。 第三部分主要关于编程，我们将学习如何使用Truffle来为智能合约编写测试和构建DApp。 第一部分 概述如果你对诸如比特币以及其工作原理等密码学货币的概念完全陌生，我们建议你先看看Andreas Antonopoulos所著的Bitcoin Book的头几章，然后读一下以太坊白皮书。(译注：以太坊白皮书中文版请看 http://ethfans.org/posts/ethereum-whitepaper) 如果你觉得白皮书中的章节太晦涩，也可以直接动手来熟悉以太坊。在以太坊上做开发并不要求你理解所有那些“密码经济计算机科学”(crypto economic computer science)，而白皮书的大部分是关于以太坊想对于比特币架构上的改进。 新手教程ethereum.org提供了官方的新手入门教程，以及一个代币合约和众筹合约的教程。合约语言Solidity也有官方文档。学习智能合约的另一份不错的资料（也是我的入门资料）是dappsForBeginners，不过现在可能有些过时了。 这篇文章的目的是成为上述资料的补充，同时介绍一些基本的开发者工具，使入门以太坊，智能合约以及构建DApps(decentralized apps, 分布式应用)更加容易。我会试图按照我自己(依然是新手)的理解来解释工作流程中的每一步是在做什么，我也得到了ConsenSys酷酷的开发者们的许多帮助。 基本概念了解这些名词是一个不错的开始： 公钥加密系统。 Alice有一把公钥和一把私钥。她可以用她的私钥创建数字签名，而Bob可以用她的公钥来验证这个签名确实是用Alice的私钥创建的，也就是说，确实是Alice的签名。当你创建一个以太坊或者比特币钱包的时候，那长长的0xdf...5f地址实质上是个公钥，对应的私钥保存某处。类似于Coinbase的在线钱包可以帮你保管私钥，你也可以自己保管。如果你弄丢了存有资金的钱包的私钥，你就等于永远失去了那笔资金，因此你最好对私钥做好备份。过来人表示：通过踩坑学习到这一点是非常痛苦的… 点对点网络。 就像BitTorrent, 以太坊分布式网络中的所有节点都地位平等，没有中心服务器。(未来会有半中心化的混合型服务出现为用户和开发者提供方便，这我们后面会讲到。) 区块链。 区块链就像是一个全球唯一的帐簿，或者说是数据库，记录了网络中所有交易历史。 以太坊虚拟机(EVM)。 它让你能在以太坊上写出更强大的程序（比特币上也可以写脚本程序）。它有时也用来指以太坊区块链，负责执行智能合约以及一切。 节点。 你可以运行节点，通过它读写以太坊区块链，也即使用以太坊虚拟机。完全节点需要下载整个区块链。轻节点仍在开发中。 矿工。 挖矿，也就是处理区块链上的区块的节点。这个网页可以看到当前活跃的一部分以太坊矿工：stats.ethdev.com。 工作量证明。 矿工们总是在竞争解决一些数学问题。第一个解出答案的(算出下一个区块)将获得以太币作为奖励。然后所有节点都更新自己的区块链。所有想要算出下一个区块的矿工都有与其他节点保持同步，并且维护同一个区块链的动力，因此整个网络总是能达成共识。(注意：以太坊正计划转向没有矿工的权益证明系统(POS)，不过那不在本文讨论范围之内。) 以太币。 缩写ETH。一种你可以购买和使用的真正的数字货币。这里是可以交易以太币的其中一家交易所的走势图。在写这篇文章的时候，1个以太币价值65美分。 Gas。(汽油) 在以太坊上执行程序以及保存数据都要消耗一定量的以太币，Gas是以太币转换而成。这个机制用来保证效率。 DApp。 以太坊社区把基于智能合约的应用称为去中心化的应用程序(Decentralized App)。DApp的目标是(或者应该是)让你的智能合约有一个友好的界面，外加一些额外的东西，例如IPFS（可以存储和读取数据的去中心化网络，不是出自以太坊团队但有类似的精神)。DApp可以跑在一台能与以太坊节点交互的中心化服务器上，也可以跑在任意一个以太坊平等节点上。(花一分钟思考一下：与一般的网站不同，DApp不能跑在普通的服务器上。他们需要提交交易到区块链并且从区块链而不是中心化数据库读取重要数据。相对于典型的用户登录系统，用户有可能被表示成一个钱包地址而其它用户数据保存在本地。许多事情都会与目前的web应用有不同架构。) 如果想看看从另一个新手视角怎么理解这些概念，请读Just Enough Bitcoin for Ethereum。 以太坊客户端，智能合约语言编写和部署智能合约并不要求你运行一个以太坊节点。下面有列出基于浏览器的IDE和API。但如果是为了学习的话，还是应该运行一个以太坊节点，以便理解其中的基本组件，何况运行节点也不难。 运行以太坊节点可用的客户端以太坊有许多不同语言的客户端实现（即多种与以太坊网络交互的方法），包括C++, Go, Python, Java, Haskell等等。为什么需要这么多实现？不同的实现能满足不同的需求（例如Haskell实现的目标是可以被数学验证），能使以太坊更加安全，能丰富整个生态系统。 在写作本文时，我使用的是Go语言实现的客户端geth (go-ethereum)，其他时候还会使用一个叫testrpc的工具, 它使用了Python客户端pyethereum。后面的例子会用到这些工具。 注: 我曾经使用过C++的客户端，现在仍然在用其中的ethminer组件和geth配合挖矿，因此这些不同的组件是可以一起工作的。关于挖矿：挖矿很有趣，有点像精心照料你的室内盆栽，同时又是一种了解整个系统的方法。虽然以太币现在的价格可能连电费都补不齐，但以后谁知道呢。人们正在创造许多酷酷的DApp, 可能会让以太坊越来越流行。 交互式控制台。 客户端运行起来后，你就可以同步区块链，建立钱包，收发以太币了。使用geth的一种方式是通过Javascript控制台（JavaScript console, 类似你在chrome浏览器里面按F12出来的那个，只不过是跑在终端里）。此外还可以使用类似cURL的命令通过JSON RPC来与客户端交互。本文的目标是带大家过一边DApp开发的流程，因此这块就不多说了。但是我们应该记住这些命令行工具是调试，配置节点，以及使用钱包的利器。 在测试网络运行节点。 如果你在正式网络运行geth客户端，下载整个区块链与网络同步会需要相当时间。（你可以通过比较节点日志中打印的最后一个块号和stats.ethdev.com上列出的最新块来确定是否已经同步。) 另一个问题是在正式网络上跑智能合约需要实实在在的以太币。在测试网络上运行节点的话就没有这个问题。此时也不需要同步整个区块链，创建一个自己的私有链就勾了，对于开发来说更省时间。 testrpc。 用geth可以创建一个测试网络，另一种更快的创建测试网络的方法是使用testrpc。Testrpc可以在启动时帮你创建一堆存有资金的测试账户。它的运行速度也更快因此更适合开发和测试。你可以从testrpc起步，然后随着合约慢慢成型，转移到geth创建的测试网络上 - 启动方法很简单，只需要指定一个networkid：geth --networkid &quot;12345&quot;。这里是testrpc的代码仓库，下文我们还会再讲到它。 接下来我们来谈谈可用的编程语言，之后就可以开始真正的编程了。 写智能合约用的编程语言用Solidity就好。 要写智能合约有好几种语言可选：有点类似Javascript的Solidity, 文件扩展名是.sol和Python接近的Serpent, 文件名以.se结尾。还有类似Lisp的LLL。Serpent曾经流行过一段时间，但现在最流行而且最稳定的要算是Solidity了，因此用Solidity就好。听说你喜欢Python? 用Solidity。 solc编译器。 用Solidity写好智能合约之后，需要用solc来编译。它是一个来自C++客户端实现的组件（又一次，不同的实现产生互补），这里是安装方法。如果你不想安装solc也可以直接使用基于浏览器的编译器，例如Solidity real-time compiler或者Cosmo。后文有关编程的部分会假设你安装了solc。 注意：以太坊正处于积极的开发中，有时候新的版本之间会有不同步。确认你使用的是最新的dev版本，或者稳定版本。如果遇到问题可以去以太坊项目对应的Gitter聊天室或者forums.ethereum.org上问问其他人在用什么版本。 web3.js API。 当Solidity合约编译好并且发送到网络上之后，你可以使用以太坊的web3.js JavaScript API来调用它，构建能与之交互的web应用。 以上就是在以太坊上编写智能合约和构建与之交互的DApp所需的基本工具。 第二部分 DApp框架，工具以及工作流程DApp开发框架虽然有上文提到的工具就可以进行开发了，但是使用社区大神们创造的框架会让开发更容易。 Truffle and Embark。 是Truffle把我领进了门。在Truffle出现之前的那个夏天，我目睹了一帮有天分的学生是如何不眠不休的参加一个hackathon（编程马拉松）活动的，虽然结果相当不错，但我还是吓到了。然后Truffle出现了，帮你处理掉大量无关紧要的小事情，让你可以迅速进入写代码-编译-部署-测试-打包DApp这个流程。另外一个相似的DApp构建与测试框架是Embark。我只用过Truffle, 但是两个阵营都拥有不少DApp大神。 Meteor。 许多DApp开发者使用的另一套开发栈由web3.js和Meteor组成，Meteor是一套通用webapp开发框架（ethereum-meteor-wallet项目提供了一个很棒的入门实例，而SilentCiero正在构建大量Meteor与web3.js和DApp集成的模板）。我下载并运行过一些不错的DApp是以这种方式构造的。在11月9日至13日的以太坊开发者大会ÐΞVCON1上将有一些有趣的讨论，是关于使用这些工具构建DApp以及相关最佳实践的（会议将会在YouTube上直播）。 APIs。 BlockApps.net打算提供一套RESTful API给DApp使用以免去开发者运行本地节点的麻烦，这个中心化服务是基于以太坊Haskell实现的。这与DApp的去中心化模型背道而驰，但是在本地无法运行以太坊节点的场合非常有用，比如在你希望只有浏览器或者使用移动设备的用户也能使用你的DApp的时候。BlockApps提供了一个命令行工具bloc，注册一个开发者帐号之后就可以使用。 许多人担心需要运行以太坊节点才能使用DApp的话会把用户吓跑，其实包括BlockApps在内的许多工具都能解决这个问题。Metamask允许你在浏览器里面使用以太坊的功能而无需节点，以太坊官方提供的AlethZero或者AlethOne是正在开发中有易用界面的客户端，ConsenSys正在打造一个轻钱包LightWallet，这些工具都会让DApp的使用变得更容易。轻客户端和水平分片(sharding)也在计划和开发之中。这是一个能进化出混合架构的P2P生态系统。 智能合约集成开发环境 (IDE)IDE。 以太坊官方出品了用来编写智能合约的Mix IDE，我还没用过但会尽快一试。 基于浏览器的IDE。 Solidity real-time compiler和Cosmo都可以让你快速开始在浏览器中编写智能合约。你甚至可以让这些工具使用你的本地节点，只要让本地节点开一个端口（注意安全！这些工具站点必须可信，而且千万不要把你的全部身家放在这样一个本地节点里面！Cosmo UI上有如何使用geth做到这一点的指引）。在你的智能合约调试通过之后，可以用开发框架来给它添加用户界面和打包成DApp，这正是Truffle的工作，后面的编程章节会有详细讲解。 Ether.Camp正在开发另一个强大的企业级浏览器IDE。他们的IDE将支持沙盒测试网络，自动生成用于测试的用户界面（取代后文将展示的手动编写测试），以及一个测试交易浏览器test.ether.camp。当你的合约准备正式上线之前，使用他们的测试网络会是确保你的智能合约在一个接近真实的环境工作正常的好方法。他们也为正式网络提供了一个交易浏览器frontier.ether.camp，上面可以看到每一笔交易的细节。在本文写作时Ether.Camp的IDE还只能通过邀请注册，预计很快会正式发布。 合约和Dapp示例。 在Github上搜索DApp仓库和.sol文件可以看到进行中的有趣东西。这里有一个DApp大列表：dapps.ethercasts.com，不过其中一些项目已经过时。Ether.fund/contracts上有一些Solidity和Serpent写的合约示例，但是不清楚这些例子有没有经过测试或者正确性验证。11月12日的开发者大会ÐΞVCON1将会有一整天的DApp主题演讲。 部署智能合约的流程流程如下： 启动一个以太坊节点 (例如geth或者testrpc)。 使用solc_编译_智能合约。 =&gt; 获得二进制代码。 将编译好的合约部署到网络。（这一步会消耗以太币，还需要使用你的节点的默认地址或者指定地址来给合约签名。） =&gt; 获得合约的区块链地址和ABI（合约接口的JSON表示，包括变量，事件和可以调用的方法）。(译注：作者在这里把ABI与合约接口弄混了。ABI是合约接口的二进制表示。) 用web3.js提供的JavaScript API来调用合约。（根据调用的类型有可能会消耗以太币。） 下图详细描绘了这个流程： 你的DApp可以给用户提供一个界面先部署所需合约再使用之（如图1到4步），也可以假设合约已经部署了（常见方法），直接从使用合约（如图第6步）的界面开始。 第三部分 编程在Truffle中进行测试Truffle用来做智能合约的测试驱动开发(TDD)非常棒，我强烈推荐你在学习中使用它。它也是学习使用JavaScript Promise的一个好途径，例如deferred和异步调用。Promise机制有点像是说“做这件事，如果结果是这样，做甲，如果结果是那样，做乙… 与此同时不要在那儿干等着结果返回，行不？”。Truffle使用了包装web3.js的一个JS Promise框架Pudding（因此它为为你安装web3.js）。(译注：Promise是流行于JavaScript社区中的一种异步调用模式。它很好的封装了异步调用，使其能够灵活组合，而不会陷入callback hell.) Transaction times。 Promise对于DApp非常有用，因为交易写入以太坊区块链需要大约12-15秒的时间。即使在测试网络上看起来没有那么慢，在正式网络上却可能会要更长的时间（例如你的交易可能用光了Gas，或者被写入了一个孤儿块）。 下面让我们给一个简单的智能合约写测试用例吧。 使用Truffle首先确保你 1.安装好了solc以及 2.testrpc。（testrpc需要Python和pip。如果你是Python新手，你可能需要用virtualenv来安装，这可以将Python程序库安装在一个独立的环境中。） 接下来安装 3.Truffle（你可以使用NodeJS’s npm来安装：npm install -g truffle, -g开关可能会需要sudo）。安装好之后，在命令行中输入truffle list来验证安装成功。然后创建一个新的项目目录（我把它命名为’conference’），进入这个目录，运行truffle init。该命令会建立如下的目录结构： 现在让我们在另一个终端里通过执行testrpc来启动一个节点（你也可以用geth）： 回到之前的终端中，输入truffle deploy。这条命令会部署之前truffle init产生的模板合约到网络上。任何你可能遇到的错误信息都会在testrpc的终端或者执行truffle的终端中输出。 在开发过程中你随时可以使用truffle compile命令来确认你的合约可以正常编译（或者使用solc YourContract.sol），truffle deploy来编译和部署合约，最后是truffle test来运行智能合约的测试用例。 第一个合约下面是一个针对会议的智能合约，通过它参会者可以买票，组织者可以设置参会人数上限，以及退款策略。本文涉及的所有代码都可以在这个代码仓库找到。 contract Conference { address public organizer; mapping (address =&gt; uint) public registrantsPaid; uint public numRegistrants; uint public quota; event Deposit(address _from, uint _amount); // so you can log these events event Refund(address _to, uint _amount); function Conference() { // Constructor organizer = msg.sender; quota = 500; numRegistrants = 0; } function buyTicket() public returns (bool success) { if (numRegistrants &gt;= quota) { return false; } registrantsPaid[msg.sender] = msg.value; numRegistrants++; Deposit(msg.sender, msg.value); return true; } function changeQuota(uint newquota) public { if (msg.sender != organizer) { return; } quota = newquota; } function refundTicket(address recipient, uint amount) public { if (msg.sender != organizer) { return; } if (registrantsPaid[recipient] == amount) { address myAddress = this; if (myAddress.balance &gt;= amount) { recipient.send(amount); registrantsPaid[recipient] = 0; numRegistrants--; Refund(recipient, amount); } } } function destroy() { // so funds not locked in contract forever if (msg.sender == organizer) { suicide(organizer); // send funds to organizer } } } 接下来让我们部署这个合约。（注意：本文写作时我使用的是Mac OS X 10.10.5, solc 0.1.3+ (通过brew安装)，Truffle v0.2.3, testrpc v0.1.18 (使用venv)） 部署合约 (译注：图中步骤翻译如下：） 使用truffle部署智能合约的步骤：1. truffle init (在新目录中) =&gt; 创建truffle项目目录结构2. 编写合约代码，保存到contracts/YourContractName.sol文件。3. 把合约名字加到config/app.json的’contracts’部分。4. 启动以太坊节点（例如在另一个终端里面运行testrpc）。5. truffle deploy（在truffle项目目录中) 添加一个智能合约。 在truffle init执行后或是一个现有的项目目录中，复制粘帖上面的会议合约到contracts/Conference.sol文件中。然后打开config/app.json文件，把’Conference’加入’deploy’数组中。 启动testrpc。 在另一个终端中启动testrpc。 编译或部署。 执行truffle compile看一下合约是否能成功编译，或者直接truffle deploy一步完成编译和部署。这条命令会把部署好的合约的地址和ABI（应用接口）加入到配置文件中，这样之后的truffle test和truffle build步骤可以使用这些信息。 出错了？ 编译是否成功了？记住，错误信息即可能出现在testrpc终端也可能出现在truffle终端。 重启节点后记得重新部署！ 如果你停止了testrpc节点，下一次使用任何合约之前切记使用truffle deploy重新部署。testrpc在每一次重启之后都会回到完全空白的状态。 合约代码解读让我们从智能合约头部的变量声明开始： address public organizer; mapping (address =&gt; uint) public registrantsPaid; uint public numRegistrants; uint public quota; address。 地址类型。第一个变量是会议组织者的钱包地址。这个地址会在合约的构造函数function Conference()中被赋值。很多时候也称呼这种地址为’owner’（所有人）。 uint。 无符号整型。区块链上的存储空间很紧张，保持数据尽可能的小。 public。 这个关键字表明变量可以被合约之外的对象使用。private修饰符则表示变量只能被本合约(或者衍生合约)内的对象使用。如果你想要在测试中通过web3.js使用合约中的某个变量，记得把它声明为public。 Mapping或数组。（译注：Mapping类似Hash, Directory等数据类型，不做翻译。）在Solidity加入数组类型之前，大家都使用类似mapping (address =&gt; uint)的Mapping类型。这个声明也可以写作address registrantsPaid[]，不过Mapping的存储占用更小(smaller footprint)。这个Mapping变量会用来保存参加者（用他们的钱包地址表示）的付款数量以便在退款时使用。 关于地址。 你的客户端（比如testrpc或者geth）可以生成一个或多个账户/地址。testrpc启动时会显示10个可用地址： 第一个地址, accounts[0]，是发起调用的默认地址，如果没有特别指定的话。 组织者地址 vs 合约地址。 部署好的合约会在区块链上拥有自己的地址（与组织者拥有的是不同的地址）。在Solidity合约中可以使用this来访问这个合约地址，正如refundTicket函数所展示的：address myAddress = this; Suicide, Solidity的好东西。（译注：suicide意为’自杀’, 为Solidity提供的关键字，不做翻译。）转给合约的资金会保存于合约（地址）中。最终这些资金通过destroy函数被释放给了构造函数中设置的组织者地址。这是通过suicide(orgnizer);这行代码实现的。没有这个，资金可能被永远锁定在合约之中（reddit上有些人就遇到过），因此如果你的合约会接受资金一定要记得在合约中使用这个方法！ 如果想要模拟另一个用户或者对手方（例如你是卖家想要模拟一个买家），你可以使用可用地址数组中另外的地址。假设你要以另一个用户，accounts[1], 的身份来买票，可以通过from参数设置： conference.buyTicket({ from: accounts[1], value: some_ticket_price_integer }); 函数调用可以是交易。 改变合约状态（修改变量值，添加记录，等等）的函数调用本身也是转账交易，隐式的包含了发送人和交易价值。因此web3.js的函数调用可以通过指定{ from: __, value: __ }参数来发送以太币。在Solidity合约中，你可以通过msg.sender和msg.value来获取这些信息： function buyTicket() public { ... registrantsPaid[msg.sender] = msg.value; ... } 事件(Event)。 可选的功能。合约中的Deposit（充值）和Send（发送）事件是会被记录在以太坊虚拟机日志中的数据。它们实际上没有任何作用，但是用事件(Event)把交易记录进日志是好的做法。 好了，现在让我们给这个智能合约写一个测试，来确保它能工作。 写测试把项目目录test/中的example.js文件重命名为conference.js，文件中所有的’Example’替换为’Conference’。 contract(&apos;Conference&apos;, function(accounts) { it(&quot;should assert true&quot;, function(done) { var conference = Conference.at(Conference.deployed_address); assert.isTrue(true); done(); // stops tests at this point }); }); 在项目根目录下运行truffle test，你应该看到测试通过。在上面的测试中truffle通过Conference.deployed_address获得合约部署在区块链上的地址。 让我们写一个测试来初始化一个新的Conference，然后检查变量都正确赋值了。将conference.js中的测试代码替换为： contract(&apos;Conference&apos;, function(accounts) { it(&quot;Initial conference settings should match&quot;, function(done) { var conference = Conference.at(Conference.deployed_address); // same as previous example up to here Conference.new({ from: accounts[0] }) .then(function(conference) { conference.quota.call().then( function(quota) { assert.equal(quota, 500, &quot;Quota doesn&apos;t match!&quot;); }).then( function() { return conference.numRegistrants.call(); }).then( function(num) { assert.equal(num, 0, &quot;Registrants should be zero!&quot;); return conference.organizer.call(); }).then( function(organizer) { assert.equal(organizer, accounts[0], &quot;Owner doesn&apos;t match!&quot;); done(); // to stop these tests earlier, move this up }).catch(done); }).catch(done); }); }); 构造函数。 Conference.new({ from: accounts[0] })通过调用合约构造函数创造了一个新的Conference实例。由于不指定from时会默认使用accounts[0]，它其实可以被省略掉： Conference.new({ from: accounts[0] }); // 和Conference.new()效果相同 Promise。 代码中的那些then和return就是Promise。它们的作用写成一个深深的嵌套调用链的话会是这样： conference.numRegistrants.call().then( function(num) { assert.equal(num, 0, &quot;Registrants should be zero!&quot;); conference.organizer.call().then( function(organizer) { assert.equal(organizer, accounts[0], &quot;Owner doesn&apos;t match!&quot;); }).then( function(...)) }).then( function(...)) // Because this would get hairy... Promise减少嵌套，使代码变得扁平，允许调用异步返回，并且简化了表达“成功时做这个”和“失败时做那个”的语法。Web3.js通过回调函数实现异步调用，因此你不需要等到交易完成就可以继续执行前端代码。Truffle借助了用Promise封装web3.js的一个框架，叫做Pudding，这个框架本身又是基于Bluebird的，它支持Promise的高级特性。 call。 我们使用call来检查变量的值，例如conference.quota.call().then(...，还可以通过传参数，例如call(0), 来获取mapping在index 0处的元素。Solidity的文档说这是一种特殊的“消息调用”因为 1.不会为矿工记录和 2.不需要从钱包账户/地址发起（因此它没有被账户持有者私钥做签名）。另一方面，交易/事务(Transaction)会被矿工记录，必须来自于一个账户（也就是有签名），会被记录到区块链上。对合约中数据做的任何修改都是交易。仅仅是检查一个变量的值则不是。因此在读取变量时不要忘记加上call()！否则会发生奇怪的事情。（此外如果在读取变量是遇到问题别忘记检查它是否是public。）call()也能用于调用不是交易的函数。如果一个函数本来是交易，但你却用call()来调用，则不会在区块链上产生交易。 断言。 标准JS测试中的断言（如果你不小心拼成了复数形式’asserts’，truffle会报错，让你一头雾水），assert.equal是最常用的，其他类型的断言可以在Chai的文档中找到。 再一次运行truffle test确保一切工作正常。 测试合约函数调用现在我们测试一下改变quote变量的函数能工作。在tests/conference.js文件的contract(&#39;Conference&#39;, function(accounts) {...};)的函数体中添加如下测试用例： it(&quot;Should update quota&quot;, function(done) { var c = Conference.at(Conference.deployed_address); Conference.new({from: accounts[0] }).then( function(conference) { conference.quota.call().then( function(quota) { assert.equal(quota, 500, &quot;Quota doesn&apos;t match!&quot;); }).then( function() { return conference.changeQuota(300); }).then( function(result) { // result here is a transaction hash console.log(result); // if you were to print this out it’d be long hex - the transaction hash return conference.quota.call() }).then( function(quota) { assert.equal(quota, 300, &quot;New quota is not correct!&quot;); done(); }).catch(done); }).catch(done); }); 这里的新东西是调用changeQuota函数的那一行。console.log对于调试很有用，用它能在运行truffle的终端中输出信息。在关键点插入console.log可以查看执行到了哪一步。记得把Solidity合约中changeQuota函数被声明为public，否则你不能调用它： function changeQuota(uint newquota) public { } 测试交易现在让我们调用一个需要发起人发送资金的函数。 Wei。 以太币有很多种单位（这里有个很有用的转换器）,在合约中通常用的是Wei，最小的单位。Web3.js提供了在各单位与Wei之间互相转换的便利方法，形如web3.toWei(.05, &#39;ether&#39;)。JavaScript在处理很大的数字时有问题，因此web3.js使用了程序库BigNumber，并建议在代码各处都以Wei做单位，直到要给用户看的时候（文档。 账户余额。 Web3.js提供了许多提供方便的方法，其中另一个会在下面测试用到的是web3.eth.getBalance(some_address)。记住发送给合约的资金会由合约自己持有直到调用suicide。 在contract(Conference, function(accounts) {...};)的函数体中插入下面的测试用例。在高亮显示的方法中，测试用例让另一个用户(accounts[1])以ticketPrice的价格买了一张门票。然后它检查合约的账户余额增加了ticketPrice，以及购票用户被加入了参会者列表。 这个测试中的buyTicket是一个交易函数： it(&quot;Should let you buy a ticket&quot;, function(done) { var c = Conference.at(Conference.deployed_address); Conference.new({ from: accounts[0] }).then( function(conference) { var ticketPrice = web3.toWei(.05, &apos;ether&apos;); var initialBalance = web3.eth.getBalance(conference.address).toNumber(); conference.buyTicket({ from: accounts[1], value: ticketPrice }).then( function() { var newBalance = web3.eth.getBalance(conference.address).toNumber(); var difference = newBalance - initialBalance; assert.equal(difference, ticketPrice, &quot;Difference should be what was sent&quot;); return conference.numRegistrants.call(); }).then(function(num) { assert.equal(num, 1, &quot;there should be 1 registrant&quot;); return conference.registrantsPaid.call(accounts[1]); }).then(function(amount) { assert.equal(amount.toNumber(), ticketPrice, &quot;Sender&apos;s paid but is not listed&quot;); done(); }).catch(done); }).catch(done); }); 交易需要签名。 和之前的函数调用不同，这个调用是一个会发送资金的交易，在这种情况下购票用户(accounts[1])会用他的私钥对buyTicket()调用做签名。（在geth中用户需要在发送资金之前通过输入密码来批准这个交易或是解锁钱包的账户。） toNumber()。 有时我们需要把Solidity返回的十六进制结果转码。如果结果可能是个很大的数字可以用web3.toBigNumber(numberOrHexString)来处理因为JavaScript直接对付大数要糟。 测试包含转账的合约最后，为了完整性，我们确认一下refundTicket方法能正常工作，而且只有会议组织者能调用。下面是测试用例： it(&quot;Should issue a refund by owner only&quot;, function(done) { var c = Conference.at(Conference.deployed_address); Conference.new({ from: accounts[0] }).then( function(conference) { var ticketPrice = web3.toWei(.05, &apos;ether&apos;); var initialBalance = web3.eth.getBalance(conference.address).toNumber(); conference.buyTicket({ from: accounts[1], value: ticketPrice }).then( function() { var newBalance = web3.eth.getBalance(conference.address).toNumber(); var difference = newBalance - initialBalance; assert.equal(difference, ticketPrice, &quot;Difference should be what was sent&quot;); // same as before up to here // Now try to issue refund as second user - should fail return conference.refundTicket(accounts[1], ticketPrice, {from: accounts[1]}); }).then( function() { var balance = web3.eth.getBalance(conference.address).toNumber(); assert.equal(web3.toBigNumber(balance), ticketPrice, &quot;Balance should be unchanged&quot;); // Now try to issue refund as organizer/owner - should work return conference.refundTicket(accounts[1], ticketPrice, {from: accounts[0]}); }).then( function() { var postRefundBalance = web3.eth.getBalance(conference.address).toNumber(); assert.equal(postRefundBalance, initialBalance, &quot;Balance should be initial balance&quot;); done(); }).catch(done); }).catch(done); }); 这个测试用例覆盖的Solidity函数如下： function refundTicket(address recipient, uint amount) public returns (bool success) { if (msg.sender != organizer) { return false; } if (registrantsPaid[recipient] == amount) { address myAddress = this; if (myAddress.balance &gt;= amount) { recipient.send(amount); Refund(recipient, amount); registrantsPaid[recipient] = 0; numRegistrants--; return true; } } return false; } 合约中发送以太币。 address myAddress = this展示了如何获取该会议合约实例的地址，以变接下来检查这个地址的余额（或者直接使用this.balance）。合约通过recipient.send(amount)方法把资金发回了购票人。 交易无法返回结果给web3.js。 注意这一点！refundTicket函数会返回一个布尔值，但是这在测试中无法检查。因为这个方法是一个交易函数（会改变合约内数据或是发送以太币的调用），而web3.js得到的交易运行结果是一个交易哈希（如果打印出来是一个长长的十六进制/怪怪的字符串）。既然如此为什么还要让refundTicket返回一个值？因为在Solidity合约内可以读到这个返回值，例如当另一个合约调用refundTicket()的时候。也就是说Solidity合约可以读取交易运行的返回值，而web3.js不行。另一方面，在web3.js中你可以用事件机制（Event, 下文会解释）来监控交易运行，而合约不行。合约也无法通过call()来检查交易是否修改了合约内变量的值。 关于sendTransaction()。 当你通过web3.js调用类似buyTicket()或者refundTicket()的交易函数时（使用web3.eth.sendTransaction），交易并不会立即执行。事实上交易会被提交到矿工网络中，交易代码直到其中一位矿工产生一个新区块把交易记录进区块链之后才执行。因此你必须等交易进入区块链并且同步回本地节点之后才能验证交易执行的结果。用testrpc的时候可能看上去是实时的，因为测试环境很快，但是正式网络会比较慢。 事件/Event。 在web3.js中你应该监听事件而不是返回值。我们的智能合约示例定义了这些事件： event Deposit(address _from, uint _amount); event Refund(address _to, uint _amount); 它们在buyTicket()和refundTicket()中被触发。触发时你可以在testrpc的输出中看到日志。要监听事件，你可以使用web.js监听器(listener)。在写本文时我还不能在truffle测试中记录事件，但是在应用中没问题： Conference.new({ from: accounts[0] }).then( function(conference) { var event = conference.allEvents().watch({}, &apos;&apos;); // or use conference.Deposit() or .Refund() event.watch(function (error, result) { if (error) { console.log(&quot;Error: &quot; + error); } else { console.log(&quot;Event: &quot; + result.event); } }); // ... 过滤器/Filter。 监听所有事件可能会产生大量的轮询，作为替代可以使用过滤器。它们可以更灵活的开始或是停止对事件的监听。更多过滤器的信息可查看Solidity文档。 总的来说，使用事件和过滤器的组合比检查变量消耗的Gas更少，因而在验证正式网络的交易运行结果时非常有用。 Gas。 （译注：以太坊上的燃料，因为代码的执行必须消耗Gas。直译为汽油比较突兀，故保留原文做专有名词。）直到现在我们都没有涉及Gas的概念，因为在使用testrpc时通常不需要显式的设置。当你转向geth和正式网络时会需要。在交易函数调用中可以在{from: __, value: __, gas: __}对象内设置Gas参数。Web3.js提供了web3.eth.gasPrice调用来获取当前Gas的价格，Solidity编译器也提供了一个参数让你可以从命令行获取合约的Gas开销概要：solc --gas YouContract.sol。下面是Conference.sol的结果： 为合约创建DApp界面下面的段落会假设你没有网页开发经验。 上面编写的测试用例用到的都是在前端界面中也可以用的方法。你可以把前端代码放到app/目录中，运行truffle build之后它们会和合约配置信息一起编译输出到build/目录。在开发时可以使用truffle watch命令在app/有任何变动时自动编译输出到build/目录。然后在浏览器中刷新页面即可看到build/目录中的最新内容。（truffle serve可以启动一个基于build/目录的网页服务器。） app/目录中有一些样板文件帮助你开始： index.html会加载app.js： 因此我们只需要添加代码到app.js就可以了。 默认的app.js会在浏览器的console(控制台)中输出一条”Hello from Truffle!”的日志。在项目根目录中运行truffle watch，然后在浏览器中打开build/index.html文件，再打开浏览器的console就可以看到。（大部分浏览器例如Chrome中，单击右键 -&gt; 选择Inspect Element然后切换到Console即可。） 在app.js中，添加一个在页面加载时会运行的window.onload调用。下面的代码会确认web3.js已经正常载入并显示所有可用的账户。（注意：你的testrpc节点应该保持运行。） window.onload = function() { var accounts = web3.eth.accounts; console.log(accounts); } 看看你的浏览器console中看看是否打印出了一组账户地址。 现在你可以从tests/conference.js中复制一些代码过来（去掉只和测试有关的断言），将调用返回的结果输出到console中以确认代码能工作。下面是个例子： window.onload = function() { var accounts = web3.eth.accounts; var c = Conference.at(Conference.deployed_address); Conference.new({ from: accounts[0] }).then( function(conference) { var ticketPrice = web3.toWei(.05, &apos;ether&apos;); var initialBalance = web3.eth.getBalance(conference.address).toNumber(); console.log(&quot;The conference&apos;s initial balance is: &quot; + initialBalance); conference.buyTicket({ from: accounts[1], value: ticketPrice }).then( function() { var newBalance = web3.eth.getBalance(conference.address).toNumber(); console.log(&quot;After someone bought a ticket it&apos;s: &quot; + newBalance); return conference.refundTicket(accounts[1], ticketPrice, {from: accounts[0]}); }).then( function() { var balance = web3.eth.getBalance(conference.address).toNumber(); console.log(&quot;After a refund it&apos;s: &quot; + balance); }); }); }; 上面的代码应该输出如下： (console输出的warning信息可忽略。) 现在起你就可以使用你喜欢的任何前端工具，jQuery, ReactJS, Meteor, Ember, AngularJS，等等等等，在app/目录中构建可以与以太坊智能合约互动的DApp界面了！接下来我们给出一个极其简单基于jQuery的界面作为示例。 这里是index.html的代码，这里是app.js的代码。 通过界面测试了智能合约之后我意识到最好加入检查以保证相同的用户不能注册两次。另外由于现在是运行在testrpc节点上，速度很快，最好是切换到geth节点并确认交易过程依然能及时响应。否则的话界面上就应该显示提示信息并且在处理交易时禁用相关的按钮。 尝试geth。 如果你使用geth, 可以尝试以下面的命令启动 - 在我这儿(geth v1.2.3)工作的很好： build/bin/geth --rpc --rpcaddr=&quot;0.0.0.0&quot; --rpccorsdomain=&quot;*&quot; --mine --unlock=&apos;0 1&apos; --verbosity=5 --maxpeers=0 --minerthreads=&apos;4&apos; --networkid &apos;12345&apos; --genesis test-genesis.json 这条命令解锁了两个账户, 0和1。1. 在geth控制台启动后你可能需要输入这两个账户的密码。2. 你需要在test-genesis.json文件里面的’alloc’配置中加入你的这两个账户，并且给它们充足的资金。3. 最后，在创建合约实例时加上gas参数： Conference.new({from: accounts[0], gas: 3141592}) 然后把整个truffle deploy, truffle build流程重来一遍。 教程中的代码。 在这篇基础教程中用到的所有代码都可以在这个代码仓库中找到。 自动为合约生成界面。 SilentCicero制作了一个叫做DApp Builder的工具，可以用Solidity合约自动生成HTML, jQuery和web.js的代码。这种模式也正在被越来越多的正在开发中的开发者工具采用。 教程到此结束！ 最后一章我们仅仅学习了一套工具集，主要是Truffle和testrpc. 要知道即使在ConsenSys内部，不同的开发者使用的工具和框架也不尽相同。你可能会发现更适合你的工具，这里所说的工具可能很快也会有改进。但是本文介绍的工作流程帮助我走上了DApp开发之路。 (⊙ω⊙) wonk wonk 感谢Joseph Chow的校阅和建议，Christian Lundkvist, Daniel Novy, Jim Berry, Peter Borah和Tim Coulter帮我修改文字和debug，以及Tim Coulter, Nchinda Nchinda和Mike Goldin对DApp前端步骤图提供的帮助。]]></content>
      <categories>
        <category>Blockchain</category>
        <category>以太坊</category>
        <category>智能合约</category>
      </categories>
      <tags>
        <tag>区块链</tag>
        <tag>以太坊</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB的基本操作：删除记录（删）]]></title>
    <url>%2Fmongodb%2Fmongodb-collection-delete.html</url>
    <content type="text"><![CDATA[MongoDB的基本操作：删除记录（删）。 方法删除记录有两个方法： 123.2版本之前db.collection.remove() // 1233.2版本之后 - db.collection.deleteMany() //删除匹配条件的多条记录 - db.collection.deleteOne() //删除匹配条件的单条记录 括号里面的参数是查询过滤器。 查询过滤器：查询过滤器用来设定查询条件。 格式&lt;field&gt;:&lt;value&gt;。 12345&#123; &lt;field1&gt;: &lt;value1&gt;, &lt;field2&gt;: &#123; &lt;operator&gt;: &lt;value&gt; &#125;, ...&#125; 实例实例：删除前文test数据库中所有记录。 1db.test.deleteMany(&#123;&#125;); {}表示没有约束条件。 实例：删除前文test数据库中_id为5abb3b5bce69c048be080199的记录。 1db.test.deleteMany(&#123;_id: ObjectId(&quot;5abb3b5bce69c048be080199&quot;)&#125;); 笔记整理到这里，发现之前的记录有点问题，因为对MongoDB的官网的结构没有完全搞清楚，所以，之前的基本操作更多偏向于参考手册的层面，可能还需要修改和调整一下。 参考：https://docs.mongodb.com/manual/tutorial/remove-documents/。]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JS：逻辑操作符“||”、“&&”和“!”]]></title>
    <url>%2Fjs%2Fjs-logical-operator.html</url>
    <content type="text"><![CDATA[JS：逻辑操作符“||”、“&amp;&amp;”和“!”。 Operator Usage Description Logical AND (&amp;&amp;) expr1 &amp;&amp; expr2 Returns expr1 if it can be converted to false; otherwise, returns expr2. Thus, when used with Boolean values, &amp;&amp; returns true if both operands are true; otherwise, returns false. Logical OR (&#124;&#124;) expr1 &#124;&#124; expr2 Returns expr1 if it can be converted to true; otherwise, returns expr2. Thus, when used with Boolean values, &#124;&#124; returns true if either operand is true. Logical NOT (!) !expr Returns false if its single operand can be converted to true; otherwise, returns true. 翻译一下： 操作符 用法 描述 逻辑和 (&amp;&amp;) expr1 &amp;&amp; expr2 如果expr1可以被转换为false，那么返回expr1，否则，返回expr2。 如果使用的是布尔值，那么仅当两个操作数都为真时，返回true；否则，返回false。 逻辑或 (&#124;&#124;) expr1 &#124;&#124; expr2 如果expr1可以被转换为true，返回expr1；否则，返回expr2。如果是布尔值，则两个操作数中有一个位true就返回true。 逻辑非 (!) !expr 如果这个操作数可以转换为true，返回false，否则，返回true 以下这些表达式都可以转换为false： null; NaN; 0; empty string (“” or ‘’); undefined. 这样就比较清楚了。 需要注意的是：操作符有一个优先级的规定，可以参考：https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Operator_Precedence。 参考：https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Logical_Operators。]]></content>
      <categories>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>JS</tag>
        <tag>逻辑操作符</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[程序员晋升之路：生存意识、服务意识--IT老兵的心得]]></title>
    <url>%2Fthinking_in_programmer_life%2Ffull-stack-programmer.html</url>
    <content type="text"><![CDATA[前言 这篇文章原载于新浪博客，写于2017-06-0623:15:33，现在因为建立了自己的博客，所以迁过来，也转载在CSDN上，同时又加上“时过境迁”，又会有一些新的思考，所以修改一下，修改的地方以备注的形式展示出来，可以看出一些心态的不同来。 有一个程序员，学过前端、学过iOS，或者这么说，他喜欢研究技术，而且能把所研究的技术都搞得明明白白，但是他做项目，从来不排期，不汇报，也从来不怎么理会产品设计，结果他什么好的产品都做不出来。 这些是在厦门遇到了一个程序员所发出的感想，到了今时今日，据我了解，他还是什么都没有做出来。 做不出好的产品来，是一个好的程序员吗？ 技术都会过时的，最新的技术也不见得是最好的技术，那么技术人员的使命是什么呢？ 掌握了那么复杂的C++就算是好的程序员了吗？ 实际上，很多年了，C++程序员都缺乏用武之地了—-直到今天的区块链的火热，才又唤起市场对C++程序员的需求。 或者说，现在所鼓吹的全栈，你成为全栈了，就是好的程序员了吗？ 我觉得都不是。 你用你的能力，掌握了技术，能够很好服务于你的公司，服务于社会，这才是好的程序员。 技术是为人类服务的，脱离了服务，再尖端的技术又有什么用呢？脱离了服务，掌握了再尖端的技术的程序员，又有什么用呢？ 要使用你的技术，去提供服务，换取你的合理报酬，这就是生存意识。 掌握社会服务所需要的，或者是将要需要的技术，去提供服务，换取更好的报酬，这就是生存意识。 固守于一门很复杂的语言，为自己掌握了它而别人没有掌握而沾沾自喜，却不思考这门语言对于提供服务的价值和意义，这就已经完全走偏了，惑于技巧的层面，而忽略了根本的初衷，我们不是为了学技术而学技术的，技术也从来不是为了让你学而产生的。如果一门技术，已经不能很好地服务于社会，那怕它再难，学习起来再有挑战性，对你来说只能是满足征服的快乐，而不是满足你谋生、立业的人生目标。 放下心中自己围起来的那道技术的篱笆，不拘一格地去掌握那些需要你掌握的技术，做出好的产品来提供你的服务。 不要太在意这个技术是你新学的，也许掌握的还没有那么扎实，也许写出来的代码还没有那么漂亮，这些都会慢慢变好的，因为你写的代码，做出的产品有人在使用，这就要比那些写的很漂亮，但是没人用，只能束之高阁的代码要强太多了。代码不被使用，再漂亮，也缺乏生命力。 代码也是有生命的，这是我的感觉，所以，我们需要好好去维护她，不断去调整，让她更好地提供服务。]]></content>
      <categories>
        <category>程序人生</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Git：git-checkout的用法总结（1）]]></title>
    <url>%2Fgit%2Fgit-checkout-1.html</url>
    <content type="text"><![CDATA[原帖收藏于IT老兵驿站，传递一个IT老兵在凋零前的光和氧。Git的git-checkout的用法总结。 初衷git-checkout是Git最常用的命令之一，但又是有些复杂的命令，总会感觉有些用不明白，用不明白的原因应该是没有深度地、全面地理解一下，所以要对它好好整理一下。 介绍checkout在CVS和SVN中都是检出的意思，从版本库检出一个版本，在Git中就不是这么简单了。手册上是这样介绍的： 1git-checkout - Switch branches or restore working tree files 在Git里面，checkout用于切换分支或者恢复工作树的文件。 实例问题：线上分支出现了一个问题，急需要修复（可以参看Git Flow一章）。步骤： 需要创建一个hotfix分支，参考语法：1git checkout -b|-B &lt;new_branch&gt; [&lt;start point&gt;] 实际语句：1git checkout -b hotfix-1.2.1 master 这个时候分支是本地分支，并没有提交到服务器上去，如果这个分支已经被创建，这个命令会失败，这个时候，如果想要重置这个分支，需要使用-B参数。 查看分支：git branch -av 进行修改工作 …… 问题：本地发生了一些修改，但是想放弃这些修改，回退到获取这个版本初始时的状态。参考语法：1git checkout [&lt;tree-ish&gt;] [--] &lt;pathspec&gt;…​ 实际语句：123git checkout 26a2e80 # 26a2e80 是一个commit号，这个命令会把index区域和工作区域的内容都更新git checkout -- README # README是想恢复的文件名，恢复成index区域里面的内容，为什么要加“--”呢，这个是为了告诉Git，这是一个文件而不是一个分支Git checkout . # 从index区域恢复所有文件 这个命令很灵活，既可以带一个commit号，又可以带着一个路径，tree-ish 可以理解成一个commit号，就是恢复到某一个commit号，index就是暂存区，这里要理解Git的三个区域，如果这个还不明白，那需要单开一篇文章去讲了。 以上是checkout比较常用的两个用法，逐步整理其他的用法。 参考：https://git-scm.com/docs/git-checkout。https://stackoverflow.com/questions/14460595/git-checkout-with-dot。]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>用法</tag>
        <tag>checkout</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下shell命令用法及常见用例：top]]></title>
    <url>%2Flinux%2Fshell-command-top.html</url>
    <content type="text"><![CDATA[top命令可以实时动态地查看系统的整体运行情况，是一个综合了多方信息监测系统性能和运行信息的使用工具。top命令提供了互动式的界面，用热键管理。这个命令是一个非常重要和常用的命令，但是同时也有点复杂，参数较多，怎么能够掌握好呢？用了这么多年，也都一直没有用好。老老实实读一遍手册，总体了解一下都有什么才好去做整理，有的时候可能连它都有什么功能都不知道。 命令格式top [选项] 命令功能top命令用来显示Linux的处理器活动和内核实时管理的任务。它会显示正在使用的处理器和内存以及运行进程等其他信息。 命令选项 -b：以批处理模式操作。 -c：显示完整的命令。 -d：屏幕刷新间隔时间。 -I：忽略失效过程。 -s：保密模式。 -S：累积模式。 -i&lt;时间&gt;：设置间隔时间。 -u&lt;用户名&gt;：指定用户名。 -p&lt;进程号&gt;：指定进程。 -n&lt;次数&gt;：循环显示的次数。 top交互命令在top命令执行过程中可以使用的一些交互命令。这些命令都是单字母的，如果在命令行中使用了-s选项， 其中一些命令可能会被屏蔽。 h：显示帮助画面，给出一些简短的命令总结说明。 k：终止一个进程。 i：忽略闲置和僵死进程，这是一个开关式命令。 q：退出程序。 r：重新安排一个进程的优先级别。 S：切换到累计模式。 s：改变两次刷新之间的延迟时间（单位为s），如果有小数，就换算成ms。输入0值则系统将不断刷新，默认值是5s。 f或者F：从当前显示中添加或者删除项目。 o或者O：改变显示项目的顺序。 l：切换显示平均负载和启动时间信息。 m：切换显示内存信息。 t：切换显示进程和CPU状态信息。 c：显示进程启动时的完整路径和程序名。 M：根据驻留内存大小进行排序。 P：根据CPU使用百分比大小进行排序。 T：根据时间/累计时间进行排序。 w：将当前设置写入~/.toprc文件中。 界面解释12345top - 21:52:52 up 247 days, 6:23, 2 users, load average: 0.09, 0.12, 0.13Tasks: 126 total, 1 running, 125 sleeping, 0 stopped, 0 zombie%Cpu(s): 4.0 us, 2.3 sy, 0.0 ni, 93.7 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 3881808 total, 153396 free, 3577588 used, 150824 buff/cacheKiB Swap: 4063228 total, 1206484 free, 2856744 used. 86344 avail Mem 统计信息区前五行是系统整体的统计信息。系统运行时间和平均负载第一行是任务队列信息，同uptime命令的执行结果，可以使用l命令切换uptime的显示。其内容如下： 21:52:52：当前时间。 up 247 days, 6:23：系统运行时间。 2 users：当前登录用户数。 load average: 0.09, 0.12, 0.13：系统负载，即任务队列平均长度。分别为1、5、15min前到现在平均值。 进程第二行为进程信息。内容如下： 126 total：进程总数[键入H可查看线程数]。 1 running：正在运行的进程。 125 sleeping：睡眠进程。 0 stopped：停止的进程。 0 zombie：僵尸进程数。 CPU状态第三行为CPU状态信息，当有多个CPU时，这些内容可能会超过两行。内容如下： us, user：运行(未调整优先级的) 用户进程的CPU百分比。 sy，system：运行内核进程的CPU百分比。 ni，niced：运行已调整优先级的用户进程的CPU百分比。 wa，IO wait：用于等待IO完成的CPU百分比。 hi：处理硬件中断的CPU百分比。 si：处理软件中断的CPU百分比。 st：这个虚拟机被hypervisor偷去的CPU百分比。（译注：如果当前处于一个hypervisor下的vm，实际上hypervisor也是要消耗一部分CPU处理时间的）。 内存使用倒数第2、3行为内存相关信息，内存显示可以用m命令切换： KiB Mem: 3881808 total, 153396 free：分别是物理内存总量、空闲内存总量。 3577588 used, 150824 buff/cache：使用物理内存总量、用作内核缓存内存量。 KiB Swap: 4063228 total, 1206484 free：分别是交换分区总量、使用交换分区剩余量。 2856744 used. 86344 avail Mem：可用来启动应用的内存（有些复杂，以后解释，恶意参考这里）。 字段/列最后一行则是进程相关的资源占用信息： PID：进程的ID，进程的唯一标识符。 USER：进程所有者的实际用户名。 PR：进程的优先级别，范围0-39，越小越优先被执行。 NI：nice值。范围-20-19，负值表示高优先级，正值表示低优先级。在top里，PR-NI=20，默认启动一个进程，nice是0。 VIRT：进程占用的虚拟内存。 RES：进程占用的物理内存。 SHR：进程使用的共享内存。 S：进程的状态。 D：表示不可终端的睡眠状态。 R：表示正在运行。 S：表示休眠。 T：表示作业控制信号下已停止。 t：表示在调试状态的停止。 Z：表示僵死状态。 %CPU：自从上一次更新到现在任务所使用的CPU使用率。 %MEM：进程使用的物理内存和总内存的百分比。 TIME+：该进程启动后占用的总的CPU时间，即占用CPU使用时间的累加值，精确到百分之一秒。 COMMAND：进程启动命令名称。 交互命令实例实例：h：帮助描述：在top状态下，按h键或者?键显示交互命令的帮助菜单。输出： 123456789101112131415161718192021222324Help for Interactive Commands - procps-ng version 3.3.10Window 1:Def: Cumulative mode Off. System: Delay 3.0 secs; Secure mode Off. Z,B,E,e Global: &apos;Z&apos; colors; &apos;B&apos; bold; &apos;E&apos;/&apos;e&apos; summary/task memory scale l,t,m Toggle Summary: &apos;l&apos; load avg; &apos;t&apos; task/cpu stats; &apos;m&apos; memory info 0,1,2,3,I Toggle: &apos;0&apos; zeros; &apos;1/2/3&apos; cpus or numa node views; &apos;I&apos; Irix mode f,F,X Fields: &apos;f&apos;/&apos;F&apos; add/remove/order/sort; &apos;X&apos; increase fixed-width L,&amp;,&lt;,&gt; . Locate: &apos;L&apos;/&apos;&amp;&apos; find/again; Move sort column: &apos;&lt;&apos;/&apos;&gt;&apos; left/right R,H,V,J . Toggle: &apos;R&apos; Sort; &apos;H&apos; Threads; &apos;V&apos; Forest view; &apos;J&apos; Num justify c,i,S,j . Toggle: &apos;c&apos; Cmd name/line; &apos;i&apos; Idle; &apos;S&apos; Time; &apos;j&apos; Str justify x,y . Toggle highlights: &apos;x&apos; sort field; &apos;y&apos; running tasks z,b . Toggle: &apos;z&apos; color/mono; &apos;b&apos; bold/reverse (only if &apos;x&apos; or &apos;y&apos;) u,U,o,O . Filter by: &apos;u&apos;/&apos;U&apos; effective/any user; &apos;o&apos;/&apos;O&apos; other criteria n,#,^O . Set: &apos;n&apos;/&apos;#&apos; max tasks displayed; Show: Ctrl+&apos;O&apos; other filter(s) C,... . Toggle scroll coordinates msg for: up,down,left,right,home,end k,r Manipulate tasks: &apos;k&apos; kill; &apos;r&apos; renice d or s Set update interval W,Y Write configuration file &apos;W&apos;; Inspect other output &apos;Y&apos; q Quit ( commands shown with &apos;.&apos; require a visible task display window ) Press &apos;h&apos; or &apos;?&apos; for help with Windows,Type &apos;q&apos; or &lt;Esc&gt; to continue 实例：显示各个CPU负载描述：在top状态下，按下“1”，可以显示每个CPU的负载情况。 12345678top - 22:30:09 up 247 days, 7:00, 2 users, load average: 0.16, 0.14, 0.14Tasks: 126 total, 1 running, 125 sleeping, 0 stopped, 0 zombie%Cpu0 : 0.3 us, 0.3 sy, 0.0 ni, 99.3 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu1 : 0.3 us, 0.0 sy, 0.0 ni, 99.7 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu2 : 0.3 us, 0.0 sy, 0.0 ni, 99.7 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 st%Cpu3 : 0.3 us, 0.3 sy, 0.0 ni, 99.3 id, 0.0 wa, 0.0 hi, 0.0 si, 0.0 stKiB Mem : 3881808 total, 141164 free, 3578540 used, 162104 buff/cacheKiB Swap: 4063228 total, 1206756 free, 2856472 used. 79768 avail Mem 实例：手动刷新描述：在top状态下，按空格或者回车进行手动刷新。top命令默认在一个特定间隔（3秒）后刷新显示。 实例：A：切换交替显示模式 描述：在top状态下，按A键，可以在全屏和交替模式间切换。在交替模式下会显示4个窗口。 Def（默认字段组） Job（任务字段组） Mem（内存字段组） Usr（用户字段组） 这四组字段共有一个独立的可配置的概括区域和它自己的可配置任务区域。4个窗口中只有一个窗口是当前窗口。当前窗口的名称显示在左上方。只有当前窗口才会接受你键盘交互命令。可以用a和w在4个窗口间切换，a移到后一个窗口，w移到前一个窗口。用g命令可以输入一个数字来选择当前窗口。 实例：B：粗体显示描述：在top状态下，按B键，会将一些重要信息会以加粗字体显示。输出： 实例：d或s：设置显示的刷新间隔描述：在top状态下，按d键或者s键，设置显示的刷新间隔为1秒。输出： 实例：f：字段管理描述：在top状态下，按f键进入字段管理界面。d键选择要显示的字段，用*标记的是已选择的。上下光标键在字段内导航，左光标键可以选择字段，右光标键进入排序状态，此时按上下光标键可以进行上下移动，回车确认。s键设置当前排序的字段，q或Esc键退出。输出： 实例：R：反向排序描述：在top状态下，按R键切换反向/常规排序。 实例：c：切换显示命令名称和完整命令行描述：在top状态下，按c键，切换是否显示进程启动时的完整路径和程序名。也可以使用如下命令行。命令：top -c输出： 实例：i：空闲任务描述：在top状态下，按i键，切换显示空闲任务。输出：不显示空闲任务： 实例：V：树视图描述：在top状态下，按V键，切换树视图。输出： 实例：z：切换彩色显示描述：在top状态下，按z键，切换彩色，即打开或关闭彩色显示。输出： 实例：Z：改变配色描述：在top状态下，按Z键，显示一个改变top命令的输出颜色的屏幕。可以为8个任务区域选择8种颜色。输出：设置修改：显示效果： 实例：按照内存使用大小排序描述：在top状态下，按shift+m，可以按照内存使用大小排序进程。输出： 实例：x、y：切换高亮信息描述：在top状态下，按x键将排序字段高亮显示（纵列）；按y键将运行进程高亮显示（横行）。输出： 实例：u：特定用户的进程描述：在top状态下，按u键将会提示输入用户名，输入首显示特定用户的进程。空白将会显示全部用户。输出： 实例：n或#：任务的数量描述：在top状态下，按n键或者#键可以设置最大显示的任务数量。输出： 实例：k：结束任务描述：在top状态下，按k键输入PID后，发送信号给任务（通常是结束任务）。输出： 实例：r：重新设置优先级描述：在top状态下，按r键输入-20~19范围中的数字后，重新设置一个任务的调度优先级（nice值）。输出： 命令行实例实例：-p：监控特定的PID描述：-p选项监控指定的PID。PID的值为0将被作为top命令自身的PID。命令：top -p 0 实例：-u或-U: 用户名或者UID描述：可以用这些选项浏览特定用户的进程。用户名或者UID可以在选项中指定。-p、-u和-U选项是互斥的，同时只可以使用这其中一个选项。试图组合使用这些选项时，会得到一个错误:命令：top -p 1248 -u root输出： 实例：-b：批处理模式描述：-b选项以批处理模式启动top命令，在文件中保存输出时是很有用的。 实例：-c：命令/程序名 触发:描述：显示进程启动时的完整路径和程序名。 实例：-d：设置延迟间隔描述：设置top的显示间隔(以秒计)。命令：top -d 1 实例：-i：切换显示空闲进程命令：top -i 实例：-n：特定重复次数后退出描述：top输出保持刷新，直到按q键或者到达指定次数。下面的命令将在10次重复之后自动退出。命令：top -n 10]]></content>
      <categories>
        <category>Linux</category>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git：Git merge的--ff和--no-ff]]></title>
    <url>%2Fgit%2Fgit-git-merge-ff-no-ff.html</url>
    <content type="text"><![CDATA[Git用法总结系列收藏于IT老兵驿站。Git：Git-merge的–ff和–no-ff。 前言Git merge最容易糊涂的地方就是这个--ff参数和--no-ff 参数，通过本文，把这个整理清楚。 其实官网讲的非常清楚，不过可能因为是英文的，所以大家阅读起来会有一些障碍。（PS：其实还是应该逐步逐步提高自己阅读英文文档的能力，想达到一个更高的高度，是需要客服自己本身很多的弱点的） 实例假设合并前的分支是这样，这个一个非常常见的场景，如果不明白，可以参考另外一篇文章Git Flow工作流：这是一个很常见的用例，功能开发分支是iss53，在开发新功能，master分支是线上分支，出现了问题，开辟了hotfix分支进行修复，修复完成，进行合并，需要把hotfix合并回master。 123456$ git checkout master$ git merge hotfixUpdating f42c576..3a0874cFast-forward index.html | 2 ++ 1 file changed, 2 insertions(+) 步骤如下： 切换回master分支。 将hotfix分支合并会master分支。然后看到了Fast-forward 的字样，这个词组的意思就是快进，播放电影的时候，可以注意一下，快进按钮上面就是这个词组。那么实际变成了什么样呢？仅仅是master指针指向了这个提交C4。这样是一种比较快的合并方式，轻量级，简单。这个时候，我们往往会删掉hotfix分支，因为它的历史作用已经结束，这个时候，我们的iss53这个功能又向前开发，进行了一次提交，到了C5，那么变成了这样：然后，我们要把iss53 这个分支合并回master，就变成了这样：这个时候生成了一个新的commit号，这种提交就不是fast-forward（这个时候也无法生成fast-forward提交，因为要将两个版本的内容进行合并，只有在没有需要合并内容的时候，会有这个fast-forward 方式的提交）。如果我们对第一次合并，使用了--no-ff参数，那么也会产生这样的结果，生成一个新的提交，实际上等于是对C4 进行一次复制，创建一个新的commit，这就是--no-ff的作用。 参考：https://git-scm.com/book/en/v2/Git-Branching-Basic-Branching-and-Merging，这里讲了原理。参考：https://git-scm.com/docs/git-merge，这里是参考。]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>git merge</tag>
        <tag>ff</tag>
        <tag>no-ff</tag>
        <tag>fast forward</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu：新增和删除用户]]></title>
    <url>%2Flinux%2Fubuntu-user-add-delete.html</url>
    <content type="text"><![CDATA[Ubuntu：新增和删除用户，修改用户组信息。参考：https://www.digitalocean.com/community/tutorials/how-to-add-and-delete-users-on-ubuntu-16-04#how-to-delete-a-user。 Linux上root用户是权力最大的用户，但是也非常危险，处于安全考虑，增加个人用户是必要的方法，下文讲了讲在Ubuntu上如何新增和删除用户。 创建用户实例： root用户新增用户chenming1234567891011121314151617root@iZhp3fz3iqsadyes2s8ay8Z:~# adduser chenmingAdding user `chenming&apos; ...Adding new group `chenming&apos; (1000) ...Adding new user `chenming&apos; (1000) with group `chenming&apos; ...Creating home directory `/home/chenming&apos; ...Copying files from `/etc/skel&apos; ...Enter new UNIX password: Retype new UNIX password: passwd: password updated successfullyChanging the user information for chenmingEnter the new value, or press ENTER for the default Full Name []: Room Number []: Work Phone []: Home Phone []: Other []: Is the information correct? [Y/n] y 首先创建了一个新的用户组chenming。在这个组内新建了用户chenming。要求你输入密码。要求输入一些其他信息，可以按回车略过。最后按下y对以上信息进行确认。 实例：非root用户新增用户 1$sudo adduser chenming 给用户授权实例：把chenming加到sudo组里面 12root@iZhp3fz3iqsadyes2s8ay8Z:~# groups chenmingchenming : chenming 可以看到，chenming只在chenming的组里面（前面是用户名，冒号后面是组名）。在这个组里面，可能很多命令你都不能执行。 1root@iZhp3fz3iqsadyes2s8ay8Z:~# usermod -aG sudo chenming 再来看一下： 12root@iZhp3fz3iqsadyes2s8ay8Z:~# groups chenmingchenming : chenming sudo look，进入了sudo组了，这下你可以臭屁了。 还有一种方法可以加入sodu组。如果是root用户。1root@iZhp3fz3iqsadyes2s8ay8Z:~# visudo 这个时候会打开一个文本编辑器，去编辑/etc/sudoer这个文件，可能是vim，也可能是nano。找到： 12# User privilege specificationroot ALL=(ALL:ALL) ALL 在下面加入： 1chenming ALL=(ALL:ALL) ALL 保存（vim下是:x，nano下是ctrl+x），退出，这样chenming这个用户就加入了sudo组。 删除用户仅仅删除用户：1234root@iZhp3fz3iqsadyes2s8ay8Z:~# deluser chenmingRemoving user `chenming&apos; ...Warning: group `chenming&apos; has no more members.Done. 将用户的目录也删除：1root@iZhp3fz3iqsadyes2s8ay8Z:~# deluser --remove-home chenming 但这个时候，这个已经被删除的用户还是在sudo组里面。参照上面的过程，使用visudo命令，删掉增加的那一行即可。]]></content>
      <categories>
        <category>Linux</category>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JS：NPM依赖包版本号波浪字符"~"]]></title>
    <url>%2Fjs%2Fjs-npm-symbol-tilde.html</url>
    <content type="text"><![CDATA[提醒原帖完整收藏于IT老兵驿站，并会不断更新。 JS：NPM依赖包版本号波浪字符”~”。 参考官网：https://github.com/npm/node-semver#functions。 Tilde Ranges ~1.2.3 ~1.2 ~1Allows patch-level changes if a minor version is specified on the comparator. Allows minor-level changes if not. 如果minor被指定，则允许patch被改变；如果没有，允许minor被改变。（个别知识需要参考前面的帖子） ~1.2.3 := &gt;=1.2.3 &lt;1.(2+1).0 := &gt;=1.2.3 &lt;1.3.0~1.2 := &gt;=1.2.0 &lt;1.(2+1).0 := &gt;=1.2.0 &lt;1.3.0 (Same as 1.2.x)~1 := &gt;=1.0.0 &lt;(1+1).0.0 := &gt;=1.0.0 &lt;2.0.0 (Same as 1.x)~0.2.3 := &gt;=0.2.3 &lt;0.(2+1).0 := &gt;=0.2.3 &lt;0.3.0~0.2 := &gt;=0.2.0 &lt;0.(2+1).0 := &gt;=0.2.0 &lt;0.3.0 (Same as 0.2.x)~0 := &gt;=0.0.0 &lt;(0+1).0.0 := &gt;=0.0.0 &lt;1.0.0 (Same as 0.x)~1.2.3-beta.2 := &gt;=1.2.3-beta.2 &lt;1.3.0 Note that prereleases in the 1.2.3 version will be allowed, if they are greater than or equal to beta.2. So, 1.2.3-beta.4 would be allowed, but 1.2.4-beta.2 would not, because it is a prerelease of a different [major, minor, patch] tuple.]]></content>
      <categories>
        <category>JavaScript</category>
      </categories>
      <tags>
        <tag>波浪字符</tag>
        <tag>依赖包</tag>
        <tag>Javascript</tag>
        <tag>NPM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JS：NPM依赖包版本号波浪字符"~"]]></title>
    <url>%2Fjs%2Fjs-npm-symbol-caret.html</url>
    <content type="text"><![CDATA[提醒原帖完整收藏于IT老兵驿站，并会不断更新。 JS：NPM依赖包版本号波浪字符”~”。 正文官网摘录如下： Tilde Ranges ~1.2.3 ~1.2 ~1Allows patch-level changes if a minor version is specified on the comparator. Allows minor-level changes if not. 简单翻译：如果minor被指定，则允许patch被改变；如果没有，允许minor被改变。这里需要理解NPM的版本三元组，NPM采用的是3元组的版本控制，[major，minor，patch]。（详细知识需要参考这里） 实例： ~1.2.3 := &gt;=1.2.3 &lt;1.(2+1).0 := &gt;=1.2.3 &lt;1.3.0 minor被指定为2，所以能够获取的版本是大于等于1.2.3，小于1.3之间。 ~1.2 := &gt;=1.2.0 &lt;1.(2+1).0 := &gt;=1.2.0 &lt;1.3.0 (Same as 1.2.x) minor被指定为2，所以能够获取的版本是大于等于1.2，小于1.3之间。 ~1 := &gt;=1.0.0 &lt;(1+1).0.0 := &gt;=1.0.0 &lt;2.0.0 (Same as 1.x) minor没有被指定，所以能够获取的版本是大于等于1，小于2之间，就是minor可以改变。 下面留几道思考题： ~0.2.3 := &gt;=0.2.3 &lt;0.(2+1).0 := &gt;=0.2.3 &lt;0.3.0~0.2 := &gt;=0.2.0 &lt;0.(2+1).0 := &gt;=0.2.0 &lt;0.3.0 (Same as 0.2.x)~0 := &gt;=0.0.0 &lt;(0+1).0.0 := &gt;=0.0.0 &lt;1.0.0 (Same as 0.x)~1.2.3-beta.2 := &gt;=1.2.3-beta.2 &lt;1.3.0 Note that prereleases in the 1.2.3 version will be allowed, if they are greater than or equal to beta.2. So, 1.2.3-beta.4 would be allowed, but 1.2.4-beta.2 would not, because it is a prerelease of a different [major, minor, patch] tuple. 参考https://github.com/npm/node-semver#functions。]]></content>
      <categories>
        <category>JavaScript</category>
        <category>NPM</category>
      </categories>
      <tags>
        <tag>JavaScript</tag>
        <tag>波浪字符</tag>
        <tag>依赖包</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下shell命令用法及常见用例：tar]]></title>
    <url>%2Flinux%2Fshell-command-tar.html</url>
    <content type="text"><![CDATA[tar命令用来归档多个文件或目录到单个归档文件中，并且归档文件可以进一步使用gzip或者bzip2等技术进行压缩。 命令格式tar [OPTION...] [FILE]... 命令功能Tar（Tape ARchive，磁带归档的缩写，最初设计用于将文件打包到磁带上，现在大都使用它来实现备份某个分区或者某些重要的目录）是类Unix系统中使用最广泛的命令，用于归档多个文件或目录到单个归档文件中，并且归档文件可以进一步使用gzip或者bzip2等技术进行压缩，还能保留其文件权限。换言之，tar命令也可以用于备份：先是归档多个文件和目录到一个单独的tar文件或归档文件，然后在需要之时将tar文件中的文件和目录释放出来。 命令选项 选项 含义 -A或–catenate 新增文件到以存在的备份文件 -B 设置区块大小 -c或–create 建立新的备份文件 -C&lt;目录&gt; 这个选项用在解压缩，若要在特定目录解压缩，可以使用这个选项 -d 记录文件的差别 -x或–extract或–get 从备份文件中还原文件 -t或–list 列出备份文件的内容 -z或–gzip或–ungzip 通过gzip指令处理备份文件 -Z或–compress或–uncompress 通过compress指令处理备份文件 -f&lt;备份文件&gt;或–file=&lt;备份文件&gt; 指定备份文件 -v或–verbose 显示指令执行过程 -r 添加文件到已经压缩的文件 -u 添加改变了和现有的文件到已经存在的压缩文件 -j 支持bzip2解压文件 -v 显示操作过程 -l 文件系统边界设置 -k 保留原有文件不覆盖 -m 保留文件不被覆盖 -w 确认压缩文件的正确性 -p或–same-permissions 用原来的文件权限还原文件 -P或–absolute-names 文件名使用绝对名称，不移除文件名称前的“/”号 -N &lt;日期格式&gt;或–newer=&lt;日期时间&gt;只将较指定日期更新的文件保存到备份文件里 –exclude=&lt;范本样式&gt; 排除符合范本样式的文件 什么是“文件压缩”？我们知道，在计算机系统中文件的内容是信息，信息实际上就是一个由值0和值1组成的位（又称为比特）序列，8个位被组织成一组，称为字节。一般来说，一个字节的8位是没有被全部利用起来的，这些没有被利用的位占据了一个文件的大部分空间，而“文件压缩”就是利用复杂的计算方式，将这些没有利用的空间腾出来，以让文件占用的空间变小。 简单来说，「压缩」就是把文件中没有完全填满的空间填满。压缩过的文件不能直接被操作系统所使用，因此，「解压缩」就是指把文件「还原」为未压缩之前的模样。压缩前与压缩后的文件所占用的磁盘空间大小之比就是「压缩比」。 常见的压缩格式Linux 中常见的压缩格式有： 123456*.Z：compress 程序压缩的文件。*.gz：gzip 程序压缩的文件。*.bz2：bzip2 程序压缩的文件。*.tar：tar 程序打包的数据，没有被压缩过。*.tar.gz（简写为 .tgz）：tar 程序打包的数据，经过 gzip 的压缩。*.tar.bz2（简写为 .tbz2）：tar 程序打包的数据，经过 bzip2 的压缩。 上面的压缩格式中，主要是gzip和bzip2两个压缩命令，它们是GNU计划的中的一部分，在此之前是compress命令，但它已经不再流行了。bzip2比gzip的压缩比很好，不过bzip2通常只能针对一个文件来压缩和解压缩。如果是这样的话，压缩整个开发环境目录就太繁琐了。 因此tar命令就出现了，tar不是一个 “压缩命令”，而是一个“打包命令”。也就是说，tar可以把很多文件「打包」成一个文件，甚至连目录也可以进行打包。一开始tar命令的确是不支持压缩的功能，后来GNU计划为了提供给使用者更方便并且更加强大的压缩与打包功能，就把整个tar与压缩的功能结合在一起了。 仅仅打包起来的tar文件俗称tarfile文件，经过压缩的tar文件叫做tarball文件。 全能的 tar 命令概要tar可以将多个目录或文件打成一个大文件，同时支持gzip/bzip2 归档：tar {-c} [option…] -f destination source追加归档：tar {-r | -u} -f source [option…] destination解压：tar {-t | -x} -f source [option…] -C destination 最简单的使用 tar 只要记住下面的方式： 压缩：tar -jcv -f filename.tar.bz2 被压缩的文件或目录名称 查看文件：tar -jtv -f filename.tar.bz2 解压缩：tar -jxv -f filename.tar.gz -C 解压到哪里 filename.tar.bz2 既然tar不是一个压缩命令，是个打包命令，那么是如何做到打包并压缩的呢？我们先来看一下tar命令的常用参数： 模式参数 -c（–create）：创建新的归档文件。 -r（–append）：与-c一样创建新的归档文件，但这是以追加的模式，只能往未压缩过的归档文件中追加，要求指定-f参数。 -t：查看归档文件的内容含有哪些文件，可以看到包括文件名在内的详细信息。 -u：与-r一样，但是只往归档文件添加更新的文件。 -x：解压缩归档文件。如果一个归档文件里有相同文件名的多个文件，那么会先将每个文件解压，最新的文件将覆盖旧的文件。 tar分为三种模式，-c，-r，-u三个一类，为归档/压缩模式，在该模式下，tar会递归遍历指定目录下的所有目录和文件，并创建归档文件。-x表示为去归档/解压模式，-t表示为打印列表模式。 通用参数 -j：使用bzip2的支持进行压缩和解压缩，文件名最好为*.tar.bz2。 -z：使用gzip的支持进行压缩和解压缩，文件名最好为*.tar.gz。 -v：在压缩/解压缩的过程中，将正在处理的文件名显示出来。 -f：后面接被处理的文件名，最好把-f单独出来写一个参数。 -C：指定解压的目录。 -p：保留文件的原始信息，权限等等 -P：解压时保留绝对路径。 –exclude=FILE：在打包压缩的时候，不要将FILE打包。 打包并创建归档文件示例：打包一个目录。描述：将/home/test这个目录打包，生成文件名为command-18-06-02.tar的归档文件，保存在当前目录下。123456# tar -cv -f command-18-06-02.tar /home/test/home/test/.bash_logout/home/test/.bashrc/home/test/apache-tomcat-9.0.7.tar.gz/home/test/.bash_profile/home/test/nginx-1.10.1.tar.gz -c（–create的简写）参数，这表示为指定的文件或者目录创建新的归档文件。使用-f指定读取或者写入的归档文件，可以用-表示标准输入或者标准输出，-f可以与其他参数连起来写，必须保证f参数后面跟的是文件名。但不推荐这样写，因为参数调换顺序是允许的，如果写成-cfv就会导致压缩后的文件名变成了v。 使用-v表示生成详细的输出，在压缩或者解压的模式中，会列出正在向归档文件读或者写的文件名字。 创建tar.gz归档文件示例：打包并且使用gzip压缩。描述：将/home/test/images目录下的所有文件以及目录中的文件打包，并用gzip进行压缩，生成名为MyImages-18-06-02.tar.gz的归档文件，放在当前目录下。 12345678# tar -zcv -f MyImages-18-06-02.tar.gz /home/test/imagesOR# tar -zcv -f MyImages-18-06-02.tar.tgz /home/test/images/home/test/images/alejandro-gonzalez-17189.jpg/home/test/images/brooke-lark-275181.jpg/home/test/images/brenda-godinez-228181.jpg/home/test/images/artur-rutkowski-97622.jpg/home/test/images/ben-white-138743.jpg -z表示要使用gzip支持来压缩或者解压文件，注意gzip的压缩的文件格式最好写成tar.gz。（注：tar.gz 和 tgz 是同一个意思） 打包压缩排除某些文件示例：打包压缩并排除某些文件。描述：将/home/test/images目录下，排除brooke-lark-275181.jpg和ben-white-138743.jpg之外的所有文件打包，并用gzip进行压缩，生成名为MyImages-18-06-02.tar.gz的归档文件，放在当前目录下。 1234# tar -czv -f MyImages-18-06-02.tar.gz --exclude=./brooke-lark-275181.jpg --exclude=./ben-white-138743.jpg /home/test/images/home/test/images/alejandro-gonzalez-17189.jpg/home/test/images/brenda-godinez-228181.jpg/home/test/images/artur-rutkowski-97622.jpg 解压归档文件（默认）示例：解压，默认解压。描述：将名为MyImages-18-06-02.tar的归档文件解压至当前目录下。 1234# tar -xvf MyImages-18-06-02.tarhome/test/images/alejandro-gonzalez-17189.jpghome/test/images/brenda-godinez-228181.jpghome/test/images/artur-rutkowski-97622.jpg 其中，-x参数表示去解压一个归档文件，如果归档文件中有两个相同名字的文件，那么每一个文件都会被解压出来，然后最新的会覆盖旧的文件。注意这里没有指定-j参数，因为tar看到指定了-x参数，就知道这是解压操作，会自动判断该解压包的压缩类型。 解压归档文件并指定目录示例：解压到一个指定目录。描述：将名为MyImages-18-06-02.tar.gz的归档文件解压至一个指定的目录。 1234# tar -xv -f MyImages-18-06-02.tar -C /home/test/public_imageshome/test/public_images/alejandro-gonzalez-17189.jpghome/test/public_images/brenda-godinez-228181.jpghome/test/public_images/artur-rutkowski-97622.jpg 查看压缩包文件信息示例：查看压缩包文件信息。描述：列出MyImages-18-06-02.tar.bz2中的文件信息，-v参数，会生成与ls(1)命令相近的输出。 123456# tar -tv -f MyImages-18-06-02.tar.gzOR# tar -tv -f MyImages-18-06-02.tar.bz2-rw-r--r-- root/root 2176861 2018-06-02 21:26 home/test/images/alejandro-gonzalez-17189.jpg-rw-r--r-- root/root 8452524 2018-06-02 21:26 home/test/images/brenda-godinez-228181.jpg-rw-r--r-- root/root 1131986 2018-06-02 21:26 home/test/images/artur-rutkowski-97622.jpg 解压单个文件示例：解压单个文件。描述：将home/test/.bashrc这一个文件从归档文件中提取出来。 12# tar -xv -f command-18-06-02.tar home/test/.bashrchome/test/.bashrc 解压多个指定的文件示例：解压多个指定的文件。描述：将file1、file2等多个文件从归档文件中提取出来，可以用空格隔开多个文件，也可以用通配符的形式。 1234567# tar -zxv -f MyImages-18-06-02.tar.gz "file 1" "file 2"OR# tar -zxv -f MyImages-18-06-02.tar.gz --wildcards '*b*.jpg'home/test/images/brooke-lark-275181.jpghome/test/images/brenda-godinez-228181.jpghome/test/images/ben-white-138743.jpghome/test/images/aleks-dahlberg-274646.jpg]]></content>
      <categories>
        <category>Linux</category>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CSS：文档流]]></title>
    <url>%2Fcss%2Fcss-normal-flow.html</url>
    <content type="text"><![CDATA[CSS的文档流介绍。 官网：https://www.w3.org/TR/2016/WD-CSS22-20160412/visuren.html#normal-flow。 文档流文档流其实应该叫正常流，英文是Normal flow，我的理解呢，就是接收到的文档的内容，因为这些内容一直从服务端传输过来，边传输边需要处理，就像水流一样，所以称为流。 在文档流中的盒子是需要归属于一个上下文的，块级盒子参与到块格式化上下文中，内联级盒子参与到内联格式化上下文中，还有表格格式化上下文。 块格式化上下文（Block formatting contexts）块格式化上下文，简称BFC，是按照从上到下，一个一个垂直排列的，块之间的间距是靠margin来控制的。 In a block formatting context, boxes are laid out one after the other, vertically, beginning at the top of a containing block. The vertical distance between two sibling boxes is determined by the ‘margin’ properties. Vertical margins between adjacent block-level boxes in a block formatting context collapse. 翻译：在块格式化上下文中，框从一个包含块的顶部开始一个接一个地垂直排列。 两个兄弟盒子之间的垂直距离由“margin”属性决定。 块格式化上下文中相邻块级盒子之间的垂直margin会折叠。 ##内联格式化上下文（Inline formatting contexts）内联格式化上下文，简称IFC，主要是水平排列的，水平对齐是由一些参数来控制的。 An inline formatting context is established by a block container box that contains no block-level boxes. In an inline formatting context, boxes are laid out horizontally, one after the other, beginning at the top of a containing block. Horizontal margins, borders, and padding are respected between these boxes. The boxes may be aligned vertically in different ways: their bottoms or tops may be aligned, or the baselines of text within them may be aligned. The rectangular area that contains the boxes that form a line is called a line box. 翻译：内联格式化上下文由不包含块级框的块容器盒子建立。 在内联格式化上下文中，盒子从一个接一个地开始，从一个包含块的顶部开始。 这些框之间会考虑水平边距，边框和填充。 盒子可以以不同的方式垂直对齐：它们的底部或顶部可以对齐，或者它们内的文本的基线可以对齐。 包含形成一条线的框的矩形区域称为线盒子line box。 这里面有一些父容器和子布局的一些关系，需要梳理。 相对定位相对定位是根据这个盒子原本在文档流中的位置或者floated进行一些偏移。 未完，待续……]]></content>
      <categories>
        <category>CSS</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java：Tomcat的部署实例之资源目录]]></title>
    <url>%2Fjava%2Fjava-deploy-resource-folder.html</url>
    <content type="text"><![CDATA[Tomcat上部署应用后，原本目录是否会被移除。 实例：一个项目的资源放在了WebContent下面，这样每次打包，都会将这些文件打包进去，这样在打包时，导致打出来的war包有好几百兆，这样上传Git也非常不方便。 方案1：分析：如果删除掉本地WebContent下的资源文件，再部署到服务器上，war包其实是一个压缩包，加压后覆盖原本目录下的相同内容，因为新上传的war包没有相同的资源文件，这样就不会覆盖原本的资源文件。结果：加压后的项目目录也不存在资源文件了，看来这个部署过程，是会删掉原本的项目目录的。 方案2：分析：因为webapps是web服务根目录，那么把资源文件从项目目录移到webapps下面，这样应该也可以被访问到。结果：成功，可以被访问到。 为了验证这个，上网查了很多帖子，众说纷纭，最后还是在官网找到这么一段话： The following deployment sequence will occur on Tomcat startup in that case: Any Context Descriptors will be deployed first. Exploded web applications not referenced by any Context Descriptor will then be deployed. If they have an associated .WAR file in the appBase and it is newer than the exploded web application, the exploded directory will be removed and the webapp will be redeployed from the .WAR .WAR files will be deployed 注意这里the exploded directory will be removed and the webapp will be redeployed from the .WAR，原本的解压目录会被移除，应用会被重新从war文件中部署。 寻根究底，而不人云亦云，这样才是端正的学习的态度。]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>tomcat</tag>
        <tag>部署</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git：工作流程Git Flow]]></title>
    <url>%2Fgit%2Fgit-git-flow.html</url>
    <content type="text"><![CDATA[Git的工作流程Git Flow介绍。 前言参考：https://nvie.com/posts/a-successful-git-branching-model/， 这篇帖子是10年发表的，而我大概是08、09年接触的Git，当时因为刚刚花了好大气力研究明白SVN的流程，所以对Git很排斥，这也是我工作中一直以来的一个问题，因为在一项老技术上花了太多气力，而导致对新技术的出现本能地产生很大的排斥。如果当时仔细去研究一下Git，应该会发现Git不是来革我们这些SVN拥趸的命，而是提供完善和丰富了SVN的功能。 概述从CVS到SVN，再从SVN到Git。从中心化到去中心化的中心化（Decentralized but centralized），这句话挺有挺有深意。 分支长期分支项目存在两个长期分支： 主分支master。 开发分支develop或者dev。 We consider origin/master to be the main branch where the source code of HEAD always reflects a production-ready state.We consider origin/develop to be the main branch where the source code of HEAD always reflects a state with the latest delivered development changes for the next release. Some would call this the “integration branch”. This is where any automatic nightly builds are built from. 这里的HEAD是Git的一个指针，指向当前的分支上。上面的话的意思大概是master分支总是指向“等待上生产”状态的代码。develop分支往往是最近交付的开发修改。这个过程是和原本的SVN工作流是很接近的，一个开发分支，一个线上分支。开发完，测试后，发布到线上。SVN流程推荐在测试时分叉一个branch出来进行测试，这个时候不影响trunk上业务的继续开发，这个工作流没有这么明说，但是因为Git的灵活性，建立一个临时的测试分支也是没有问题的。Git好就好在非常灵活，不过也正是因为如此，导致了一些问题，之前有一个小朋友，把所有的功能分支都保存了下来，还说这样会更加方便，我很难理解，这样怎么会方便呢？每个人分支都需要不断同步。灵活也应该是相对的，在一个相对固定的流程下，适当的灵活，是可以提高效率的。 支持分支原文叫做supporting branches。这里面的每一个分支都有指定的目的和约束的规则，如何产生和如何合并。 Feature branches Release branches Hotfix branches 功能分支可以产生于:develop必须合并到:develop分支命名约定:除了master, develop, release-, or hotfix- 都可以，前面几个作为保留。 功能分支用于开发未来的一项功能，目标的发布此时可能还不确定。这个分支最终会被合并回develop（采用了）或者被抛弃掉（不采用）。功能分支更多存在于用户仓库，而不是origin仓库。 创建：12$ git checkout -b myfeature developSwitched to a new branch &quot;myfeature&quot; 合并回develop： 12345678$ git checkout developSwitched to branch &apos;develop&apos;$ git merge --no-ff myfeatureUpdating ea1b82a..05e9557(Summary of changes)$ git branch -d myfeatureDeleted branch myfeature (was 05e9557).$ git push origin develop 对于–no-ff，参考：https://git-scm.com/docs/git-merge，有待更进一步的解释。 发布分支可以产生于:develop必须合并到:develop和master分支分支命名约定:release-* 我理解的，这里主要用于准备一个发布版的功能已经开发完成，等待一些信息最后的确认，为了不影响下一个开发版的正常进行，打出一个发布分支。 创建一个发布分支1234567$ git checkout -b release-1.2 developSwitched to a new branch &quot;release-1.2&quot;$ ./bump-version.sh 1.2Files modified successfully, version bumped to 1.2.$ git commit -a -m &quot;Bumped version number to 1.2&quot;[release-1.2 74d9424] Bumped version number to 1.21 files changed, 1 insertions(+), 1 deletions(-) 结束一个发布分支合并回master分支123456$ git checkout masterSwitched to branch &apos;master&apos;$ git merge --no-ff release-1.2Merge made by recursive.(Summary of changes)$ git tag -a 1.2 合并回develop分支12345$ git checkout developSwitched to branch &apos;develop&apos;$ git merge --no-ff release-1.2Merge made by recursive.(Summary of changes) 删除原分支12$ git branch -d release-1.2Deleted branch release-1.2 (was ff452fe). 热修复分支可以产生于:master必须合并到:develop和master分支分支命名约定:hotfix-* 主要用于对线上代码进行热修复用，线上代码出现了问题，开出一个分支进行修复，等修复完成，合并回master和develop分支。 创建 1234567$ git checkout -b hotfix-1.2.1 masterSwitched to a new branch &quot;hotfix-1.2.1&quot;$ ./bump-version.sh 1.2.1Files modified successfully, version bumped to 1.2.1.$ git commit -a -m &quot;Bumped version number to 1.2.1&quot;[hotfix-1.2.1 41e61bb] Bumped version number to 1.2.11 files changed, 1 insertions(+), 1 deletions(-) 提交 123$ git commit -m &quot;Fixed severe production problem&quot;[hotfix-1.2.1 abbe5d6] Fixed severe production problem5 files changed, 32 insertions(+), 17 deletions(-) 结束合并回master123456$ git checkout masterSwitched to branch &apos;master&apos;$ git merge --no-ff hotfix-1.2.1Merge made by recursive.(Summary of changes)$ git tag -a 1.2.1 合并回develop12345$ git checkout developSwitched to branch &apos;develop&apos;$ git merge --no-ff hotfix-1.2.1Merge made by recursive.(Summary of changes) 删除 12$ git branch -d hotfix-1.2.1Deleted branch hotfix-1.2.1 (was abbe5d6).]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
        <tag>Git Flow</tag>
        <tag>工作流</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下shell命令用法及常见用例：netstat]]></title>
    <url>%2Flinux%2Fshell-command-netstat.html</url>
    <content type="text"><![CDATA[netstat命令用来查看系统中所有的网络套接字连接情况。 命令格式netstat [选项] 参考：https://linux.die.net/man/8/netstat。 netstat命令用来查看系统中所有的网络套接字连接情况。 命令格式netstat [选项] 参考：https://linux.die.net/man/8/netstat。 netstat命令用来查看系统中所有的网络套接字连接情况。 命令格式netstat [选项] 命令功能netstat命令用来查看系统中所有的网络套接字连接情况，包括TCP、UDP和Unix套接字。也可以显示路由表，接口状态，masquerade 连接，多播成员（Multicast Memberships）等等。另外，它还可以列出处于监听状态（等待接入请求）的套接字，比如想确认系统中的web服务是否起来，就可以查看80端口有没有打开。 命令参数 -a或–all：显示所有选项，默认不显示LISTEN相关。 -t或–tcp：(TCP)仅显示TCP相关选项。 -u或–udp：(UDP)仅显示UDP相关选项。 -x或–unix：此参数的效果和指定”-A unix”参数相同。 -n或–numeric：拒绝显示别名，能显示数字的全部转化成数字。 -l或–listening：仅列出有在Listen(监听)的服务状态。 -g或–groups：显示多重广播功能群组组员名单。 -p或–programs：显示建立相关链接的程序名和PID。 -r或–route：显示路由信息，路由表。 -e或–extend：显示扩展信息，例如UID等。 -s或–statistics：按各个协议进行统计。 -c或–continuous：每隔一个固定时间，执行该netstat命令。 -g或–groups：显示多重广播功能群组组员名单。 提示：LISTEN和LISTENING的状态只有用-a或者-l才能看到。 输出信息含义netstat的输出结构可以分为两个部分：一个是Active Internet connections，称为有源TCP连接。其中”Recv-Q”和”Send-Q”指的是接收队列和发送队列。123456Active Internet connections (w/o servers)Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 VM01.root:ssh 61.149.11.230:21859 ESTABLISHEDtcp 0 0 localhost:51476 localhost:27017 ESTABLISHEDtcp 0 0 VM01.root:ssh 61.149.11.230:50883 ESTABLISHEDtcp 0 0 VM01.root:58300 47.89.193.173:3666 ESTABLISHED 另一个是Active UNIX domain sockets，称为有源Unix域套接口(和网络套接字一样，但是只能用于本机通信，性能可以提高一倍)。Proto显示连接使用的协议，RefCnt表示连接到本套接口上的进程号，Types显示套接口的类型，State显示套接口当前的状态，Path表示连接到套接口的其它进程使用的路径名。 1234567Active UNIX domain sockets (w/o servers)Proto RefCnt Flags Type State I-Node Pathunix 2 [ ] DGRAM 15049 /run/user/0/systemd/notifyunix 3 [ ] DGRAM 13640 /run/systemd/notifyunix 2 [ ] DGRAM 13645 /run/systemd/journal/syslogunix 8 [ ] DGRAM 13660 /run/systemd/journal/socketunix 25 [ ] DGRAM 10467 /run/systemd/journal/dev-log 实例实例：列出当前所有的连接（-a）命令：netstat -a输出： 12345678root@iZhp3fz3iqsadyes2s8ayeZ:~# netstat -aActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 *:8838 *:* LISTEN tcp 0 0 localhost:27017 *:* LISTEN tcp 0 0 *:8330 *:* LISTEN tcp 0 0 localhost:submission *:* LISTEN ...... 实例：列出所有TCP端口（-t）命令：netstat -at输出： 1234567root@iZhp3fz3iqsadyes2s8ayeZ:~# netstat -atActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 *:8838 *:* LISTEN tcp 0 0 localhost:27017 *:* LISTEN tcp 0 0 *:8330 *:* LISTEN tcp 0 0 localhost:submission *:* LISTEN 示例：列出所有监听TCP的端口，数字显示描述：查看本机监听的（-l）TCP连接（-t）的IP地址的数字显示（-n）。不适用-n的话，就会用端口的约定名称来显示，例如80端口，会显示成http。命令：netstat -tnl输出： 123456root@iZhp3fz3iqsadyes2s8ayeZ:~# netstat -tnlActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 0.0.0.0:8838 0.0.0.0:* LISTEN tcp 0 0 127.0.0.1:27017 0.0.0.0:* LISTEN tcp 0 0 0.0.0.0:8330 0.0.0.0:* LISTEN 示例：获取本机的所有的TCP连接的进程名、进程号以及用户ID描述：使用-p选项查看进程信息，-ep选项可以同时查看进程名和用户名。另外，-n和-e选项一起使用，User列的属性就是用户ID，而不是用户名。查看本机所有的（al）TCP连接的（t）进程名（p）和用户名ID（ne）。命令：netstat -altpen 1234567root@iZhp3fz3iqsadyes2s8ayeZ:~# netstat -altpenActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address Foreign Address State User Inode PID/Program nametcp 0 0 0.0.0.0:8838 0.0.0.0:* LISTEN 0 11863750 31212/bnewd tcp 0 0 127.0.0.1:27017 0.0.0.0:* LISTEN 110 2945745 18546/mongod tcp 0 0 0.0.0.0:8330 0.0.0.0:* LISTEN 0 22250263 13550/btnd tcp 0 0 127.0.0.1:587 0.0.0.0:* LISTEN 0 12285119 11792/sendmail: MTA 这个可能是最屌的命令了，也可能是最常用的命令了。 还有一些实例，暂时不常用，有待完善。]]></content>
      <categories>
        <category>Linux</category>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB：聚合之累加操作符]]></title>
    <url>%2Fmongodb%2Fmongodb-collection-aggregator-accumulate-operator.html</url>
    <content type="text"><![CDATA[MongoDB的聚合之累加操作符。 官网：https://docs.mongodb.com/manual/reference/operator/aggregation/group/#considerations。 累加操作符感觉这个没有太多可说的，简单翻译一下。 名字 描述 $avg Returns an average of numerical values. Ignores non-numeric values.（返回平均值） $first Returns a value from the first document for each group. Order is only defined if the documents are in a defined order.（返回第一个） $last Returns a value from the last document for each group. Order is only defined if the documents are in a defined order.（返回最后一个） $max Returns the highest expression value for each group.（返回最大值） $min Returns the lowest expression value for each group.（返回最小值） $push Returns an array of expression values for each group. $addToSet Returns an array of unique expression values for each group. Order of the array elements is undefined.（） $stdDevPop Returns the population standard deviation of the input values. $stdDevSamp Returns the sample standard deviation of the input values. $sum Returns a sum of numerical values. Ignores non-numeric values.（返回总和）]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[MongoDB学习笔记：聚合之介绍]]></title>
    <url>%2Fmongodb%2Fmongodb-collection-aggregation-introduction.html</url>
    <content type="text"><![CDATA[完整的MongoDB学习笔记位于IT老兵博客。 MongoDB学习笔记：聚合之介绍。 前言初衷：MongoDB的使用还是有一定难度的，官网讲解的一环牵扯一环，不容易一下子把握住重点，也不利于快速查询操作，所以整理一下。 本文第一版是2018年7月4完成，8月30日感觉这篇文章的结构和后来写的结构不太统一，思路也不统一，所以对其进行一定的修改。 正文概念聚合函数是对记录集（data records）进行操作，是把多条记录集合（group）在一起，进行一些统一的操作，返回一个结果，与此相对应的是sql的group by等操作，这是数据处理所涉及的一个方面，对很多具有一定相同属性的数据整体进行处理。 MongoDB提供三种聚合方法： 聚合管道。 map-reduce函数。 单一功能的聚合方法。 聚合管道接触过linux shell的人应该对管道不会陌生，管道就是对输入的数据进行一系列的处理、转换，变成新的数据。 这里的聚合管道是对记录集进行多阶段（multi-stage）的转换，转换文档为一个新的聚合结果，例如： 解释一下： 数据集合：orders，共有4条记录，这里省略了_id 这个域。 需求：查找所有status=&quot;A&quot; 的记录，根据cust_id进行分组，计算每个组的amount的和。 分析：{$match: {status: &quot;A&quot;}}，第一个阶段，匹配阶段，查找所有status=&quot;A&quot; 的记录。{$group: {_id: &quot;$cust_id&quot;, total: {$sum: &quot;$amount&quot;}}}，第二个阶段，分组计算，根据cust_id进行分组，对每个组的amount进行求和。这里涉及$group 的语法，如下： 1&#123; $group: &#123; _id: &lt;expression&gt;, &lt;field1&gt;: &#123; &lt;accumulator1&gt; : &lt;expression1&gt; &#125;, ... &#125; &#125; 其中，_id是强制的，后面是可选的。&lt;accumulator1&gt;是累加操作符，参考这里，例如这里的$sum，注意，这里必须要加$。&lt;expression1&gt;是表达式，有待补充， &quot;$amount&quot; , 表示是去取上一个结果中的amount 这个域，对其进行累加，并把结果存入新的域total中。 这个例子看明白了，聚合就基本明白了。 #Map-Reducemap-reduce操作分为两个阶段：map阶段，处理每一条记录，产出一个或多个对象；reduce阶段，合并map阶段的输出。作为可选，map-reduce可以有一个最终阶段来对结果进行最终的操作。map-reduce也可以进行查询、排序和限制输出结果。关于这个例子，还有一些没有看懂，需要等待下一步来补充。 #单一功能的聚合方法MongoDB也提供db.collection.count()（求和）和db.collection.distinct()（去重）函数。 总结关于聚合，总体的概念总结到这里，下一步，需要细化了。 参考https://docs.mongodb.com/manual/aggregation/#single-purpose-agg-operations]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
        <tag>aggregate</tag>
        <tag>聚合</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB：查询和投影操作符]]></title>
    <url>%2Fmongodb%2Fmongodb-collection-find-projection-operator.html</url>
    <content type="text"><![CDATA[MongoDB查询和投影操作符。 官网：https://docs.mongodb.com/manual/reference/operator/query/。 这一章节都是很简单的英语，就做一个很简单的备注，如果连这个英语都看不懂，那就需要提高了，程序员看不懂基本的英语是很难提高的。这一章节还需要完善一些样例，这个有待补充。 查询选择器比较 名字 描述 $eq Matches values that are equal to a specified value.（判断相等） $gt Matches values that are greater than a specified value.（判断大于） $gte Matches values that are greater than or equal to a specified value.（判断大于等于） $in Matches any of the values specified in an array.（判断在其中） $lt Matches values that are less than a specified value.（判断小于） $lte Matches values that are less than or equal to a specified value.（判断小于等于） $ne Matches all values that are not equal to a specified value.（判断所有值都不等于指定值） $nin Matches none of the values specified in an array.（判断不在其中） 逻辑 名字 描述 $and Joins query clauses with a logical AND returns all documents that match the conditions of both clauses.（与） $not Inverts the effect of a query expression and returns documents that do not match the query expression.（非） $nor Joins query clauses with a logical NOR returns all documents that fail to match both clauses.（异或） $or Joins query clauses with a logical OR returns all documents that match the conditions of either clause.（或） 元素 名字 描述 $exists Matches documents that have the specified field. $type Selects documents if a field is of the specified type. 评估 名字 描述 $expr Allows use of aggregation expressions within the query language. $jsonSchema Validate documents against the given JSON Schema. $mod Performs a modulo operation on the value of a field and selects documents with a specified result. $regex Selects documents where values match a specified regular expression. $text Performs text search. $where Matches documents that satisfy a JavaScript expression. 地理空间 名字 描述 $geoIntersects Selects geometries that intersect with a GeoJSON geometry. The 2dsphere index supports $geoIntersects. $geoWithin Selects geometries within a bounding GeoJSON geometry. The 2dsphere and 2d indexes support $geoWithin. $near Returns geospatial objects in proximity to a point. Requires a geospatial index. The 2dsphere and 2d indexes support $near. $nearSphere Returns geospatial objects in proximity to a point on a sphere. Requires a geospatial index. The 2dsphere and 2d indexes support $nearSphere. 数组 名字 描述 $all Matches arrays that contain all elements specified in the query. $elemMatch Selects documents if element in the array field matches all the specified $elemMatch conditions. $size Selects documents if the array field is a specified size. 位操作 名字 描述 $bitsAllClear Matches numeric or binary values in which a set of bit positions all have a value of 0. $bitsAllSet Matches numeric or binary values in which a set of bit positions all have a value of 1. $bitsAnyClear Matches numeric or binary values in which any bit from a set of bit positions has a value of 0. $bitsAnySet Matches numeric or binary values in which any bit from a set of bit positions has a value of 1. 注释 名字 描述 $comment Adds a comment to a query predicate. 投影操作 名字 描述 $ Projects the first element in an array that matches the query condition. $elemMatch Projects the first element in an array that matches the specified $elemMatch condition. $meta Projects the document’s score assigned during $text operation. $slice Limits the number of elements projected from an array. Supports skip and limit slices.]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[MongoDB集合的基本操作：查找记录（查）]]></title>
    <url>%2Fmongodb%2Fmongodb-collection-find-1.html</url>
    <content type="text"><![CDATA[MongoDB集合的基本操作：查找记录（查）。 语法1db.collection.find(query, projection) 在集合或者视图的文档中进行选择，并且返回一个指向被选中的文档的游标。（原文是：Selects documents in a collection or view and returns a cursor to the selected documents.）参数|类型|描述-|-|-query|文档型|可选。使用查询操作符(参考这里)，指定了查询过滤器。 想要返回集合中所有的文档，忽略这个参数，或者传一个空的文档({})。projection|文档型|可选。制定了匹配查询过滤器，要返回的文档的域。想要返回匹配的文档中的所有域，忽略这个参数。 projection参数决定了哪些域需要被返回。 1&#123; field1: &lt;value&gt;, field2: &lt;value&gt; ... &#125; &lt;value&gt;可以是: 1 或 true 表示要在返回文档中包含这个域。 0 或 false 表示不包含这个域。 表达式使用了投影操作符（有待解释）。 分析基本的查找参考上面的语法即可，下面也有实例，其实较为难以掌握的是组合查找，例如逻辑关系是AND的，或者是OR的，还有IN的，这几个需要梳理一下。 实例实例 查找上文test集合中的所有文档。12345678910111213141516171819&gt; db.test.find().pretty()&#123; &quot;_id&quot; : ObjectId(&quot;5abb3b5bce69c048be080199&quot;), &quot;meta&quot; : &#123; &quot;createAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;), &quot;updateAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;) &#125;, &quot;a&quot; : &quot;1&quot;, &quot;b&quot; : &quot;1&quot;&#125;&#123; &quot;_id&quot; : ObjectId(&quot;5abb3b5bce69c048be080120&quot;), &quot;meta&quot; : &#123; &quot;createAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;), &quot;updateAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;) &#125;, &quot;a&quot; : &quot;1&quot;, &quot;b&quot; : &quot;3&quot;&#125; pretty()是用来让展示更加舒适。 实例 查找test集合中的b=&quot;3&quot;的记录，这里要注意“3”和3是不一样的，这里是要符合js的语法，字符串和数字表示方式是不同的。做一个好的程序员，一定要严谨，而做到了严谨，可以帮你更快地提高，更快地产出，更好地规避错误，其实加快了你的职场发展节奏。12345678910&gt; db.test.find(&#123;b: &quot;3&quot;&#125;).pretty()&#123; &quot;_id&quot; : ObjectId(&quot;5abb3b5bce69c048be080120&quot;), &quot;meta&quot; : &#123; &quot;createAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;), &quot;updateAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;) &#125;, &quot;a&quot; : &quot;1&quot;, &quot;b&quot; : &quot;3&quot;&#125; 可以看到，这次只查出了一条符合条件的记录。 实例 查找test集合中的b=&quot;3&quot;的记录a和b两个域，不要其它域。 12&gt; db.test.find(&#123;b: &quot;3&quot;&#125;, &#123;a: 1, b: 1&#125;).pretty()&#123; &quot;_id&quot; : ObjectId(&quot;5abb3b5bce69c048be080120&quot;), &quot;a&quot; : &quot;1&quot;, &quot;b&quot; : &quot;3&quot; &#125; 可以看到，没有涉及的域就没有再获取出来，这样在一些情况下是可以节省网络开销和分析成本的，在《高性能MySQL》也是讲过类似的原理，不要大而全地去把所有内容获取回来，对于资源的使用，应该是有规划的、经济地去使用。 实例 查找test集合中的b=&quot;3&quot; 并且a=&quot;4&quot;的记录。1&gt; db.test.find(&#123;b: &quot;3&quot;, a: &quot;4&quot;&#125;&#125;).pretty() 可以看到，在第一个{} 中逗号分隔开的是AND的查询关系。 实例 查找test集合中的b=&quot;3&quot; 或者b=&quot;4&quot;的记录。1&gt; db.test.find(&#123;b: &#123;$in: [&quot;3&quot;, &quot;4&quot;]&#125;&#125;).pretty() 这个语法的原则是操作符$in在前，作为JSON名值对的名，[&quot;3&quot;, &quot;4&quot;]是它的值，然后整个{$in: [&quot;3&quot;, &quot;4&quot;]}作为b的值，从JSON语法的角度去思考和记忆这个语法，就容易一些了。 实例 修改一下上面的例子，查找test集合中的b=&quot;3&quot; 或者a=&quot;4&quot;的记录。1&gt; db.test.find(&#123;$or: [&#123;b: &quot;3&quot;&#125;, &#123;a: &quot;4&quot;&#125;]&#125;).pretty() 这个语法和IN 的道理是一样的，其实AND也可以这么用，上面那种是隐式的用法，显式的用法是这样：1&gt; db.test.find(&#123;$and: [&#123;b: &quot;3&quot;&#125;, &#123;a: &quot;4&quot;&#125;]&#125;).pretty() 查询操作符还有一些大于、小于等操作，具体参考查询操作符一节。 参考https://docs.mongodb.com/manual/reference/method/db.collection.find/。]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB学习笔记：插入记录（增）]]></title>
    <url>%2Fmongodb%2Fmongodb-collection-insert-1.html</url>
    <content type="text"><![CDATA[完整的MongoDB学习笔记位于IT老兵博客。 MongoDB学习笔记：插入记录（增）。 初衷MongoDB的使用还是有一定难度的，官网讲解的一环牵扯一环，不容易一下子把握住重点，也不利于快速查询操作，所以整理一下，便于快速查找。另外，做一做笔记，对于记忆和理解也是有好处的，同时可以方便一些英语暂时不好的同学用来参考。 语法1233.2版本之后db.collection.insertOne()db.collection.insertMany() 123.2版本之前db.collection.insert() 12345678910111213141516171819202122db.collection.insert( &lt;document or array of documents&gt;, &#123; writeConcern: &lt;document&gt;, ordered: &lt;boolean&gt; &#125;)db.collection.insertOne( &lt;document&gt;, &#123; writeConcern: &lt;document&gt; &#125;)db.collection.insertMany( [ &lt;document 1&gt; , &lt;document 2&gt;, ... ], &#123; writeConcern: &lt;document&gt;, ordered: &lt;boolean&gt; &#125;) 参数 类型 描述 document 文档或者数组 将要插入集合的文档或者文档数组。 writeConcern 文档 可选。待解释和细化。 ordered 布尔型 可选。插入数组时是否要按照顺序，默认为true。 实例：数据库：my_test，之前文章创建的数据库，创建数据库，参看这里。集合：test。插入记录如下： 123456789&#123; &quot;_id&quot; : ObjectId(&quot;5abb3b5bce69c048be080199&quot;), &quot;meta&quot; : &#123; &quot;createAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;), &quot;updateAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;) &#125;, &quot;a&quot; : &quot;1&quot;, &quot;b&quot; : &quot;1&quot;,&#125; 语句： 123456789db.test.insert(&#123; &quot;meta&quot; : &#123; &quot;createAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;), &quot;updateAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;) &#125;, &quot;a&quot; : &quot;1&quot;, &quot;b&quot; : &quot;1&quot;,&#125;)WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;) 看到最后这句，表示插入一条记录成功。馈赠一条，为之后的例子做一个铺垫：123456789db.test.insert(&#123; &quot;meta&quot; : &#123; &quot;createAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;), &quot;updateAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;) &#125;, &quot;a&quot; : &quot;1&quot;, &quot;b&quot; : &quot;3&quot;,&#125;)WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;) 查看一下： 12345678910111213141516171819&gt; db.test.find().pretty()&#123; &quot;_id&quot; : ObjectId(&quot;5abb3b5bce69c048be080199&quot;), &quot;meta&quot; : &#123; &quot;createAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;), &quot;updateAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;) &#125;, &quot;a&quot; : &quot;1&quot;, &quot;b&quot; : &quot;1&quot;&#125;&#123; &quot;_id&quot; : ObjectId(&quot;5abb3b5bce69c048be080120&quot;), &quot;meta&quot; : &#123; &quot;createAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;), &quot;updateAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;) &#125;, &quot;a&quot; : &quot;1&quot;, &quot;b&quot; : &quot;3&quot;&#125; 我们看到了两条记录，查询的语法请参考关于查询的文档。 参考https://docs.mongodb.com/manual/tutorial/insert-documents/。https://docs.mongodb.com/manual/reference/method/db.collection.insert/#db.collection.insert。]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
        <tag>插入</tag>
        <tag>文档</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下shell命令用法及常见用例：touch]]></title>
    <url>%2Flinux%2Fshell-command-touch.html</url>
    <content type="text"><![CDATA[touch命令用来创建文件，也可以更改和修改一个文件的时间戳。 概要touch [选项]... 文件... 描述touch命令用来创建文件，也可以更改和修改一个文件的时间戳。Linux中的每个文件都与时间戳相关联，而且每个文件都存储上次访问时间，上次修改时间，上次更改时间的信息。因为，无论何时创建一个新文件，访问或者修改现有文件，时间戳都会被自动更新。 命令选项Linux中的文件有三个时间： access time（atime）：访问时间，对一次文件的内容就会更新。例如cat，vi/vim，cp，touch命令。 modification time（mtime）：修改时间，对文件内容修改一次就会更新。例如touch，vi/vim命令。 status time（ctime）：状态改动时间。通过chmod/chown/chgrp等命令更改一次文件属性，通过touch准确地修改时间等，这个时间就会更新。例如mv，touch，chmod/chown/chgrp，vi/vim等命令。 touch命令选项： -a，只改变访问时间。 -c，如果文件不存在，那就不创建。 -d，更新访问时间和修改时间。 -m，只改变修改时间。 -r，将参照文件ref_file相应的时间戳作为指定文件file时间戳的新值。 -t，用指定的时间创建文件，格式是[[CC]YY]MMDDhhmm[.SS]。CCYY的范围在1969~2068之内。SS为秒数，范围在0~61之间，这样可以处理闰秒。由于系统的限制，早于1970年1月1日的时间是错误的。 示例：1. 创建空文件描述：若文件不存在，使用touch命令可以轻松地创建一个空文件，或是创建多个。如果文件已存在，那么文件的3个时间：修改时间（mtime）、状态改动时间（ctime）和访问时间（atime）都会被更新为当前时间。stat命令可以查看文件时间。命令：touch my_onestat my_onetouch my_one my_two my_three输出： 示例：2. 只改变文件的修改时间（mtime）和状态改动时间（ctime）描述：只改变my_three文件的修改时间为当前时间，同时状态改动时间会在命令执行后更新为当前时间。这个操作并不需要修改文件内容。-m选项只更改文件的修改时间。命令：touch -m my_three输出： 示例：3. 只改变文件访问时间（atime）和状态改动时间（ctime）描述：只改变my_three文件的访问时间为当前时间，同时状态改动时间会在命令执行后更新为当前时间。如果文件不存在，会创建新的空文件。-a选项只更改文件的访问时间。命令：touch -a my_three输出： 示例：4. 指定文件的访问时间和修改时间描述：同时设置文件的访问时间和修改时间为指定时间，同时会更新状态改变时间为当前命令执行后的时间。如果文件不存在，会创建新的空文件。-d选项同时改变文件的访问时间和修改时间。命令：touch -d &quot;2018-06-14 14:00:00&quot; my_three输出： 描述：将my_three文件的访问时间和修改时间修改成两天前。touch还支持像date命令那样修改文件的时间。命令：touch -d &quot;2 days ago&quot; my_three输出： 示例：5. 避免创建新文件描述：更新atime、ctime、mtime，如果文件不存在，-c选项不会创建新的文件。命令：touch -c leena输出： 示例：6. 使用另一个文件的时间戳描述：-r选项将my_three的时间戳作为my_two文件的时间戳的新值，这两个文件有相同的时间戳。命令：touch -r my_three my_two输出： 示例：7. 使用指定的时间戳创建一个文件描述：将my_four文件的时间戳指定为1997年6月14日17点00分55秒。时间格式是[[CC]YY]MMDDhhmm[.SS]。命令：touch -t 199706141700.55 my_four输出：]]></content>
      <categories>
        <category>Linux</category>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下shell命令用法及常见用例：sed]]></title>
    <url>%2Flinux%2Fshell-command-sed.html</url>
    <content type="text"><![CDATA[sed是stream editor（流式编辑器）的缩写，是一个非交互式的流编辑器，用于过滤或者转换文本。未完待续… 概要sed 选项… [脚本] [输入文件…] 描述sed编辑器被称作流编辑器(stream editor)，和普通的交互式文本编辑器恰好相反。在交互式文本编辑器中(比如vim)，你可以用键盘命令来交互式地插入、删除或替换数据中的文本。流编辑器则会在编辑器处理数据之前基于预先提供的一组规则来编辑数据流。sed编辑器可以根据命令来处理数据流中的数据，这些命令要么从命令行中输入，要么存储在一个命令文本文件中。sed编辑器会执行下列操作。(1) 一次从输入中读取一行数据。(2) 根据所提供的编辑器命令匹配数据。(3) 按照命令修改流中的数据。(4) 将新的数据输出到STDOUT。 在流编辑器将所有命令与一行数据匹配完毕后，它会读取下一行数据并重复这个过程。在流编辑器处理完流中的所有数据行后，它就会终止。 由于命令是按顺序逐行给出的，sed编辑器只需对数据流进行一遍处理就可以完成编辑操作。这使得sed编辑器要比交互式编辑器快得多，你可以快速完成对数据的自动修改。 理解这个命令使用起来有些复杂，复杂在于功能强大，需要逐步消化。 常见用例实例 替换input.txt文件中所有的“hello”为“world”，并且输出到output.txt中。 1sed &apos;s/hello/world/&apos; input.txt &gt; output.txt 这可能是最常用的例子了（至少在我工作这么多年的经验中），这里使用了sed的命令s。如果想输出到原文件的话，使用-i参数。 1sed -i &apos;s/hello/world/&apos; input.txt 这个在mac下表现会不一样，参考：https://blog.csdn.net/cuiaamay/article/details/49495885。 参考：https://www.gnu.org/software/sed/manual/sed.html。]]></content>
      <categories>
        <category>Linux</category>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下shell命令用法及常见用例：awk]]></title>
    <url>%2Flinux%2Fshell-command-awk.html</url>
    <content type="text"><![CDATA[awk命令在文件或字符串中基于指定规则浏览和抽取信息。 命令功能awk是一种小巧的编程语言及命令行工具。（其名称得自于它的创始人Alfred Aho、Peter Weinberger 和 Brian Kernighan姓氏的首个字母）。它非常适合服务器上的日志处理，主要是因为awk可以对文件进行操作，通常以可读文本构建行。awk命令在文件或字符串中基于指定规则浏览和抽取信息。awk抽取信息后，才能进行其他文本操作，awk脚本通常用来格式化文本文件中的信息。 命令格式有三种方式调用awk，第一种是命令行方式，例如：awk [-F field-separator] &#39;commands&#39; input-file(s)awk默认使用空格作为缺省的域分隔符。如果要浏览诸如passwd文件，此文件是以冒号作为分隔符，则必须指明-F选项。例如：awk -F : &#39;commands&#39; input-file第二种方式是将所有awk命令插入一个文件，并使awk程序可执行，然后用awk命令解释器作为脚本的首行，以便通过键入脚本名称来调用它。第三种方式是将所有的awk命令插入一个单独文件，然后调用：awl -f awk-script-file input-file(s)-f选项指明在文件awk-script-file中的awk脚本，input_file(s)是使用awk进行浏览的文件名。 awk脚本代码结构awk脚本的代码结构很简单，就是一系列的模式（pattern）和动作（action）。 12345678# commentPattern1 &#123; ACTIONS; &#125;# commentPattern2 &#123; ACTIONS; &#125;# commentPattern3 &#123; ACTIONS; &#125;# commentPattern4 &#123; ACTIONS; &#125; 扫描文档的每一行时都必须与每一个模式进行匹配比较，一次只匹配一个模式。 12this is line 1this is line 2 this is line 1这行会先Pattern1进行匹配，如果匹配成功，就会执行ACTIONS。然后this is line 1会和Pattern2进行匹配，如果匹配失败，就调到Pattern3进行匹配，以此类推。一旦所有的模式都匹配过了，this is line 2就会以同样的步骤进行匹配。其他的行也一样，直到读取完整个文件。这就是awk的运行模式。 数据类型awk仅有两个主要的数据类型：字符串和数字，它们可以相互转换。在ACTIONS部分使用=操作符给变量赋值，可以在任意时刻、任意地方声明和使用变量，也可以使用未初始化的变量，默认是空字符串。awk有数组类型，并且它们是动态的一维关联数组。 模式模式分为三大类：正则表达式、布尔表达式和特殊模式。 所有模式都是可选的，下面的脚本形式会对输入的每一行都会简单地执行ACRIONS。{ ACTIONS } 特殊的模式模式包括两个特殊字段：BEGIN和END。BEGIN在所有输入未被处理之前，即文本浏览动作之前进行匹配。可以初始化脚本变量和所有种类的状态的主要地方。END会在所有的输入都被处理完后，即完成文本浏览动作后进行匹配。可以在退出前进行清除工作和一些最后的输出。最后一类模式，要把它进行归类有点困难。它处于变量和特殊值之间，我们通常称它们为域（Field）。而且名副其实。 域1234567891011# According to the following line## $1 $2 $3# 00:34:23 GET /foo/bar.html# _____________ _____________/# $0 # Hack attempt?/admin.html$/ &amp;&amp; $2 == &quot;DELETE&quot; &#123;print &quot;Hacker Alert!&quot;;&#125; 域（默认地）由空格分隔。$0域代表了一整行的字符串。$1 域是第一块字符串（在任何空格之前），$2\$域是后一块，以此类推。awk执行时，其浏览域标记为$1, $2, $3…$n。这种方式称为域标识。使用$1, $3标识表示第1和第3域。使用$0$标识表示所有域。awk浏览到一新行时，即到达域的记录末尾，执行新记录下一行的读动作，重新设置域分隔。 动作最常用和最有用的行为： 123456789101112&#123; print $0; &#125; # prints $0. In this case, equivalent to &apos;print&apos; alone&#123; exit; &#125; # ends the program&#123; next; &#125; # skips to the next line of input&#123; a=$1; b=$0 &#125; # variable assignment&#123; c[$1] = $2 &#125; # variable assignment (array) &#123; if (BOOLEAN) &#123; ACTION &#125;else if (BOOLEAN) &#123; ACTION &#125;else &#123; ACTION &#125;&#125;&#123; for (i=1; i&lt;x; i++) &#123; ACTION &#125; &#125;&#123; for (item in c) &#123; ACTION &#125; &#125; awk里的变量都是全局变量。 函数函数的通用文档(regular documentation) 1&#123; somecall($2) &#125; 用户定义的函数： 123456789# function arguments are call-by-valuefunction name (parameter-list) &#123; ACTIONS; #same actions as usual&#125;# return is valid keywordfunction add (val) &#123;return val+1;&#125; 实用命令实例：0. 新建测试文件描述：新建一个device文件，其中(1)为序号，(2)为Android版本，(3)为访问时间，(4)为IP，(5)为访问次数。本文大部分实例根据这一文件进行说明。输出： 实例：1. 抽取域描述：打印第1个（序号）域和第2个（Android版本）域的内容。print用来输出其后跟着的内容，用大括号把print语句括起来，表示一个打印动作。输出： 实例：2. 打印所有记录描述：打印所有记录。$0代表所有域。命令：awk &#39;{print $0}&#39; device输出： 实例：3. 打印报告头描述：在序号和IP地址之间用一些空格使之更容易划分，也可以在域间使用tab键加以划分。本例中加入NO和IP两个信息头以及中划线，\n启动新行，并在\n下一行启动打印文本操作。打印信息头放置在BEGIN模式部分，因为打印信息头被界定为一个动作，必须用大括号括起来。在awk查看第一条记录前，信息头被打印。命令：awk &#39;BEGIN {print &quot;NO IP\n------------------------&quot;} {print $1&quot;\t&quot;$4}&#39; device输出： 实例：4. 打印信息尾描述：在末行加入end of report信息。END语句在所有文本处理动作执行完之后才被执行，在脚本中的位置是在主要动作之后。命令：awk &#39;BEGIN {print &quot;Version\n-------&quot;} {print $2} END {print &quot;end-of-report&quot;}&#39; device输出： 实例：5. 错误信息提示描述：如果将在awk命令中缺少一个双引号，awk将返回错误提示信息。命令：awk &#39;BEGIN {print &quot;Version\n-------&quot;} {print $2} END {print &quot;end-of-report}&#39; device输出： 注意：在碰到awk错误时，应从以下几点进行排查： 确保整个awk命令引用单引号括起来。 确保命令内所有引号成对出现。 确保用花括号括起动作语句，用圆括号括起条件语句。 可能忘记使用花括号。 描述：如果查询的文件不存在，将得到以下错误信息：命令：awk &#39;END {print NR}&#39; device.txt输出： 条件操作符实例：1. 匹配描述：如果field-4以数字4开头，打印它。如果条件满足，则打印匹配的记录行。符号~后紧跟正则表达式，使一域号匹配正则表达式，也可以使用if语句。awk的if后面的条件用()括起来。^尖角符号表示行首。命令：awk &#39;{ if ($4 ~ /^4/) print $0}&#39; device输出： 等同于： 实例：2. 精确匹配描述：精确匹配访问次数为1次的记录，确保不匹配访问次数为15次的记录。使用等号==，并用单引号括起条件，也可以使用if语句。命令：awk &#39;$5==&quot;1&quot; {print $0}&#39; device或者：awk &#39;{if($5==/1/) print $0}&#39; device输出： 实例：3. 不匹配描述：不匹配IP地址以4开头的记录。使用!~表示不匹配。命令：awk &#39;$4 !~ /^4/&#39; device或者：awk &#39;{ if ($4 !~ /^4/) print $0}&#39; device输出： 注意这里不能用!=，因为用引号或者/括起了^4，将只匹配4而不匹配49.65.119.165等。如果查询非49.65.119.165的记录，可做如下操作：awk &#39;$4 != &quot;49.65.119.165&quot;&#39; device 实例：4. 小于，小于等于，大于，大于等于描述：匹配访问次数小于序号的记录。同样的有小于等于（&lt;=），大于（&gt;），大于等于（&gt;=）。命令：awk &#39;$4 !~ /^4/&#39; device或者：awk &#39;{ if ($4 !~ /^4/) print $0}&#39; device输出： 实例：5. 设置大小写描述：匹配含有前面是i或I，后面是OS的记录。[]符号可匹配[]内任意字符或单词。命令：awk &#39;/[iI]OS/&#39; device输出： 实例：6. 任意字符描述：匹配Android版本，第八个字符是7，打印它。表达式/^…….7/表示行首前7个字符任务，第八个是7。命令：awk &#39;$2 ~ /^.......7/&#39; device输出： 实例：7. 或关系匹配描述：匹配IP地址以4或者3开头的记录。竖线符|意为两边模式之一。可以得到与[]表达式相同的结果。命令：awk &#39;$4 ~ /^(4|3)/&#39; device输出： 注意，在使用竖线符时，语句必须用圆括号括起来。另外，除了字符重复出现外，其他的正则表达式在awk中都是合法的。 实例：8. AND 描述：匹配Android版本在7.0以上，并且IP地址以4开头的记录。OR，非与之类似。命令：awk &#39;$2 ~ /^.......7/ &amp;&amp; $4 ~ /^4/&#39; device等同于：awk &#39;{ if ($2 ~ /^.......7/ &amp;&amp; $4 ~ /^4/) print $0} &#39; device输出： awk内置变量awk内置变量如下： 1234567891011BEGIN &#123; # Can be modified by the userFS = &quot;,&quot;; # Field SeparatorRS = &quot;n&quot;; # Record Separator (lines)OFS = &quot; &quot;; # Output Filed SeparatorORS = &quot;n&quot;; # Output Record Separator (lines)&#125;&#123; # Can&apos;t be modified by the userNF # Number of Fileds in the current Record (lines)NR # Number of Records seen so farARGV / ARGC # Script Arguments&#125; NF：支持记录域个数，在记录被读之后再设置。NR：已读的记录数。FILENAME：告知系统目前正在浏览的实际文件，因为awk可以同时处理许多文件。 实例：1. NF、NR、FILENAME 描述：所有记录被打印，并带有记录号（第二和第三列），并在最后输出文件名。使用NF变量显示每一条读记录中有多少个域（5个），使用NR显示已读的记录数，使用FILENAME显示正在处理的文件名。命令：awk &#39;{print NF,NR,$0} END {print FILENAME}&#39; device输出： 实例：2. 判断文件至少有一个记录 描述：先检查文件中至少有一个记录时才查询IP地址。命令：awk &#39;NR &gt; 0 &amp;&amp; $4 ~ /^4/&#39; device输出： 实例：3. 与echo结合使用 描述：将变量$PWD的返回值传入awk并显示其目录。需要指定域分隔符/。命令：echo $PWD | awk -F / &#39;{print $NF}&#39;输出： 描述：显示文件名。命令：echo &quot;/etc/vimrc&quot; | awk -F / &#39;{print $NF}&#39;输出： awk操作符 实例：1. 设置输入域到域变量名描述：赋值IP地址域为ip，版本域为version，查询版本大于7的记录，并打印IP地址和版本信息。命令：awk &#39;{ip=$4;version=$2; if (version ~ /*7*/) print ip&quot;&quot;version}&#39; device输出： 实例：2. 域值比较操作有两种方式测试数值域是否小于另一数值域。 在BEGIN中给变量名赋值。 在关系操作中使用实际数值。 描述：找出访问次数大于10次的所有记录。命令：awk &#39;{if ($5 &gt; 10) print $0}&#39; device输出： 实例：3. 修改数值域的值 当在awk中修改任何域时，实际输入文件是不可修改的，修改的只是保存在缓存里的awk副本，awk会在变量NR或NF变量中反映出修改痕迹。 描述：修改序号为6的记录，将其访问次数减一。命令：awk &#39;{if ($1==6) $5=$5-1; print $1, $2, $5 }&#39; device输出： 实例：4. 修改文本域 描述：修改序号为6的记录，将其版本修改为iOS11.2.3。修改文本域就是对其重新赋值。命令：awk &#39;{if ($1==6) ($2=&quot;iOS11.2.3&quot;); print $1, $2, $5 }&#39; device输出： 实例：5. 只显示修改记录 描述：只显示修改后序号为6的记录。命令：awk &#39;{if ($1==6) {$2=&quot;iOS11.2.3&quot;; print $2}; }&#39; device输出： 实例：6. 创建新的输出域 描述：创建新域6保存目前访问次数大于序号的减法值，表达式为’{$6=$5-$1}’，只打印其值大于零的序号和其新域值。在BEGIN部分加入tab键以对齐报告头。也可以赋给新域更有意义的变量名。命令：awk &#39;BEGIN {print &quot;IP\t Difference&quot;} {if ($5 &gt; $1) {$6=$5-$1; print $1 &quot;\t&quot; $6}}&#39; device输出： 实例：7. 增加列值 描述：使用+=累加访问次数的值。awk的每一个操作匹配时，如果没有说明打印记录，那默认会打印所有记录。命令：awk &#39;(total+=$5); END {print &quot;total visits : &quot; total}&#39; device输出： 实例：8. 文件长度相加 描述：查看当前目录中所有文件的长度及其综合，但要排除子目录，使用ls -l命令，然后管道输出到awk，awk首先剔除首字符d（/^[^d]/）的记录，然后将文件长度相加，并输出每一文件长度及在END部分输出所有文件的长度。命令：ls -l | awk &#39;/^[^d]/ {print $9&quot;\t&quot;$5} {total+=$5} END {print &quot;total KB: &quot; total}&#39;输出： 内置字符串函数 gsub类似于sed查找和替换。它允许替换一个字符串或字符为另一个字符串或字符，并以正则表达式的形式执行，第一个函数作用于记录$0，第二个gsub函数允许指定目标，如果未指定，默认是$0。index(s, t)函数返回目标字符串s中查询字符串t的首位置。length函数返回字符串s字符长度。match函数测试字符串s是否包含一个正则表达式r定义的匹配。split函数使用域分隔符fs，将字符串s划分为指定序列a。sprint函数类似于printf函数，返回基本输出格式fmt的结果字符串exp。sub(r, s)函数将用s代替$0中最左边最长的子串，该子串被（r）匹配。sub(s, p)返回字符串s在位置p后的后缀部分。substr(s, p, n)函数返回字符串s在位置p后长度为n的后缀部分。 实例：1. gsub 描述：匹配记录中访问时间为11:35的记录，修改为11:40。注意要用双引号括起来。命令：awk &#39;gsub(/11:35/, &quot;11:40&quot;) {print $0}&#39; device输出： 实例：2. index描述：匹配字符串Honey中，ney子串第一次出现的位置，即字符个数。命令：awk &#39;BEGIN {print index(&quot;Honey&quot;, &quot;ney&quot;)}&#39;输出： 实例：3. length 描述：匹配序号为6，第二个域的字符长度。也可以直接使用字符串。命令：awk &#39;$1==6 {print length($2) &quot;---&quot; $2}&#39; device输出： 实例：4. match 描述：match测试目标字符串是否包含查找字符的一部分，可以使用正则表达式。命令：在AWK中查找d，因其不存在，所以返回0。awk &#39;BEGIN {print match(&quot;AWK&quot;, /d/)}&#39;在AWK中查找K，因其存在，所有返回AWK中K出现的首位置字符数。awk &#39;BEGIN {print match(&quot;AWK&quot;, /K/)}&#39;在序号为6的记录中，查找Android的大版本号。awk &#39;$1==6 {print match($2, &quot;7&quot;)}&#39; device输出： 实例：5. split 描述：如果域中具有分隔符形式的字符串，使用split函数将其分隔，并保存到一个数组中，最后将数组的第一个元素打印出来。命令：awk &#39;BEGIN {print split(&quot;123#456#789&quot;, myarray, &quot;#&quot;)}&#39;输出： 实例：6. sub 描述：匹配所有Android，替换为android。注意只在模式第一次出现时进行替换操作。命令：awk &#39;sub(/Android/, &quot;android&quot;)&#39; device输出： 实例：7. substr 描述：匹配第二个域版本信息中，打印从第一个字符开始到第七个字符。如果给定的长度值远大于字符串长度，awk将从起始位置返回所有字符。另一种形式是返回字符串后缀或指定位置后面的字符。命令：awk &#39;$1==5 {print substr($2,1,7)}&#39; device输出： 实例：8. 从shell向awk传入字符串命令：使用管道将字符串powerful传入awk，返回其长度。echo &quot;powerful&quot; | awk &#39;{print length($0)}&#39;设置文件名为一变量，管道输出到awk，但会不带扩展名的文件名。STR=&quot;myawk.txt&quot; | echo $STR | awk &#39;{print substr($STR,1,5)}&#39;设置文件名为一变量，管道输出到awk，只返回其扩展名。TR=&quot;myawk.txt&quot; | echo $STR | awk &#39;{print substr($STR,7)}&#39; 输出： 字符转义 printf修饰符基本语法：printf([格式控制符], 参数)格式控制符通常在引号里。 awkprintf修饰符： awk printf格式： 实例：1. 字符转换描述：通过管道输出65到awk中，printf进行ASCII码字符转换。命令：echo &quot;65&quot; | awk &#39;{printf (&quot;%c\n&quot;, $0)}&#39;或者awk &#39;BEGIN {printf &quot;%c\n&quot;, 65}&#39;输出： 描述：数字1024转换为浮点数之后，被加入了六个小数点。命令：awk &#39;BEGIN {printf &quot;%f\n&quot;, 1024}&#39; 输出： 实例：2. 格式化输出 描述：BEGIN后的第一个花括号嵌入头信息，第二个花括号打印所有用户的IP地址和访问时间，要求IP地址左对齐，23个字符长度，后跟访问时间。命令：awk &#39;BEGIN {print &quot;IP\t\t\tTime&quot;} {printf &quot;%-23s %s\n&quot;, $4, $3}&#39; device 输出： 实例：3. 向一行awk命令传值 描述：在命令行中设置VISITS等于10，然后传入awk中，查询访问次数大于10的所有记录。命令：awk &#39;{if($5 &gt; VISITS) print $0} &#39; VISITS=10 device输出： 描述：用管道将df -k传入awk，然后抽出第四列，即剩余可利用空间容量。使用$4 ~ /^[0-9]/取得容量数值，最后对命令行if($4 &lt; TRIGGER)上变量TRIGGER的值进行查询。查看文件系统空间容量，观察其是否达到一定水平。因为要监视的已使用空间容量不断在变化，所以需要再命令行指定一个触发值。命令：df -k | awk &#39;($4 ~ /^[0-9]/) {if ($4 &lt; TRIGGER) printf &quot;%-15s %s\n&quot;,$6,$4}&#39; TRIGGER=930000输出： 描述：打印当前注册用户，并加入一定信息。命令：who | awk &#39;{print $1 &quot; is logged on&quot;}&#39;输出： 描述：传入环境变量LOGNAME，显示当前用户名。命令：who | awk &#39;{if ($1 == user) print $1&quot; you are connected to &quot; $2}&#39; user=$LOGNAME&quot;}&#39;输出： 实例：4. awk脚本文件 描述：第一行#! /usr/bin/awk -f告知脚本系统awk命令的位置。在脚本文件后键入文件名之前，需要先对脚本文件加入可执行权限。命令：chmod u+x user_tot.awkuser_tot.awk脚本文件： 描述：执行user_tot.awk脚本文件。命令：./user_tot.awk device输出： 实例：5. 在awk中使用FS变量 描述：从/etc/passwd文件中抽取第1和第5域，通过FS变量，指定冒号:分隔passwd文件域。第1域时账号名，第5域是账号所有者。命令：chmod u+x passwd.awk | ./passwd.awk /etc/passwd输出： 实例：6. 向awk脚本传值 向awk脚本传值与向awk一行命令传值的方式大体相同，格式为：awk script_file var=value input_file 描述：对比检查文件中域号和指定数字。注意不要忘了增加脚本的可执行权限。命令：chmod u+x fieldcheck.awk | ./fieldcheck.awk MAX=7 FS=&quot;:&quot; /etc/passwd输出： 描述：从du命令获得输入，并输出块和字节数。命令：chmod u+x duawk.awk | du /root | ./duawk.awk输出： 实例：9. awk数组 描述：用split将123#456#789划分开，并存入myarray数组，再使用循环打印各数组元素。命令：chmod u+x duawk.awk | du /root | ./duawk.awk输出： 实例：10. 处理由通配符指定的多个文件名 描述：打印当前目录中以.txt结尾的文件。nextfile告诉awk停止处理当前的输入文件。下一个输入记录读取来自下一个输入文件。命令：awk &#39;{ print FILENAME; nextfile } &#39; *.txtawk &#39;BEGIN{ print &quot;Starting...&quot;} { print FILENAME; nextfile }END{ print &quot;....DONE&quot;} &#39; *.txt输出：]]></content>
      <categories>
        <category>Linux</category>
        <category>Shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB学习笔记：创建数据集合]]></title>
    <url>%2Fmongodb%2Fmongodb-collection-create.html</url>
    <content type="text"><![CDATA[完整的MongoDB学习笔记位于IT老兵博客。 MongoDB如何创建数据集合（collection）。 前言本篇文章整理一下MongoDB如何创建数据集合。 正文这节有点混乱，也有点尴尬，因为原本MongoDB就有些“没有规矩”。 关于快速创建一个集合，需要参考插入这一节，因为如果集合不存在的情况下，插入一条记录就会创建集合，这是非常方面的一种操作。 再举个例子，如下： 12345678910db.test.insert(&#123; &quot;_id&quot; : ObjectId(&quot;5abb3b5bce69c048be080199&quot;), &quot;meta&quot; : &#123; &quot;createAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;), &quot;updateAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;) &#125;, &quot;a&quot; : &quot;1&quot;, &quot;b&quot; : &quot;1&quot;,&#125;)WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;) 这样即会创建集合test，又会给这个集合插入一条记录。 如果非要规矩地创建（其实是可以设置一些选项），那么： 12345678910111213db.createCollection(&lt;name&gt;, &#123; capped: &lt;boolean&gt;, autoIndexId: &lt;boolean&gt;, size: &lt;number&gt;, max: &lt;number&gt;, storageEngine: &lt;document&gt;, validator: &lt;document&gt;, validationLevel: &lt;string&gt;, validationAction: &lt;string&gt;, indexOptionDefaults: &lt;document&gt;, viewOn: &lt;string&gt;, pipeline: &lt;pipeline&gt;, collation: &lt;document&gt;, writeConcern: &lt;document&gt;&#125; ) 参数 类型 描述 name 字符串 要创建的集合的名称。 options 文档 可选。一大堆选项，暂时没用到，将来再补充了。 参考https://docs.mongodb.com/manual/reference/method/db.createCollection/#db.createCollection。]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
        <tag>collection</tag>
        <tag>数据集合</tag>
        <tag>创建</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB学习笔记：创建数据库]]></title>
    <url>%2Fmongodb%2Fmongodb-database-create.html</url>
    <content type="text"><![CDATA[MongoDB如何创建数据库。 前言 初衷：MongoDB的使用还是有一定难度的，官网讲解的一环牵扯一环，不容易一下子把握住重点，也不利于快速查询操作，所以整理一下。 这是之前写这篇笔记的初衷，现在发生了一些修改，现在本篇文章是作为MongoDB学习笔记的一部分，但也可以作为独立的一个MongoDB知识点学习的笔记。 本篇文章整理一下MongoDB如何创建数据库。 正文进入mongo shell（关于mongo shell，需要先安装并且启动好MongoDB）： 1234root@iZhp3fz3iqsadyes2s8ayeZ:~# mongoMongoDB shell version: 2.6.10connecting to: test...... 如果没有mongo这个命令，表示路径没有配置好。上面的显示表示这个MongoDB的版本是2.6.10，进入数据库后，默认会进入到test库。 使用以下的操作就可以切换数据库，如果数据库不存在，且会创建一个新的数据库：1use &lt;database&gt; 尖括号表示需要你替换的变量，就是你的数据库名称，关于数据库名称是有一些限制的，可以去查一下。 如果数据库存在，这条命令会切换到该数据库，如果不存在，则创建并切换到该数据库。 实例：创建一个数据库，名字为my_test。 12use my_testswitched to db my_test 这样，创建成功一个数据库，这种操作要比MySQL的创建数据库容易很多。 参考https://docs.mongodb.com/manual/core/databases-and-collections/]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
        <tag>database</tag>
        <tag>create</tag>
        <tag>创建数据库</tag>
      </tags>
  </entry>
</search>
