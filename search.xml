<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[JS：NPM依赖包版本号波浪字符"~"]]></title>
    <url>%2Fjs%2Fjs-npm-symbol-tilde.html</url>
    <content type="text"><![CDATA[JS：NPM依赖包版本号波浪字符”~”。 参考官网：https://github.com/npm/node-semver#functions。 Tilde Ranges ~1.2.3 ~1.2 ~1Allows patch-level changes if a minor version is specified on the comparator. Allows minor-level changes if not. 如果minor被指定，则允许patch被改变；如果没有，允许minor被改变。 ~1.2.3 := &gt;=1.2.3 &lt;1.(2+1).0 := &gt;=1.2.3 &lt;1.3.0~1.2 := &gt;=1.2.0 &lt;1.(2+1).0 := &gt;=1.2.0 &lt;1.3.0 (Same as 1.2.x)~1 := &gt;=1.0.0 &lt;(1+1).0.0 := &gt;=1.0.0 &lt;2.0.0 (Same as 1.x)~0.2.3 := &gt;=0.2.3 &lt;0.(2+1).0 := &gt;=0.2.3 &lt;0.3.0~0.2 := &gt;=0.2.0 &lt;0.(2+1).0 := &gt;=0.2.0 &lt;0.3.0 (Same as 0.2.x)~0 := &gt;=0.0.0 &lt;(0+1).0.0 := &gt;=0.0.0 &lt;1.0.0 (Same as 0.x)~1.2.3-beta.2 := &gt;=1.2.3-beta.2 &lt;1.3.0 Note that prereleases in the 1.2.3 version will be allowed, if they are greater than or equal to beta.2. So, 1.2.3-beta.4 would be allowed, but 1.2.4-beta.2 would not, because it is a prerelease of a different [major, minor, patch] tuple.]]></content>
      <categories>
        <category>js</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[JS：NPM依赖包版本号脱字符"^"]]></title>
    <url>%2Fjs%2Fjs-npm-symbol-caret.html</url>
    <content type="text"><![CDATA[JS：NPM依赖包版本号脱字符”^”。 参考官网：https://github.com/npm/node-semver#functions。 Caret Ranges ^1.2.3 ^0.2.5 ^0.0.4Allows changes that do not modify the left-most non-zero digit in the [major, minor, patch] tuple. In other words, this allows patch and minor updates for versions 1.0.0 and above, patch updates for versions 0.X &gt;=0.1.0, and no updates for versions 0.0.X.Many authors treat a 0.x version as if the x were the major “breaking-change” indicator. 大概意思是：允许的改变不能发生在最左侧非零的数字上，NPM采用的是3元组的版本控制，[major，minor，patch]。换句话说，对于版本1.0.0，允许变更的是minor和patch，对于0.X的，patch可以变更，而对于0.0.X，啥都不能变了。 Caret ranges are ideal when an author may make breaking changes between 0.2.4 and 0.3.0 releases, which is a common practice. However, it presumes that there will not be breaking changes between 0.2.4 and 0.2.5. It allows for changes that are presumed to be additive (but non-breaking), according to commonly observed practices. “^”这个符号叫做脱字符（caret），这好像是原来打字机的一个功能，现在叫这个名字感觉是有些陌生的。以下是一些例子，感觉也没有太多可讲的。 ^1.2.3 := &gt;=1.2.3 &lt;2.0.0 ^0.2.3 := &gt;=0.2.3 &lt;0.3.0 ^0.0.3 := &gt;=0.0.3 &lt;0.0.4 ^1.2.3-beta.2 := &gt;=1.2.3-beta.2 &lt;2.0.0 Note that prereleases in the 1.2.3 version will be allowed, if they are greater than or equal to beta.2. So, 1.2.3-beta.4 would be allowed, but 1.2.4-beta.2 would not, because it is a prerelease of a different [major, minor, patch] tuple. ^0.0.3-beta := &gt;=0.0.3-beta &lt;0.0.4 Note that prereleases in the 0.0.3 version only will be allowed, if they are greater than or equal to beta. So, 0.0.3-pr.2 would be allowed. When parsing caret ranges, a missing patch value desugars to the number 0, but will allow flexibility within that value, even if the major and minor versions are both 0. ^1.2.x := &gt;=1.2.0 &lt;2.0.0 ^0.0.x := &gt;=0.0.0 &lt;0.1.0 ^0.0 := &gt;=0.0.0 &lt;0.1.0 A missing minor and patch values will desugar to zero, but also allow flexibility within those values, even if the major version is zero. ^1.x := &gt;=1.0.0 &lt;2.0.0 ^0.x := &gt;=0.0.0 &lt;1.0.0]]></content>
      <categories>
        <category>js</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Linux下shell命令用法及常见用例：tar]]></title>
    <url>%2Flinux%2Fshell-command-tar.html</url>
    <content type="text"><![CDATA[tar命令用来归档多个文件或目录到单个归档文件中，并且归档文件可以进一步使用gzip或者bzip2等技术进行压缩。 命令格式tar [OPTION...] [FILE]... 命令功能Tar（Tape ARchive，磁带归档的缩写，最初设计用于将文件打包到磁带上，现在大都使用它来实现备份某个分区或者某些重要的目录）是类Unix系统中使用最广泛的命令，用于归档多个文件或目录到单个归档文件中，并且归档文件可以进一步使用gzip或者bzip2等技术进行压缩，还能保留其文件权限。换言之，tar命令也可以用于备份：先是归档多个文件和目录到一个单独的tar文件或归档文件，然后在需要之时将tar文件中的文件和目录释放出来。 命令选项 选项 含义 -A或–catenate 新增文件到以存在的备份文件 -B 设置区块大小 -c或–create 建立新的备份文件 -C&lt;目录&gt; 这个选项用在解压缩，若要在特定目录解压缩，可以使用这个选项 -d 记录文件的差别 -x或–extract或–get 从备份文件中还原文件 -t或–list 列出备份文件的内容 -z或–gzip或–ungzip 通过gzip指令处理备份文件 -Z或–compress或–uncompress 通过compress指令处理备份文件 -f&lt;备份文件&gt;或–file=&lt;备份文件&gt; 指定备份文件 -v或–verbose 显示指令执行过程 -r 添加文件到已经压缩的文件 -u 添加改变了和现有的文件到已经存在的压缩文件 -j 支持bzip2解压文件 -v 显示操作过程 -l 文件系统边界设置 -k 保留原有文件不覆盖 -m 保留文件不被覆盖 -w 确认压缩文件的正确性 -p或–same-permissions 用原来的文件权限还原文件 -P或–absolute-names 文件名使用绝对名称，不移除文件名称前的“/”号 -N &lt;日期格式&gt;或–newer=&lt;日期时间&gt;只将较指定日期更新的文件保存到备份文件里 –exclude=&lt;范本样式&gt; 排除符合范本样式的文件 什么是“文件压缩”？我们知道，在计算机系统中文件的内容是信息，信息实际上就是一个由值0和值1组成的位（又称为比特）序列，8个位被组织成一组，称为字节。一般来说，一个字节的8位是没有被全部利用起来的，这些没有被利用的位占据了一个文件的大部分空间，而“文件压缩”就是利用复杂的计算方式，将这些没有利用的空间腾出来，以让文件占用的空间变小。 简单来说，「压缩」就是把文件中没有完全填满的空间填满。压缩过的文件不能直接被操作系统所使用，因此，「解压缩」就是指把文件「还原」为未压缩之前的模样。压缩前与压缩后的文件所占用的磁盘空间大小之比就是「压缩比」。 常见的压缩格式Linux 中常见的压缩格式有： 123456*.Z：compress 程序压缩的文件。*.gz：gzip 程序压缩的文件。*.bz2：bzip2 程序压缩的文件。*.tar：tar 程序打包的数据，没有被压缩过。*.tar.gz（简写为 .tgz）：tar 程序打包的数据，经过 gzip 的压缩。*.tar.bz2（简写为 .tbz2）：tar 程序打包的数据，经过 bzip2 的压缩。 上面的压缩格式中，主要是gzip和bzip2两个压缩命令，它们是GNU计划的中的一部分，在此之前是compress命令，但它已经不再流行了。bzip2比gzip的压缩比很好，不过bzip2通常只能针对一个文件来压缩和解压缩。如果是这样的话，压缩整个开发环境目录就太繁琐了。 因此tar命令就出现了，tar不是一个 “压缩命令”，而是一个“打包命令”。也就是说，tar可以把很多文件「打包」成一个文件，甚至连目录也可以进行打包。一开始tar命令的确是不支持压缩的功能，后来GNU计划为了提供给使用者更方便并且更加强大的压缩与打包功能，就把整个tar与压缩的功能结合在一起了。 仅仅打包起来的tar文件俗称tarfile文件，经过压缩的tar文件叫做tarball文件。 全能的 tar 命令概要tar可以将多个目录或文件打成一个大文件，同时支持gzip/bzip2 归档：tar {-c} [option…] -f destination source追加归档：tar {-r | -u} -f source [option…] destination解压：tar {-t | -x} -f source [option…] -C destination 最简单的使用 tar 只要记住下面的方式： 压缩：tar -jcv -f filename.tar.bz2 被压缩的文件或目录名称 查看文件：tar -jtv -f filename.tar.bz2 解压缩：tar -jxv -f filename.tar.gz -C 解压到哪里 filename.tar.bz2 既然tar不是一个压缩命令，是个打包命令，那么是如何做到打包并压缩的呢？我们先来看一下tar命令的常用参数： 模式参数 -c（–create）：创建新的归档文件。 -r（–append）：与-c一样创建新的归档文件，但这是以追加的模式，只能往未压缩过的归档文件中追加，要求指定-f参数。 -t：查看归档文件的内容含有哪些文件，可以看到包括文件名在内的详细信息。 -u：与-r一样，但是只往归档文件添加更新的文件。 -x：解压缩归档文件。如果一个归档文件里有相同文件名的多个文件，那么会先将每个文件解压，最新的文件将覆盖旧的文件。 tar分为三种模式，-c，-r，-u三个一类，为归档/压缩模式，在该模式下，tar会递归遍历指定目录下的所有目录和文件，并创建归档文件。-x表示为去归档/解压模式，-t表示为打印列表模式。 通用参数 -j：使用bzip2的支持进行压缩和解压缩，文件名最好为*.tar.bz2。 -z：使用gzip的支持进行压缩和解压缩，文件名最好为*.tar.gz。 -v：在压缩/解压缩的过程中，将正在处理的文件名显示出来。 -f：后面接被处理的文件名，最好把-f单独出来写一个参数。 -C：指定解压的目录。 -p：保留文件的原始信息，权限等等 -P：解压时保留绝对路径。 –exclude=FILE：在打包压缩的时候，不要将FILE打包。 打包并创建归档文件示例：打包一个目录。描述：将/home/test这个目录打包，生成文件名为command-18-06-02.tar的归档文件，保存在当前目录下。123456# tar -cv -f command-18-06-02.tar /home/test/home/test/.bash_logout/home/test/.bashrc/home/test/apache-tomcat-9.0.7.tar.gz/home/test/.bash_profile/home/test/nginx-1.10.1.tar.gz -c（–create的简写）参数，这表示为指定的文件或者目录创建新的归档文件。使用-f指定读取或者写入的归档文件，可以用-表示标准输入或者标准输出，-f可以与其他参数连起来写，必须保证f参数后面跟的是文件名。但不推荐这样写，因为参数调换顺序是允许的，如果写成-cfv就会导致压缩后的文件名变成了v。 使用-v表示生成详细的输出，在压缩或者解压的模式中，会列出正在向归档文件读或者写的文件名字。 创建tar.gz归档文件示例：打包并且使用gzip压缩。描述：将/home/test/images目录下的所有文件以及目录中的文件打包，并用gzip进行压缩，生成名为MyImages-18-06-02.tar.gz的归档文件，放在当前目录下。 12345678# tar -zcv -f MyImages-18-06-02.tar.gz /home/test/imagesOR# tar -zcv -f MyImages-18-06-02.tar.tgz /home/test/images/home/test/images/alejandro-gonzalez-17189.jpg/home/test/images/brooke-lark-275181.jpg/home/test/images/brenda-godinez-228181.jpg/home/test/images/artur-rutkowski-97622.jpg/home/test/images/ben-white-138743.jpg -z表示要使用gzip支持来压缩或者解压文件，注意gzip的压缩的文件格式最好写成tar.gz。（注：tar.gz 和 tgz 是同一个意思） 打包压缩排除某些文件示例：打包压缩并排除某些文件。描述：将/home/test/images目录下，排除brooke-lark-275181.jpg和ben-white-138743.jpg之外的所有文件打包，并用gzip进行压缩，生成名为MyImages-18-06-02.tar.gz的归档文件，放在当前目录下。 1234# tar -czv -f MyImages-18-06-02.tar.gz --exclude=./brooke-lark-275181.jpg --exclude=./ben-white-138743.jpg /home/test/images/home/test/images/alejandro-gonzalez-17189.jpg/home/test/images/brenda-godinez-228181.jpg/home/test/images/artur-rutkowski-97622.jpg 解压归档文件（默认）示例：解压，默认解压。描述：将名为MyImages-18-06-02.tar的归档文件解压至当前目录下。 1234# tar -xvf MyImages-18-06-02.tarhome/test/images/alejandro-gonzalez-17189.jpghome/test/images/brenda-godinez-228181.jpghome/test/images/artur-rutkowski-97622.jpg 其中，-x参数表示去解压一个归档文件，如果归档文件中有两个相同名字的文件，那么每一个文件都会被解压出来，然后最新的会覆盖旧的文件。注意这里没有指定-j参数，因为tar看到指定了-x参数，就知道这是解压操作，会自动判断该解压包的压缩类型。 解压归档文件并指定目录示例：解压到一个指定目录。描述：将名为MyImages-18-06-02.tar.gz的归档文件解压至一个指定的目录。 1234# tar -xv -f MyImages-18-06-02.tar -C /home/test/public_imageshome/test/public_images/alejandro-gonzalez-17189.jpghome/test/public_images/brenda-godinez-228181.jpghome/test/public_images/artur-rutkowski-97622.jpg 查看压缩包文件信息示例：查看压缩包文件信息。描述：列出MyImages-18-06-02.tar.bz2中的文件信息，-v参数，会生成与ls(1)命令相近的输出。 123456# tar -tv -f MyImages-18-06-02.tar.gzOR# tar -tv -f MyImages-18-06-02.tar.bz2-rw-r--r-- root/root 2176861 2018-06-02 21:26 home/test/images/alejandro-gonzalez-17189.jpg-rw-r--r-- root/root 8452524 2018-06-02 21:26 home/test/images/brenda-godinez-228181.jpg-rw-r--r-- root/root 1131986 2018-06-02 21:26 home/test/images/artur-rutkowski-97622.jpg 解压单个文件示例：解压单个文件。描述：将home/test/.bashrc这一个文件从归档文件中提取出来。 12# tar -xv -f command-18-06-02.tar home/test/.bashrchome/test/.bashrc 解压多个指定的文件示例：解压多个指定的文件。描述：将file1、file2等多个文件从归档文件中提取出来，可以用空格隔开多个文件，也可以用通配符的形式。 1234567# tar -zxv -f MyImages-18-06-02.tar.gz "file 1" "file 2"OR# tar -zxv -f MyImages-18-06-02.tar.gz --wildcards '*b*.jpg'home/test/images/brooke-lark-275181.jpghome/test/images/brenda-godinez-228181.jpghome/test/images/ben-white-138743.jpghome/test/images/aleks-dahlberg-274646.jpg]]></content>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[CSS：文档流]]></title>
    <url>%2Fcss%2Fcss-normal-flow.html</url>
    <content type="text"><![CDATA[CSS的文档流介绍。 官网：https://www.w3.org/TR/2016/WD-CSS22-20160412/visuren.html#normal-flow。 文档流文档流其实应该叫正常流，英文是Normal flow，我的理解呢，就是接收到的文档的内容，因为这些内容一直从服务端传输过来，边传输边需要处理，就像水流一样，所以称为流。 在文档流中的盒子是需要归属于一个上下文的，块级盒子参与到块格式化上下文中，内联级盒子参与到内联格式化上下文中，还有表格格式化上下文。 块格式化上下文（Block formatting contexts）块格式化上下文，简称BFC，是按照从上到下，一个一个垂直排列的，块之间的间距是靠margin来控制的。 In a block formatting context, boxes are laid out one after the other, vertically, beginning at the top of a containing block. The vertical distance between two sibling boxes is determined by the ‘margin’ properties. Vertical margins between adjacent block-level boxes in a block formatting context collapse. 翻译：在块格式化上下文中，框从一个包含块的顶部开始一个接一个地垂直排列。 两个兄弟盒子之间的垂直距离由“margin”属性决定。 块格式化上下文中相邻块级盒子之间的垂直margin会折叠。 ##内联格式化上下文（Inline formatting contexts）内联格式化上下文，简称IFC，主要是水平排列的，水平对齐是由一些参数来控制的。 An inline formatting context is established by a block container box that contains no block-level boxes. In an inline formatting context, boxes are laid out horizontally, one after the other, beginning at the top of a containing block. Horizontal margins, borders, and padding are respected between these boxes. The boxes may be aligned vertically in different ways: their bottoms or tops may be aligned, or the baselines of text within them may be aligned. The rectangular area that contains the boxes that form a line is called a line box. 翻译：内联格式化上下文由不包含块级框的块容器盒子建立。 在内联格式化上下文中，盒子从一个接一个地开始，从一个包含块的顶部开始。 这些框之间会考虑水平边距，边框和填充。 盒子可以以不同的方式垂直对齐：它们的底部或顶部可以对齐，或者它们内的文本的基线可以对齐。 包含形成一条线的框的矩形区域称为线盒子line box。 这里面有一些父容器和子布局的一些关系，需要梳理。 相对定位相对定位是根据这个盒子原本在文档流中的位置或者floated进行一些偏移。 未完，待续……]]></content>
      <categories>
        <category>CSS</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Java：Tomcat的部署实例之资源目录]]></title>
    <url>%2Fjava%2Fjava-deploy-resource-folder.html</url>
    <content type="text"><![CDATA[Tomcat上部署应用后，原本目录是否会被移除。 实例：一个项目的资源放在了WebContent下面，这样每次打包，都会将这些文件打包进去，这样在打包时，导致打出来的war包有好几百兆，这样上传Git也非常不方便。 方案1：分析：如果删除掉本地WebContent下的资源文件，再部署到服务器上，war包其实是一个压缩包，加压后覆盖原本目录下的相同内容，因为新上传的war包没有相同的资源文件，这样就不会覆盖原本的资源文件。结果：加压后的项目目录也不存在资源文件了，看来这个部署过程，是会删掉原本的项目目录的。 方案2：分析：因为webapps是web服务根目录，那么把资源文件从项目目录移到webapps下面，这样应该也可以被访问到。结果：成功，可以被访问到。 为了验证这个，上网查了很多帖子，众说纷纭，最后还是在官网找到这么一段话： The following deployment sequence will occur on Tomcat startup in that case: Any Context Descriptors will be deployed first. Exploded web applications not referenced by any Context Descriptor will then be deployed. If they have an associated .WAR file in the appBase and it is newer than the exploded web application, the exploded directory will be removed and the webapp will be redeployed from the .WAR .WAR files will be deployed 注意这里the exploded directory will be removed and the webapp will be redeployed from the .WAR，原本的解压目录会被移除，应用会被重新从war文件中部署。 寻根究底，而不人云亦云，这样才是端正的学习的态度。]]></content>
      <categories>
        <category>Java</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Git：工作流程Git Flow]]></title>
    <url>%2Fgit%2Fgit-git-flow.html</url>
    <content type="text"><![CDATA[Git的工作流程Git Flow介绍。 前言参考：https://nvie.com/posts/a-successful-git-branching-model/， 这篇帖子是10年发表的，而我大概是08、09年接触的Git，当时因为刚刚花了好大气力研究明白SVN的流程，所以对Git很排斥，这也是我工作中一直以来的一个问题，因为在一项老技术上花了太多气力，而导致对新技术的出现本能地产生很大的排斥。如果当时仔细去研究一下Git，应该会发现Git不是来革我们这些SVN拥趸的命，而是提供完善和丰富了SVN的功能。 概述从CVS到SVN，再从SVN到Git。从中心化到去中心化的中心化（Decentralized but centralized），这句话挺有挺有深意。 分支长期分支项目存在两个长期分支： 主分支master。 开发分支develop或者dev。 We consider origin/master to be the main branch where the source code of HEAD always reflects a production-ready state.We consider origin/develop to be the main branch where the source code of HEAD always reflects a state with the latest delivered development changes for the next release. Some would call this the “integration branch”. This is where any automatic nightly builds are built from. 这里的HEAD是Git的一个指针，指向当前的分支上。上面的话的意思大概是master分支总是指向“等待上生产”状态的代码。develop分支往往是最近交付的开发修改。这个过程是和原本的SVN工作流是很接近的，一个开发分支，一个线上分支。开发完，测试后，发布到线上。SVN流程推荐在测试时分叉一个branch出来进行测试，这个时候不影响trunk上业务的继续开发，这个工作流没有这么明说，但是因为Git的灵活性，建立一个临时的测试分支也是没有问题的。Git好就好在非常灵活，不过也正是因为如此，导致了一些问题，之前有一个小朋友，把所有的功能分支都保存了下来，还说这样会更加方便，我很难理解，这样怎么会方便呢？每个人分支都需要不断同步。灵活也应该是相对的，在一个相对固定的流程下，适当的灵活，是可以提高效率的。 支持分支原文叫做supporting branches。这里面的每一个分支都有指定的目的和约束的规则，如何产生和如何合并。 Feature branches Release branches Hotfix branches 功能分支可以产生于:develop必须合并到:develop分支命名约定:除了master, develop, release-, or hotfix- 都可以，前面几个作为保留。 功能分支用于开发未来的一项功能，目标的发布此时可能还不确定。这个分支最终会被合并回develop（采用了）或者被抛弃掉（不采用）。功能分支更多存在于用户仓库，而不是origin仓库。 创建：12$ git checkout -b myfeature developSwitched to a new branch &quot;myfeature&quot; 合并回develop： 12345678$ git checkout developSwitched to branch &apos;develop&apos;$ git merge --no-ff myfeatureUpdating ea1b82a..05e9557(Summary of changes)$ git branch -d myfeatureDeleted branch myfeature (was 05e9557).$ git push origin develop 对于–no-ff，参考：https://git-scm.com/docs/git-merge，有待更进一步的解释。 发布分支可以产生于:develop必须合并到:develop和master分支分支命名约定:release-* 我理解的，这里主要用于准备一个发布版的功能已经开发完成，等待一些信息最后的确认，为了不影响下一个开发版的正常进行，打出一个发布分支。 创建一个发布分支1234567$ git checkout -b release-1.2 developSwitched to a new branch &quot;release-1.2&quot;$ ./bump-version.sh 1.2Files modified successfully, version bumped to 1.2.$ git commit -a -m &quot;Bumped version number to 1.2&quot;[release-1.2 74d9424] Bumped version number to 1.21 files changed, 1 insertions(+), 1 deletions(-) 结束一个发布分支合并回master分支123456$ git checkout masterSwitched to branch &apos;master&apos;$ git merge --no-ff release-1.2Merge made by recursive.(Summary of changes)$ git tag -a 1.2 合并回develop分支12345$ git checkout developSwitched to branch &apos;develop&apos;$ git merge --no-ff release-1.2Merge made by recursive.(Summary of changes) 删除原分支12$ git branch -d release-1.2Deleted branch release-1.2 (was ff452fe). 热修复分支可以产生于:master必须合并到:develop和master分支分支命名约定:hotfix-* 主要用于对线上代码进行热修复用，线上代码出现了问题，开出一个分支进行修复，等修复完成，合并回master和develop分支。 创建 1234567$ git checkout -b hotfix-1.2.1 masterSwitched to a new branch &quot;hotfix-1.2.1&quot;$ ./bump-version.sh 1.2.1Files modified successfully, version bumped to 1.2.1.$ git commit -a -m &quot;Bumped version number to 1.2.1&quot;[hotfix-1.2.1 41e61bb] Bumped version number to 1.2.11 files changed, 1 insertions(+), 1 deletions(-) 提交 123$ git commit -m &quot;Fixed severe production problem&quot;[hotfix-1.2.1 abbe5d6] Fixed severe production problem5 files changed, 32 insertions(+), 17 deletions(-) 结束合并回master123456$ git checkout masterSwitched to branch &apos;master&apos;$ git merge --no-ff hotfix-1.2.1Merge made by recursive.(Summary of changes)$ git tag -a 1.2.1 合并回develop12345$ git checkout developSwitched to branch &apos;develop&apos;$ git merge --no-ff hotfix-1.2.1Merge made by recursive.(Summary of changes) 删除 12$ git branch -d hotfix-1.2.1Deleted branch hotfix-1.2.1 (was abbe5d6).]]></content>
      <categories>
        <category>Git</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Linux下shell命令用法及常见用例：netstat]]></title>
    <url>%2Flinux%2Fshell-command-netstat.html</url>
    <content type="text"><![CDATA[netstat命令用来查看系统中所有的网络套接字连接情况。 命令格式netstat [选项] 参考：https://linux.die.net/man/8/netstat。 netstat命令用来查看系统中所有的网络套接字连接情况。 命令格式netstat [选项] 参考：https://linux.die.net/man/8/netstat。 netstat命令用来查看系统中所有的网络套接字连接情况。 命令格式netstat [选项] 命令功能netstat命令用来查看系统中所有的网络套接字连接情况，包括TCP、UDP和Unix套接字。也可以显示路由表，接口状态，masquerade 连接，多播成员（Multicast Memberships）等等。另外，它还可以列出处于监听状态（等待接入请求）的套接字，比如想确认系统中的web服务是否起来，就可以查看80端口有没有打开。 命令参数 -a或–all：显示所有选项，默认不显示LISTEN相关。 -t或–tcp：(TCP)仅显示TCP相关选项。 -u或–udp：(UDP)仅显示UDP相关选项。 -x或–unix：此参数的效果和指定”-A unix”参数相同。 -n或–numeric：拒绝显示别名，能显示数字的全部转化成数字。 -l或–listening：仅列出有在Listen(监听)的服务状态。 -g或–groups：显示多重广播功能群组组员名单。 -p或–programs：显示建立相关链接的程序名和PID。 -r或–route：显示路由信息，路由表。 -e或–extend：显示扩展信息，例如UID等。 -s或–statistics：按各个协议进行统计。 -c或–continuous：每隔一个固定时间，执行该netstat命令。 -g或–groups：显示多重广播功能群组组员名单。 提示：LISTEN和LISTENING的状态只有用-a或者-l才能看到。 输出信息含义netstat的输出结构可以分为两个部分：一个是Active Internet connections，称为有源TCP连接。其中”Recv-Q”和”Send-Q”指的是接收队列和发送队列。123456Active Internet connections (w/o servers)Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 VM01.root:ssh 61.149.11.230:21859 ESTABLISHEDtcp 0 0 localhost:51476 localhost:27017 ESTABLISHEDtcp 0 0 VM01.root:ssh 61.149.11.230:50883 ESTABLISHEDtcp 0 0 VM01.root:58300 47.89.193.173:3666 ESTABLISHED 另一个是Active UNIX domain sockets，称为有源Unix域套接口(和网络套接字一样，但是只能用于本机通信，性能可以提高一倍)。Proto显示连接使用的协议，RefCnt表示连接到本套接口上的进程号，Types显示套接口的类型，State显示套接口当前的状态，Path表示连接到套接口的其它进程使用的路径名。 1234567Active UNIX domain sockets (w/o servers)Proto RefCnt Flags Type State I-Node Pathunix 2 [ ] DGRAM 15049 /run/user/0/systemd/notifyunix 3 [ ] DGRAM 13640 /run/systemd/notifyunix 2 [ ] DGRAM 13645 /run/systemd/journal/syslogunix 8 [ ] DGRAM 13660 /run/systemd/journal/socketunix 25 [ ] DGRAM 10467 /run/systemd/journal/dev-log 实例实例：列出当前所有的连接（-a）命令：netstat -a输出： 12345678root@iZhp3fz3iqsadyes2s8ayeZ:~# netstat -aActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 *:8838 *:* LISTEN tcp 0 0 localhost:27017 *:* LISTEN tcp 0 0 *:8330 *:* LISTEN tcp 0 0 localhost:submission *:* LISTEN ...... 实例：列出所有TCP端口（-t）命令：netstat -at输出： 1234567root@iZhp3fz3iqsadyes2s8ayeZ:~# netstat -atActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 *:8838 *:* LISTEN tcp 0 0 localhost:27017 *:* LISTEN tcp 0 0 *:8330 *:* LISTEN tcp 0 0 localhost:submission *:* LISTEN 示例：列出所有监听TCP的端口，数字显示描述：查看本机监听的（-l）TCP连接（-t）的IP地址的数字显示（-n）。不适用-n的话，就会用端口的约定名称来显示，例如80端口，会显示成http。命令：netstat -tnl输出： 123456root@iZhp3fz3iqsadyes2s8ayeZ:~# netstat -tnlActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address State tcp 0 0 0.0.0.0:8838 0.0.0.0:* LISTEN tcp 0 0 127.0.0.1:27017 0.0.0.0:* LISTEN tcp 0 0 0.0.0.0:8330 0.0.0.0:* LISTEN 示例：获取本机的所有的TCP连接的进程名、进程号以及用户ID描述：使用-p选项查看进程信息，-ep选项可以同时查看进程名和用户名。另外，-n和-e选项一起使用，User列的属性就是用户ID，而不是用户名。查看本机所有的（al）TCP连接的（t）进程名（p）和用户名ID（ne）。命令：netstat -altpen 1234567root@iZhp3fz3iqsadyes2s8ayeZ:~# netstat -altpenActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address Foreign Address State User Inode PID/Program nametcp 0 0 0.0.0.0:8838 0.0.0.0:* LISTEN 0 11863750 31212/bnewd tcp 0 0 127.0.0.1:27017 0.0.0.0:* LISTEN 110 2945745 18546/mongod tcp 0 0 0.0.0.0:8330 0.0.0.0:* LISTEN 0 22250263 13550/btnd tcp 0 0 127.0.0.1:587 0.0.0.0:* LISTEN 0 12285119 11792/sendmail: MTA 这个可能是最屌的命令了，也可能是最常用的命令了。 还有一些实例，暂时不常用，有待完善。]]></content>
      <categories>
        <category>linux</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB：聚合之累加操作符]]></title>
    <url>%2Fmongodb%2Fmongodb-collection-aggregator-accumulate-operator.html</url>
    <content type="text"><![CDATA[MongoDB的聚合之累加操作符。 官网：https://docs.mongodb.com/manual/reference/operator/aggregation/group/#considerations。 累加操作符感觉这个没有太多可说的，简单翻译一下。 名字 描述 $avg Returns an average of numerical values. Ignores non-numeric values.（返回平均值） $first Returns a value from the first document for each group. Order is only defined if the documents are in a defined order.（返回第一个） $last Returns a value from the last document for each group. Order is only defined if the documents are in a defined order.（返回最后一个） $max Returns the highest expression value for each group.（返回最大值） $min Returns the lowest expression value for each group.（返回最小值） $push Returns an array of expression values for each group. $addToSet Returns an array of unique expression values for each group. Order of the array elements is undefined.（） $stdDevPop Returns the population standard deviation of the input values. $stdDevSamp Returns the sample standard deviation of the input values. $sum Returns a sum of numerical values. Ignores non-numeric values.（返回总和）]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[MongoDB：聚合之介绍]]></title>
    <url>%2Fmongodb%2Fmongodb-collection-aggregation-introduction.html</url>
    <content type="text"><![CDATA[MongoDB的聚合功能介绍。 官网：https://docs.mongodb.com/manual/aggregation/#single-purpose-agg-operations。 初衷：MongoDB的使用还是有一定难度的，官网讲解的一环牵扯一环，不容易一下子把握住重点，也不利于快速查询操作，所以整理一下。 聚合函数是对记录集（data records）进行操作，是把多条记录集合（group）在一起，进行处理，与此相对应的是sql的group by等操作，这是数据处理的一个方面。 MongoDB提供三种聚合方法： 聚合管道。 map-reduce函数。 单一功能的聚合方法。 聚合管道接触过linux shell的人应该对管道不会陌生，管道就是对输入的数据进行一系列的处理、转换，变成新的数据。 这里的聚合管道是对记录集进行多阶段的转换，产出新聚合结果，例如： 解释一下： 数据集合：orders，共有4条记录，这里省略了_id 这个域。 需求：查找所有status=&quot;A&quot; 的记录，根据cust_id进行分组，计算每个组的amount的和。 分析：{$match: {status: &quot;A&quot;}}，第一个阶段，匹配阶段，查找所有status=&quot;A&quot; 的记录。{$group: {_id: &quot;$cust_id&quot;, total: {$sum: &quot;$amount&quot;}}}，第二个阶段，分组计算，根据cust_id进行分组，对每个组的amount进行求和。这里涉及$group 的语法，如下： 1&#123; $group: &#123; _id: &lt;expression&gt;, &lt;field1&gt;: &#123; &lt;accumulator1&gt; : &lt;expression1&gt; &#125;, ... &#125; &#125; 其中，_id是强制的，后面是可选的。&lt;accumulator1&gt;是累加操作符，参考这里，例如这里的$sum，注意，这里必须要加$。&lt;expression1&gt;是表达式，有待补充， &quot;$amount&quot; , 表示是去取上一个结果中的amount 这个域，对其进行累加，并把结果存入新的域total中。 这个例子看明白了，聚合就基本明白了。 Map-Reducemap-reduce操作分为两个阶段：map阶段，处理每一条记录，产出一个或多个对象；reduce阶段，合并map阶段的输出。作为可选，map-reduce可以有一个最终阶段来对结果进行最终的操作。map-reduce也可以进行查询、排序和限制输出结果。 单一功能的聚合方法MongoDB也提供db.collection.count()（求和）和db.collection.distinct()（去重）函数。]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[MongoDB：查找记录 find（1）]]></title>
    <url>%2Fmongodb%2Fmongodb-collection-find-1.html</url>
    <content type="text"><![CDATA[MongoDB如何查询记录之一。 官网：https://docs.mongodb.com/manual/reference/method/db.collection.find/。 定义：1db.collection.find(query, projection) 在集合或者视图的文档中进行选择，并且返回一个指向被选中的文档的游标。（原文是：Selects documents in a collection or view and returns a cursor to the selected documents.） 参数 类型 描述 query 文档型 可选。使用查询操作符(参考这里)，指定了查询过滤器。 想要返回集合中所有的文档，忽略这个参数，或者传一个空的文档({})。 projection 文档型 可选。制定了匹配查询过滤器，要返回的文档的域。想要返回匹配的文档中的所有域，忽略这个参数。 行为投影projection参数决定了哪些域需要被返回。 1&#123; field1: &lt;value&gt;, field2: &lt;value&gt; ... &#125; &lt;value&gt;可以是: 1 或 true 表示要在返回文档中包含这个域。 0 或 false 表示不包含这个域。 表达式使用了投影操作符（有待解释）。 实例实例 查找上文test集合中的所有文档。12345678910111213141516171819&gt; db.test.find().pretty()&#123; &quot;_id&quot; : ObjectId(&quot;5abb3b5bce69c048be080199&quot;), &quot;meta&quot; : &#123; &quot;createAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;), &quot;updateAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;) &#125;, &quot;a&quot; : &quot;1&quot;, &quot;b&quot; : &quot;1&quot;&#125;&#123; &quot;_id&quot; : ObjectId(&quot;5abb3b5bce69c048be080120&quot;), &quot;meta&quot; : &#123; &quot;createAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;), &quot;updateAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;) &#125;, &quot;a&quot; : &quot;1&quot;, &quot;b&quot; : &quot;3&quot;&#125; pretty()是用来让展示更加舒适。 实例 查找test集合中的b=&quot;3&quot;的记录，这里要注意“3”和3是不一样的，这里是要符合js的语法，字符串和数字表示方式是不同的。做一个好的程序员，一定要严谨，而做到了严谨，可以帮你更快地提高，更快地产出，更好地规避错误，其实加快了你的职场发展节奏。12345678910&gt; db.test.find(&#123;b: &quot;3&quot;&#125;).pretty()&#123; &quot;_id&quot; : ObjectId(&quot;5abb3b5bce69c048be080120&quot;), &quot;meta&quot; : &#123; &quot;createAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;), &quot;updateAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;) &#125;, &quot;a&quot; : &quot;1&quot;, &quot;b&quot; : &quot;3&quot;&#125; 可以看到，这次只查出了一条符合条件的记录。 实例 查找test集合中的b=”3”的记录a和b两个域，不要其它域。 12&gt; db.test.find(&#123;b: &quot;3&quot;&#125;, &#123;a: 1, b: 1&#125;).pretty()&#123; &quot;_id&quot; : ObjectId(&quot;5abb3b5bce69c048be080120&quot;), &quot;a&quot; : &quot;1&quot;, &quot;b&quot; : &quot;3&quot; &#125; 可以看到，没有涉及的域就没有再获取出来，这样在一些情况下是可以节省网络开销和分析成本的，在《高性能MySQL》也是讲过类似的原理，不要大而全地去把所有内容获取回来，对于资源的使用，应该是有规划的、经济地去使用。]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[MongoDB：查询和投影操作符]]></title>
    <url>%2Fmongodb%2Fmongodb-collection-find-projection-operator.html</url>
    <content type="text"><![CDATA[MongoDB查询和投影操作符。 官网：https://docs.mongodb.com/manual/reference/operator/query/。 这一章节都是很简单的英语，就做一个很简单的备注，如果连这个英语都看不懂，那就需要提高了，程序员看不懂基本的英语是很难提高的。这一章节还需要完善一些样例，这个有待补充。 查询选择器比较 名字 描述 $eq Matches values that are equal to a specified value.（判断相等） $gt Matches values that are greater than a specified value.（判断大于） $gte Matches values that are greater than or equal to a specified value.（判断大于等于） $in Matches any of the values specified in an array.（判断在其中） $lt Matches values that are less than a specified value.（判断小于） $lte Matches values that are less than or equal to a specified value.（判断小于等于） $ne Matches all values that are not equal to a specified value.（判断所有值都不等于指定值） $nin Matches none of the values specified in an array.（判断不在其中） 逻辑 名字 描述 $and Joins query clauses with a logical AND returns all documents that match the conditions of both clauses.（与） $not Inverts the effect of a query expression and returns documents that do not match the query expression.（非） $nor Joins query clauses with a logical NOR returns all documents that fail to match both clauses.（异或） $or Joins query clauses with a logical OR returns all documents that match the conditions of either clause.（或） 元素 名字 描述 $exists Matches documents that have the specified field. $type Selects documents if a field is of the specified type. 评估 名字 描述 $expr Allows use of aggregation expressions within the query language. $jsonSchema Validate documents against the given JSON Schema. $mod Performs a modulo operation on the value of a field and selects documents with a specified result. $regex Selects documents where values match a specified regular expression. $text Performs text search. $where Matches documents that satisfy a JavaScript expression. 地理空间 名字 描述 $geoIntersects Selects geometries that intersect with a GeoJSON geometry. The 2dsphere index supports $geoIntersects. $geoWithin Selects geometries within a bounding GeoJSON geometry. The 2dsphere and 2d indexes support $geoWithin. $near Returns geospatial objects in proximity to a point. Requires a geospatial index. The 2dsphere and 2d indexes support $near. $nearSphere Returns geospatial objects in proximity to a point on a sphere. Requires a geospatial index. The 2dsphere and 2d indexes support $nearSphere. 数组 名字 描述 $all Matches arrays that contain all elements specified in the query. $elemMatch Selects documents if element in the array field matches all the specified $elemMatch conditions. $size Selects documents if the array field is a specified size. 位操作 名字 描述 $bitsAllClear Matches numeric or binary values in which a set of bit positions all have a value of 0. $bitsAllSet Matches numeric or binary values in which a set of bit positions all have a value of 1. $bitsAnyClear Matches numeric or binary values in which any bit from a set of bit positions has a value of 0. $bitsAnySet Matches numeric or binary values in which any bit from a set of bit positions has a value of 1. 注释 名字 描述 $comment Adds a comment to a query predicate. 投影操作 名字 描述 $ Projects the first element in an array that matches the query condition. $elemMatch Projects the first element in an array that matches the specified $elemMatch condition. $meta Projects the document’s score assigned during $text operation. $slice Limits the number of elements projected from an array. Supports skip and limit slices.]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Linux下shell命令用法及常见用例：touch]]></title>
    <url>%2Flinux%2Fshell-command-touch.html</url>
    <content type="text"><![CDATA[touch命令用来创建文件，也可以更改和修改一个文件的时间戳。 概要touch [选项]... 文件... 描述touch命令用来创建文件，也可以更改和修改一个文件的时间戳。Linux中的每个文件都与时间戳相关联，而且每个文件都存储上次访问时间，上次修改时间，上次更改时间的信息。因为，无论何时创建一个新文件，访问或者修改现有文件，时间戳都会被自动更新。 命令选项Linux中的文件有三个时间： access time（atime）：访问时间，对一次文件的内容就会更新。例如cat，vi/vim，cp，touch命令。 modification time（mtime）：修改时间，对文件内容修改一次就会更新。例如touch，vi/vim命令。 status time（ctime）：状态改动时间。通过chmod/chown/chgrp等命令更改一次文件属性，通过touch准确地修改时间等，这个时间就会更新。例如mv，touch，chmod/chown/chgrp，vi/vim等命令。 touch命令选项： -a，只改变访问时间。 -c，如果文件不存在，那就不创建。 -d，更新访问时间和修改时间。 -m，只改变修改时间。 -r，将参照文件ref_file相应的时间戳作为指定文件file时间戳的新值。 -t，用指定的时间创建文件，格式是[[CC]YY]MMDDhhmm[.SS]。CCYY的范围在1969~2068之内。SS为秒数，范围在0~61之间，这样可以处理闰秒。由于系统的限制，早于1970年1月1日的时间是错误的。 示例：1. 创建空文件描述：若文件不存在，使用touch命令可以轻松地创建一个空文件，或是创建多个。如果文件已存在，那么文件的3个时间：修改时间（mtime）、状态改动时间（ctime）和访问时间（atime）都会被更新为当前时间。stat命令可以查看文件时间。命令：touch my_onestat my_onetouch my_one my_two my_three输出： 示例：2. 只改变文件的修改时间（mtime）和状态改动时间（ctime）描述：只改变my_three文件的修改时间为当前时间，同时状态改动时间会在命令执行后更新为当前时间。这个操作并不需要修改文件内容。-m选项只更改文件的修改时间。命令：touch -m my_three输出： 示例：3. 只改变文件访问时间（atime）和状态改动时间（ctime）描述：只改变my_three文件的访问时间为当前时间，同时状态改动时间会在命令执行后更新为当前时间。如果文件不存在，会创建新的空文件。-a选项只更改文件的访问时间。命令：touch -a my_three输出： 示例：4. 指定文件的访问时间和修改时间描述：同时设置文件的访问时间和修改时间为指定时间，同时会更新状态改变时间为当前命令执行后的时间。如果文件不存在，会创建新的空文件。-d选项同时改变文件的访问时间和修改时间。命令：touch -d &quot;2018-06-14 14:00:00&quot; my_three输出： 描述：将my_three文件的访问时间和修改时间修改成两天前。touch还支持像date命令那样修改文件的时间。命令：touch -d &quot;2 days ago&quot; my_three输出： 示例：5. 避免创建新文件描述：更新atime、ctime、mtime，如果文件不存在，-c选项不会创建新的文件。命令：touch -c leena输出： 示例：6. 使用另一个文件的时间戳描述：-r选项将my_three的时间戳作为my_two文件的时间戳的新值，这两个文件有相同的时间戳。命令：touch -r my_three my_two输出： 示例：7. 使用指定的时间戳创建一个文件描述：将my_four文件的时间戳指定为1997年6月14日17点00分55秒。时间格式是[[CC]YY]MMDDhhmm[.SS]。命令：touch -t 199706141700.55 my_four输出：]]></content>
      <categories>
        <category>linux</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下shell命令用法及常见用例：sed]]></title>
    <url>%2Flinux%2Fshell-command-sed.html</url>
    <content type="text"><![CDATA[sed是stream editor（流式编辑器）的缩写，是一个非交互式的流编辑器，用于过滤或者转换文本。未完待续… 概要sed 选项… [脚本] [输入文件…] 描述sed编辑器被称作流编辑器(stream editor)，和普通的交互式文本编辑器恰好相反。在交互式文本编辑器中(比如vim)，你可以用键盘命令来交互式地插入、删除或替换数据中的文本。流编辑器则会在编辑器处理数据之前基于预先提供的一组规则来编辑数据流。sed编辑器可以根据命令来处理数据流中的数据，这些命令要么从命令行中输入，要么存储在一个命令文本文件中。sed编辑器会执行下列操作。(1) 一次从输入中读取一行数据。(2) 根据所提供的编辑器命令匹配数据。(3) 按照命令修改流中的数据。(4) 将新的数据输出到STDOUT。 在流编辑器将所有命令与一行数据匹配完毕后，它会读取下一行数据并重复这个过程。在流编辑器处理完流中的所有数据行后，它就会终止。 由于命令是按顺序逐行给出的，sed编辑器只需对数据流进行一遍处理就可以完成编辑操作。这使得sed编辑器要比交互式编辑器快得多，你可以快速完成对数据的自动修改。 理解这个命令使用起来有些复杂，复杂在于功能强大，需要逐步消化。 常见用例实例 替换input.txt文件中所有的“hello”为“world”，并且输出到output.txt中。 1sed &apos;s/hello/world/&apos; input.txt &gt; output.txt 这可能是最常用的例子了（至少在我工作这么多年的经验中），这里使用了sed的命令s。如果想输出到原文件的话，使用-i参数。 1sed -i &apos;s/hello/world/&apos; input.txt 这个在mac下表现会不一样，参考：https://blog.csdn.net/cuiaamay/article/details/49495885。 参考：https://www.gnu.org/software/sed/manual/sed.html。]]></content>
      <categories>
        <category>linux</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux下shell命令用法及常见用例： awk]]></title>
    <url>%2Flinux%2Fshell-command-awk.html</url>
    <content type="text"><![CDATA[awk命令在文件或字符串中基于指定规则浏览和抽取信息。 命令功能awk是一种小巧的编程语言及命令行工具。（其名称得自于它的创始人Alfred Aho、Peter Weinberger 和 Brian Kernighan姓氏的首个字母）。它非常适合服务器上的日志处理，主要是因为awk可以对文件进行操作，通常以可读文本构建行。awk命令在文件或字符串中基于指定规则浏览和抽取信息。awk抽取信息后，才能进行其他文本操作，awk脚本通常用来格式化文本文件中的信息。 命令格式有三种方式调用awk，第一种是命令行方式，例如：awk [-F field-separator] &#39;commands&#39; input-file(s)awk默认使用空格作为缺省的域分隔符。如果要浏览诸如passwd文件，此文件是以冒号作为分隔符，则必须指明-F选项。例如：awk -F : &#39;commands&#39; input-file第二种方式是将所有awk命令插入一个文件，并使awk程序可执行，然后用awk命令解释器作为脚本的首行，以便通过键入脚本名称来调用它。第三种方式是将所有的awk命令插入一个单独文件，然后调用：awl -f awk-script-file input-file(s)-f选项指明在文件awk-script-file中的awk脚本，input_file(s)是使用awk进行浏览的文件名。 awk脚本代码结构awk脚本的代码结构很简单，就是一系列的模式（pattern）和动作（action）。 12345678# commentPattern1 &#123; ACTIONS; &#125;# commentPattern2 &#123; ACTIONS; &#125;# commentPattern3 &#123; ACTIONS; &#125;# commentPattern4 &#123; ACTIONS; &#125; 扫描文档的每一行时都必须与每一个模式进行匹配比较，一次只匹配一个模式。 12this is line 1this is line 2 this is line 1这行会先Pattern1进行匹配，如果匹配成功，就会执行ACTIONS。然后this is line 1会和Pattern2进行匹配，如果匹配失败，就调到Pattern3进行匹配，以此类推。一旦所有的模式都匹配过了，this is line 2就会以同样的步骤进行匹配。其他的行也一样，直到读取完整个文件。这就是awk的运行模式。 数据类型awk仅有两个主要的数据类型：字符串和数字，它们可以相互转换。在ACTIONS部分使用=操作符给变量赋值，可以在任意时刻、任意地方声明和使用变量，也可以使用未初始化的变量，默认是空字符串。awk有数组类型，并且它们是动态的一维关联数组。 模式模式分为三大类：正则表达式、布尔表达式和特殊模式。 所有模式都是可选的，下面的脚本形式会对输入的每一行都会简单地执行ACRIONS。{ ACTIONS } 特殊的模式模式包括两个特殊字段：BEGIN和END。BEGIN在所有输入未被处理之前，即文本浏览动作之前进行匹配。可以初始化脚本变量和所有种类的状态的主要地方。END会在所有的输入都被处理完后，即完成文本浏览动作后进行匹配。可以在退出前进行清除工作和一些最后的输出。最后一类模式，要把它进行归类有点困难。它处于变量和特殊值之间，我们通常称它们为域（Field）。而且名副其实。 域1234567891011# According to the following line## $1 $2 $3# 00:34:23 GET /foo/bar.html# _____________ _____________/# $0 # Hack attempt?/admin.html$/ &amp;&amp; $2 == &quot;DELETE&quot; &#123;print &quot;Hacker Alert!&quot;;&#125; 域（默认地）由空格分隔。$0域代表了一整行的字符串。$1 域是第一块字符串（在任何空格之前），$2\$域是后一块，以此类推。awk执行时，其浏览域标记为$1, $2, $3…$n。这种方式称为域标识。使用$1, $3标识表示第1和第3域。使用$0$标识表示所有域。awk浏览到一新行时，即到达域的记录末尾，执行新记录下一行的读动作，重新设置域分隔。 动作最常用和最有用的行为： 123456789101112&#123; print $0; &#125; # prints $0. In this case, equivalent to &apos;print&apos; alone&#123; exit; &#125; # ends the program&#123; next; &#125; # skips to the next line of input&#123; a=$1; b=$0 &#125; # variable assignment&#123; c[$1] = $2 &#125; # variable assignment (array) &#123; if (BOOLEAN) &#123; ACTION &#125;else if (BOOLEAN) &#123; ACTION &#125;else &#123; ACTION &#125;&#125;&#123; for (i=1; i&lt;x; i++) &#123; ACTION &#125; &#125;&#123; for (item in c) &#123; ACTION &#125; &#125; awk里的变量都是全局变量。 函数函数的通用文档(regular documentation) 1&#123; somecall($2) &#125; 用户定义的函数： 123456789# function arguments are call-by-valuefunction name (parameter-list) &#123; ACTIONS; #same actions as usual&#125;# return is valid keywordfunction add (val) &#123;return val+1;&#125; 实用命令实例：0. 新建测试文件描述：新建一个device文件，其中(1)为序号，(2)为Android版本，(3)为访问时间，(4)为IP，(5)为访问次数。本文大部分实例根据这一文件进行说明。输出： 实例：1. 抽取域描述：打印第1个（序号）域和第2个（Android版本）域的内容。print用来输出其后跟着的内容，用大括号把print语句括起来，表示一个打印动作。输出： 实例：2. 打印所有记录描述：打印所有记录。$0代表所有域。命令：awk &#39;{print $0}&#39; device输出： 实例：3. 打印报告头描述：在序号和IP地址之间用一些空格使之更容易划分，也可以在域间使用tab键加以划分。本例中加入NO和IP两个信息头以及中划线，\n启动新行，并在\n下一行启动打印文本操作。打印信息头放置在BEGIN模式部分，因为打印信息头被界定为一个动作，必须用大括号括起来。在awk查看第一条记录前，信息头被打印。命令：awk &#39;BEGIN {print &quot;NO IP\n------------------------&quot;} {print $1&quot;\t&quot;$4}&#39; device输出： 实例：4. 打印信息尾描述：在末行加入end of report信息。END语句在所有文本处理动作执行完之后才被执行，在脚本中的位置是在主要动作之后。命令：awk &#39;BEGIN {print &quot;Version\n-------&quot;} {print $2} END {print &quot;end-of-report&quot;}&#39; device输出： 实例：5. 错误信息提示描述：如果将在awk命令中缺少一个双引号，awk将返回错误提示信息。命令：awk &#39;BEGIN {print &quot;Version\n-------&quot;} {print $2} END {print &quot;end-of-report}&#39; device输出： 注意：在碰到awk错误时，应从以下几点进行排查： 确保整个awk命令引用单引号括起来。 确保命令内所有引号成对出现。 确保用花括号括起动作语句，用圆括号括起条件语句。 可能忘记使用花括号。 描述：如果查询的文件不存在，将得到以下错误信息：命令：awk &#39;END {print NR}&#39; device.txt输出： 条件操作符实例：1. 匹配描述：如果field-4以数字4开头，打印它。如果条件满足，则打印匹配的记录行。符号~后紧跟正则表达式，使一域号匹配正则表达式，也可以使用if语句。awk的if后面的条件用()括起来。^尖角符号表示行首。命令：awk &#39;{ if ($4 ~ /^4/) print $0}&#39; device输出： 等同于： 实例：2. 精确匹配描述：精确匹配访问次数为1次的记录，确保不匹配访问次数为15次的记录。使用等号==，并用单引号括起条件，也可以使用if语句。命令：awk &#39;$5==&quot;1&quot; {print $0}&#39; device或者：awk &#39;{if($5==/1/) print $0}&#39; device输出： 实例：3. 不匹配描述：不匹配IP地址以4开头的记录。使用!~表示不匹配。命令：awk &#39;$4 !~ /^4/&#39; device或者：awk &#39;{ if ($4 !~ /^4/) print $0}&#39; device输出： 注意这里不能用!=，因为用引号或者/括起了^4，将只匹配4而不匹配49.65.119.165等。如果查询非49.65.119.165的记录，可做如下操作：awk &#39;$4 != &quot;49.65.119.165&quot;&#39; device 实例：4. 小于，小于等于，大于，大于等于描述：匹配访问次数小于序号的记录。同样的有小于等于（&lt;=），大于（&gt;），大于等于（&gt;=）。命令：awk &#39;$4 !~ /^4/&#39; device或者：awk &#39;{ if ($4 !~ /^4/) print $0}&#39; device输出： 实例：5. 设置大小写描述：匹配含有前面是i或I，后面是OS的记录。[]符号可匹配[]内任意字符或单词。命令：awk &#39;/[iI]OS/&#39; device输出： 实例：6. 任意字符描述：匹配Android版本，第八个字符是7，打印它。表达式/^…….7/表示行首前7个字符任务，第八个是7。命令：awk &#39;$2 ~ /^.......7/&#39; device输出： 实例：7. 或关系匹配描述：匹配IP地址以4或者3开头的记录。竖线符|意为两边模式之一。可以得到与[]表达式相同的结果。命令：awk &#39;$4 ~ /^(4|3)/&#39; device输出： 注意，在使用竖线符时，语句必须用圆括号括起来。另外，除了字符重复出现外，其他的正则表达式在awk中都是合法的。 实例：8. AND 描述：匹配Android版本在7.0以上，并且IP地址以4开头的记录。OR，非与之类似。命令：awk &#39;$2 ~ /^.......7/ &amp;&amp; $4 ~ /^4/&#39; device等同于：awk &#39;{ if ($2 ~ /^.......7/ &amp;&amp; $4 ~ /^4/) print $0} &#39; device输出： awk内置变量awk内置变量如下： 1234567891011BEGIN &#123; # Can be modified by the userFS = &quot;,&quot;; # Field SeparatorRS = &quot;n&quot;; # Record Separator (lines)OFS = &quot; &quot;; # Output Filed SeparatorORS = &quot;n&quot;; # Output Record Separator (lines)&#125;&#123; # Can&apos;t be modified by the userNF # Number of Fileds in the current Record (lines)NR # Number of Records seen so farARGV / ARGC # Script Arguments&#125; NF：支持记录域个数，在记录被读之后再设置。NR：已读的记录数。FILENAME：告知系统目前正在浏览的实际文件，因为awk可以同时处理许多文件。 实例：1. NF、NR、FILENAME 描述：所有记录被打印，并带有记录号（第二和第三列），并在最后输出文件名。使用NF变量显示每一条读记录中有多少个域（5个），使用NR显示已读的记录数，使用FILENAME显示正在处理的文件名。命令：awk &#39;{print NF,NR,$0} END {print FILENAME}&#39; device输出： 实例：2. 判断文件至少有一个记录 描述：先检查文件中至少有一个记录时才查询IP地址。命令：awk &#39;NR &gt; 0 &amp;&amp; $4 ~ /^4/&#39; device输出： 实例：3. 与echo结合使用 描述：将变量$PWD的返回值传入awk并显示其目录。需要指定域分隔符/。命令：echo $PWD | awk -F / &#39;{print $NF}&#39;输出： 描述：显示文件名。命令：echo &quot;/etc/vimrc&quot; | awk -F / &#39;{print $NF}&#39;输出： awk操作符 实例：1. 设置输入域到域变量名描述：赋值IP地址域为ip，版本域为version，查询版本大于7的记录，并打印IP地址和版本信息。命令：awk &#39;{ip=$4;version=$2; if (version ~ /*7*/) print ip&quot;&quot;version}&#39; device输出： 实例：2. 域值比较操作有两种方式测试数值域是否小于另一数值域。 在BEGIN中给变量名赋值。 在关系操作中使用实际数值。 描述：找出访问次数大于10次的所有记录。命令：awk &#39;{if ($5 &gt; 10) print $0}&#39; device输出： 实例：3. 修改数值域的值 当在awk中修改任何域时，实际输入文件是不可修改的，修改的只是保存在缓存里的awk副本，awk会在变量NR或NF变量中反映出修改痕迹。 描述：修改序号为6的记录，将其访问次数减一。命令：awk &#39;{if ($1==6) $5=$5-1; print $1, $2, $5 }&#39; device输出： 实例：4. 修改文本域 描述：修改序号为6的记录，将其版本修改为iOS11.2.3。修改文本域就是对其重新赋值。命令：awk &#39;{if ($1==6) ($2=&quot;iOS11.2.3&quot;); print $1, $2, $5 }&#39; device输出： 实例：5. 只显示修改记录 描述：只显示修改后序号为6的记录。命令：awk &#39;{if ($1==6) {$2=&quot;iOS11.2.3&quot;; print $2}; }&#39; device输出： 实例：6. 创建新的输出域 描述：创建新域6保存目前访问次数大于序号的减法值，表达式为’{$6=$5-$1}’，只打印其值大于零的序号和其新域值。在BEGIN部分加入tab键以对齐报告头。也可以赋给新域更有意义的变量名。命令：awk &#39;BEGIN {print &quot;IP\t Difference&quot;} {if ($5 &gt; $1) {$6=$5-$1; print $1 &quot;\t&quot; $6}}&#39; device输出： 实例：7. 增加列值 描述：使用+=累加访问次数的值。awk的每一个操作匹配时，如果没有说明打印记录，那默认会打印所有记录。命令：awk &#39;(total+=$5); END {print &quot;total visits : &quot; total}&#39; device输出： 实例：8. 文件长度相加 描述：查看当前目录中所有文件的长度及其综合，但要排除子目录，使用ls -l命令，然后管道输出到awk，awk首先剔除首字符d（/^[^d]/）的记录，然后将文件长度相加，并输出每一文件长度及在END部分输出所有文件的长度。命令：ls -l | awk &#39;/^[^d]/ {print $9&quot;\t&quot;$5} {total+=$5} END {print &quot;total KB: &quot; total}&#39;输出： 内置字符串函数 gsub类似于sed查找和替换。它允许替换一个字符串或字符为另一个字符串或字符，并以正则表达式的形式执行，第一个函数作用于记录$0，第二个gsub函数允许指定目标，如果未指定，默认是$0。index(s, t)函数返回目标字符串s中查询字符串t的首位置。length函数返回字符串s字符长度。match函数测试字符串s是否包含一个正则表达式r定义的匹配。split函数使用域分隔符fs，将字符串s划分为指定序列a。sprint函数类似于printf函数，返回基本输出格式fmt的结果字符串exp。sub(r, s)函数将用s代替$0中最左边最长的子串，该子串被（r）匹配。sub(s, p)返回字符串s在位置p后的后缀部分。substr(s, p, n)函数返回字符串s在位置p后长度为n的后缀部分。 实例：1. gsub 描述：匹配记录中访问时间为11:35的记录，修改为11:40。注意要用双引号括起来。命令：awk &#39;gsub(/11:35/, &quot;11:40&quot;) {print $0}&#39; device输出： 实例：2. index描述：匹配字符串Honey中，ney子串第一次出现的位置，即字符个数。命令：awk &#39;BEGIN {print index(&quot;Honey&quot;, &quot;ney&quot;)}&#39;输出： 实例：3. length 描述：匹配序号为6，第二个域的字符长度。也可以直接使用字符串。命令：awk &#39;$1==6 {print length($2) &quot;---&quot; $2}&#39; device输出： 实例：4. match 描述：match测试目标字符串是否包含查找字符的一部分，可以使用正则表达式。命令：在AWK中查找d，因其不存在，所以返回0。awk &#39;BEGIN {print match(&quot;AWK&quot;, /d/)}&#39;在AWK中查找K，因其存在，所有返回AWK中K出现的首位置字符数。awk &#39;BEGIN {print match(&quot;AWK&quot;, /K/)}&#39;在序号为6的记录中，查找Android的大版本号。awk &#39;$1==6 {print match($2, &quot;7&quot;)}&#39; device输出： 实例：5. split 描述：如果域中具有分隔符形式的字符串，使用split函数将其分隔，并保存到一个数组中，最后将数组的第一个元素打印出来。命令：awk &#39;BEGIN {print split(&quot;123#456#789&quot;, myarray, &quot;#&quot;)}&#39;输出： 实例：6. sub 描述：匹配所有Android，替换为android。注意只在模式第一次出现时进行替换操作。命令：awk &#39;sub(/Android/, &quot;android&quot;)&#39; device输出： 实例：7. substr 描述：匹配第二个域版本信息中，打印从第一个字符开始到第七个字符。如果给定的长度值远大于字符串长度，awk将从起始位置返回所有字符。另一种形式是返回字符串后缀或指定位置后面的字符。命令：awk &#39;$1==5 {print substr($2,1,7)}&#39; device输出： 实例：8. 从shell向awk传入字符串命令：使用管道将字符串powerful传入awk，返回其长度。echo &quot;powerful&quot; | awk &#39;{print length($0)}&#39;设置文件名为一变量，管道输出到awk，但会不带扩展名的文件名。STR=&quot;myawk.txt&quot; | echo $STR | awk &#39;{print substr($STR,1,5)}&#39;设置文件名为一变量，管道输出到awk，只返回其扩展名。TR=&quot;myawk.txt&quot; | echo $STR | awk &#39;{print substr($STR,7)}&#39; 输出： 字符转义 printf修饰符基本语法：printf([格式控制符], 参数)格式控制符通常在引号里。 awkprintf修饰符： awk printf格式： 实例：1. 字符转换描述：通过管道输出65到awk中，printf进行ASCII码字符转换。命令：echo &quot;65&quot; | awk &#39;{printf (&quot;%c\n&quot;, $0)}&#39;或者awk &#39;BEGIN {printf &quot;%c\n&quot;, 65}&#39;输出： 描述：数字1024转换为浮点数之后，被加入了六个小数点。命令：awk &#39;BEGIN {printf &quot;%f\n&quot;, 1024}&#39; 输出： 实例：2. 格式化输出 描述：BEGIN后的第一个花括号嵌入头信息，第二个花括号打印所有用户的IP地址和访问时间，要求IP地址左对齐，23个字符长度，后跟访问时间。命令：awk &#39;BEGIN {print &quot;IP\t\t\tTime&quot;} {printf &quot;%-23s %s\n&quot;, $4, $3}&#39; device 输出： 实例：3. 向一行awk命令传值 描述：在命令行中设置VISITS等于10，然后传入awk中，查询访问次数大于10的所有记录。命令：awk &#39;{if($5 &gt; VISITS) print $0} &#39; VISITS=10 device输出： 描述：用管道将df -k传入awk，然后抽出第四列，即剩余可利用空间容量。使用$4 ~ /^[0-9]/取得容量数值，最后对命令行if($4 &lt; TRIGGER)上变量TRIGGER的值进行查询。查看文件系统空间容量，观察其是否达到一定水平。因为要监视的已使用空间容量不断在变化，所以需要再命令行指定一个触发值。命令：df -k | awk &#39;($4 ~ /^[0-9]/) {if ($4 &lt; TRIGGER) printf &quot;%-15s %s\n&quot;,$6,$4}&#39; TRIGGER=930000输出： 描述：打印当前注册用户，并加入一定信息。命令：who | awk &#39;{print $1 &quot; is logged on&quot;}&#39;输出： 描述：传入环境变量LOGNAME，显示当前用户名。命令：who | awk &#39;{if ($1 == user) print $1&quot; you are connected to &quot; $2}&#39; user=$LOGNAME&quot;}&#39;输出： 实例：4. awk脚本文件 描述：第一行#! /usr/bin/awk -f告知脚本系统awk命令的位置。在脚本文件后键入文件名之前，需要先对脚本文件加入可执行权限。命令：chmod u+x user_tot.awkuser_tot.awk脚本文件： 描述：执行user_tot.awk脚本文件。命令：./user_tot.awk device输出： 实例：5. 在awk中使用FS变量 描述：从/etc/passwd文件中抽取第1和第5域，通过FS变量，指定冒号:分隔passwd文件域。第1域时账号名，第5域是账号所有者。命令：chmod u+x passwd.awk | ./passwd.awk /etc/passwd输出： 实例：6. 向awk脚本传值 向awk脚本传值与向awk一行命令传值的方式大体相同，格式为：awk script_file var=value input_file 描述：对比检查文件中域号和指定数字。注意不要忘了增加脚本的可执行权限。命令：chmod u+x fieldcheck.awk | ./fieldcheck.awk MAX=7 FS=&quot;:&quot; /etc/passwd输出： 描述：从du命令获得输入，并输出块和字节数。命令：chmod u+x duawk.awk | du /root | ./duawk.awk输出： 实例：9. awk数组 描述：用split将123#456#789划分开，并存入myarray数组，再使用循环打印各数组元素。命令：chmod u+x duawk.awk | du /root | ./duawk.awk输出： 实例：10. 处理由通配符指定的多个文件名 描述：打印当前目录中以.txt结尾的文件。nextfile告诉awk停止处理当前的输入文件。下一个输入记录读取来自下一个输入文件。命令：awk &#39;{ print FILENAME; nextfile } &#39; *.txtawk &#39;BEGIN{ print &quot;Starting...&quot;} { print FILENAME; nextfile }END{ print &quot;....DONE&quot;} &#39; *.txt输出：]]></content>
      <categories>
        <category>linux</category>
        <category>shell</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB：创建数据集合]]></title>
    <url>%2Fmongodb%2Fmongodb-collection-create.html</url>
    <content type="text"><![CDATA[MongoDB如何创建数据集合（collection）。 官网地址：https://docs.mongodb.com/manual/reference/method/db.createCollection/#db.createCollection。 这节有点混乱，也有点尴尬，因为原本MongoDB就有些“没有规矩”。 快速创建一个集合，参考插入这一节。 集合不存在的情况下，插入一条记录就会创建集合。 稍微啰嗦一点，如下： 12345678910db.test.insert(&#123; &quot;_id&quot; : ObjectId(&quot;5abb3b5bce69c048be080199&quot;), &quot;meta&quot; : &#123; &quot;createAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;), &quot;updateAt&quot; : ISODate(&quot;2018-03-28T06:51:07.579Z&quot;) &#125;, &quot;a&quot; : &quot;1&quot;, &quot;b&quot; : &quot;1&quot;,&#125;)WriteResult(&#123; &quot;nInserted&quot; : 1 &#125;) 这样即会创建集合test，又会给这个集合插入一条记录。 非要规矩地创建（其实是可以设置一些选项），那么： 12345678910111213db.createCollection(&lt;name&gt;, &#123; capped: &lt;boolean&gt;, autoIndexId: &lt;boolean&gt;, size: &lt;number&gt;, max: &lt;number&gt;, storageEngine: &lt;document&gt;, validator: &lt;document&gt;, validationLevel: &lt;string&gt;, validationAction: &lt;string&gt;, indexOptionDefaults: &lt;document&gt;, viewOn: &lt;string&gt;, pipeline: &lt;pipeline&gt;, collation: &lt;document&gt;, writeConcern: &lt;document&gt;&#125; ) 参数 类型 描述 name 字符串 要创建的集合的名称。 options 文档 可选。一大堆选项，暂时没用到，将来再补充了。]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[MongoDB：创建数据库]]></title>
    <url>%2Fmongodb%2Fmongodb-dababase-create.html</url>
    <content type="text"><![CDATA[MongoDB如何创建数据库。 官网位置：https://docs.mongodb.com/manual/mongo/。 初衷：MongoDB的使用还是有一定难度的，官网讲解的一环牵扯一环，不容易一下子把握住重点，也不利于快速查询操作，所以整理一下。 进入mongo： 1234root@iZhp3fz3iqsadyes2s8ayeZ:~# mongoMongoDB shell version: 2.6.10connecting to: test...... 如果没有mongo这个命令，表示路径没有配置好。 1use &lt;database&gt; 尖括号表示需要你替换的变量，别完全照搬，当年我是犯过这种很猪头的错误的，你不要证明你也猪头了。 如果数据库存在，这条命令会切换到该数据库，如果不存在，则创建并切换到该数据库。 实例：创建一个数据库，名字为my_test。 12use my_testswitched to db my_test 好，创建成功。]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
  </entry>
</search>
